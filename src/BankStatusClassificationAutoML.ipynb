{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Klee - Visual Analytics](https://github.com/nikbearbrown/Visual_Analytics/blob/main/IMG/Klee_Visual_Analytics.png?raw=true)\n",
    "\n",
    "\n",
    "YouTube - https://www.youtube.com/c/NikBearBrown    \n",
    "GitHub - https://github.com/nikbearbrown/Visual_Analytics   \n",
    "Kaggle - https://www.kaggle.com/nikbearbrown   \n",
    "Klee.ai (Visual AI) - http://klee.ai "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML with H2O.ai\n",
    "\n",
    "_Lessons from Kaggle – Ensemble ML and Feature Engineering_\n",
    "\n",
    "99.9% of high ranking Kaggle submissions shared two approaches. Stacking and feature engineering. In this notebook, we will use indivdual models and stacked models to predict lift. Stacking is a type of ensemble, creating a ”super-model” by combining many complementary models.\n",
    "\n",
    "We will use generate thousands on individual models, select the best models and combine the best models into a ”super-model” to predict lift.\n",
    "\n",
    "_Models and hyperparamter optimization_\n",
    "\n",
    "A model is an algorithm with a given set of hyperparamters. For example, a random forest estimator that uses 10 trees and one that uses 20 trees are two different models. Using a few algorithms and important tuning paramters (hyperparamters) we will try many combination and select rank the models on some metric like AUC, mean residual deviance, RSME as approriate for the analysis.  \n",
    "\n",
    "_The machine learning algorithms_\n",
    "\n",
    "We will use the following algorithms as our base:\n",
    "\n",
    "* Deep Learning (Neural Networks)    \n",
    "* Generalized Linear Model (GLM)  \n",
    "* Extreme Random Forest (XRT) \n",
    "* Distributed Random Forest (DRF)     \n",
    "* Gradient Boosting Machine (GBM)     \n",
    "* XGBoost   \n",
    "\n",
    "\n",
    "_Deep Learning (Neural Networks)_  \n",
    "\n",
    "The are simple Multiclass perceptrons (MLPs) as discussed in the first notebook.  \n",
    "\n",
    "\n",
    "_Generalized Linear Model (GLM)_   \n",
    "\n",
    "The generalized linear model (GLM) is a flexible generalization of ordinary linear regression that allows for response variables that have error distribution models other than a normal distribution. The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.\n",
    "\n",
    "In our case, we will assume that the the distribution of errors is normal and that the link function is the identity, which means the will will be performing simple linear regression.   Linear regression predicts the response variable $y$ assuming it has a linear relationship with predictor variable(s) $x$ or $x_1, x_2, ,,, x_n$.\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x + \\varepsilon .$$\n",
    "\n",
    "\n",
    "_Distributed Random Forest (DRF)_    \n",
    "\n",
    "A Distributed Random Forest (DRF) is a powerful low-bias classification and regression tool that can fit highly non-linear data. To prevent overfitting a DRF generates a forest of classification or regression trees, rather than a single classification or regression tree through a process called bagging. The variance of estimates can be adjusted by the number of trees used. \n",
    "\n",
    "_Extreme Random Forest (XRT)_\n",
    "\n",
    "Extreme random forests are nearly identical to standard random forests except that the splits, both attribute and cut-point, are chosen totally or partially at random. Bias/variance\n",
    "analysis has shown that XRTs work by decreasing variance while at the same time increasing bias. Once the randomization level is properly adjusted, the variance almost vanishes while bias only slightly increases with respect to standard trees. \n",
    "\n",
    "\n",
    "_Gradient Boosting Machine (GBM)_   \n",
    "\n",
    "Gradient Boosting Machine (for Regression and Classification) is a forward learning ensemble method. The guiding heuristic is that good predictive results can be obtained through increasingly refined approximations. Boosting can create more accurate models than bagging but doesn’t help to avoid overfitting as much as bagging does.\n",
    "\n",
    "Unlike a DRF which uses bagging to prevent overfitting a GBM uses boosting to sequentially refine a regression or classification tree. However as each tree is built in parallel it allows for multi-threading (asynchronous) training large data sets.\n",
    "\n",
    "As with all tree based methods it creates decision trees and is highly interpretable.\n",
    "\n",
    "\n",
    "_XGBoost_\n",
    "\n",
    "XGBoost is a supervised learning algorithm that implements a process called boosting to yield accurate models. Boosting refers to the ensemble learning technique of building many models sequentially, with each new model attempting to correct for the deficiencies in the previous model. \n",
    "\n",
    "Both XGBoost and GBM follows the principle of gradient boosting. However, XGBoost has a more regularized model formalization to control overfitting. Boosting does not prevent overfitting the way bagging does, but typically gives better accuracy. XGBoost corrects for the deficiencies of boosting by ensembling regularized trees.\n",
    "\n",
    "Like a GBM, each tree is built in parallel it allows for multi-threading (asynchronous) training large data sets.\n",
    "\n",
    "As with all tree based methods it creates decision trees and is highly interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2O.ai Automl\n",
    "\n",
    "H2O’s AutoML can be used for automating the machine learning workflow, which includes automatic training and tuning of many models within a user-specified time-limit. Stacked Ensembles – one based on all previously trained models, another one on the best model of each family – will be automatically trained on collections of individual models to produce highly predictive ensemble models which, in most cases, will be the top performing models in the AutoML Leaderboard.\n",
    "\n",
    "\n",
    "You will need to install H2O.ai Automl for python to run this notebook. \n",
    "\n",
    "\n",
    "```bash\n",
    "\n",
    "pip install requests\n",
    "pip install tabulate\n",
    "pip install \"colorama>=0.3.8\"\n",
    "pip install future\n",
    "\n",
    "pip uninstall h2o\n",
    "\n",
    "\n",
    "pip install -f http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Py.html h2o\n",
    "\n",
    "```\n",
    "\n",
    "Note: When installing H2O from pip in OS X El Capitan, users must include the --user flag.\n",
    "\n",
    "```bash\n",
    "pip install -f http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Py.html h2o --user\n",
    "```\n",
    "\n",
    "See Downloading & Installing H2O [http://docs.h2o.ai/h2o/latest-stable/h2o-docs/downloading.html](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/downloading.html)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# Use pip install or conda install if missing a library\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import random, os, sys\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import logging\n",
    "import csv\n",
    "import optparse\n",
    "import time\n",
    "import json\n",
    "from distutils.util import strtobool\n",
    "import psutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a minimum memory size and a run time in seconds\n",
    "min_mem_size=6\n",
    "run_time=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Use 50% of availible resources\n",
    "pct_memory=0.5\n",
    "virtual_memory=psutil.virtual_memory()\n",
    "min_mem_size=int(round(int(pct_memory*virtual_memory.available)/1073741824,0))\n",
    "print(min_mem_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:42708 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_311\"; Java(TM) SE Runtime Environment (build 1.8.0_311-b11); Java HotSpot(TM) 64-Bit Server VM (build 25.311-b11, mixed mode)\n",
      "  Starting server from /opt/anaconda3/lib/python3.9/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/5q/w_y2sfjj2bv130sh86slry7r0000gq/T/tmp__1_yumb\n",
      "  JVM stdout: /var/folders/5q/w_y2sfjj2bv130sh86slry7r0000gq/T/tmp__1_yumb/h2o_work_started_from_python.out\n",
      "  JVM stderr: /var/folders/5q/w_y2sfjj2bv130sh86slry7r0000gq/T/tmp__1_yumb/h2o_work_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:42708\n",
      "Connecting to H2O server at http://127.0.0.1:42708 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>04 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.36.0.2</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>16 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_work_wvxy5g</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.772 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:42708</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, Infogram, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.7 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         04 secs\n",
       "H2O_cluster_timezone:       America/New_York\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.36.0.2\n",
       "H2O_cluster_version_age:    16 days\n",
       "H2O_cluster_name:           H2O_from_python_work_wvxy5g\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.772 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:42708\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, Infogram, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.9.7 final\n",
       "--------------------------  ----------------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 65535 Highest port no\n",
    "# Start the H2O server on a random port\n",
    "port_no=random.randint(5555,55555)\n",
    "\n",
    "#  h2o.init(strict_version_check=False,min_mem_size_GB=min_mem_size,port=port_no) # start h2o\n",
    "try:\n",
    "  h2o.init(strict_version_check=False,min_mem_size_GB=min_mem_size,port=port_no) # start h2o\n",
    "except:\n",
    "  logging.critical('h2o.init')\n",
    "  h2o.download_all_logs(dirname=logs_path, filename=logfile)      \n",
    "  h2o.cluster().shutdown()\n",
    "  sys.exit(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and Manage Data Types\n",
    "\n",
    "This exploration of H2O will use a version of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "# Import the processed data from notebook One\n",
    "url = \"https://raw.githubusercontent.com/sanapsanket/Bank-Loan-Status-Predictive-Analysis/main/KaggleDataset/BankLoanStatusDataset/credit_train.csv\"\n",
    "df = h2o.import_file(path = url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Loan ID                             </th><th>Customer ID                         </th><th>Loan Status  </th><th style=\"text-align: right;\">  Current Loan Amount</th><th>Term      </th><th style=\"text-align: right;\">  Credit Score</th><th style=\"text-align: right;\">  Annual Income</th><th>Years in current job  </th><th>Home Ownership  </th><th>Purpose          </th><th style=\"text-align: right;\">  Monthly Debt</th><th style=\"text-align: right;\">  Years of Credit History</th><th style=\"text-align: right;\">  Months since last delinquent</th><th style=\"text-align: right;\">  Number of Open Accounts</th><th style=\"text-align: right;\">  Number of Credit Problems</th><th style=\"text-align: right;\">  Current Credit Balance</th><th style=\"text-align: right;\">  Maximum Open Credit</th><th style=\"text-align: right;\">  Bankruptcies</th><th style=\"text-align: right;\">  Tax Liens</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>14DD8831-6AF5-400B-83EC-68E61888A048</td><td>981165EC-3274-42F5-A3B4-D104041A9CA9</td><td>Fully Paid   </td><td style=\"text-align: right;\">               445412</td><td>Short Term</td><td style=\"text-align: right;\">           709</td><td style=\"text-align: right;\">    1.16749e+06</td><td>8 years               </td><td>Home Mortgage   </td><td>Home Improvements</td><td style=\"text-align: right;\">       5214.74</td><td style=\"text-align: right;\">                     17.2</td><td style=\"text-align: right;\">                           nan</td><td style=\"text-align: right;\">                        6</td><td style=\"text-align: right;\">                          1</td><td style=\"text-align: right;\">                  228190</td><td style=\"text-align: right;\">               416746</td><td style=\"text-align: right;\">             1</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na_omit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best.varimp(use_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe()\n",
    "#df=df.drop('Loan ID')\n",
    "#df=df.drop('Customer ID')\n",
    "#df=df.drop('Tax Liens')\n",
    "#df=df.drop('Bankruptcies')\n",
    "#df=df.drop('Number of Credit Problems')\n",
    "#df=df.drop('Term')\n",
    "#df=df.drop('Home Ownership')\n",
    "#df=df.drop('Maximum Open Credit')\n",
    "#df=df.drop('Purpose')\n",
    "#df=df.drop('Years in current job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 80/20 train/test splie\n",
    "pct_rows=0.80\n",
    "df_train, df_test = df.split_frame([pct_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80518, 19)\n",
      "(19996, 19)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Loan ID                             </th><th>Customer ID                         </th><th>Loan Status  </th><th style=\"text-align: right;\">  Current Loan Amount</th><th>Term      </th><th style=\"text-align: right;\">  Credit Score</th><th style=\"text-align: right;\">  Annual Income</th><th>Years in current job  </th><th>Home Ownership  </th><th>Purpose           </th><th style=\"text-align: right;\">  Monthly Debt</th><th style=\"text-align: right;\">  Years of Credit History</th><th style=\"text-align: right;\">  Months since last delinquent</th><th style=\"text-align: right;\">  Number of Open Accounts</th><th style=\"text-align: right;\">  Number of Credit Problems</th><th style=\"text-align: right;\">  Current Credit Balance</th><th style=\"text-align: right;\">  Maximum Open Credit</th><th style=\"text-align: right;\">  Bankruptcies</th><th style=\"text-align: right;\">  Tax Liens</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>4771CC26-131A-45DB-B5AA-537EA4BA5342</td><td>2DE017A3-2E01-49CB-A581-08169E83BE29</td><td>Fully Paid   </td><td style=\"text-align: right;\">               262328</td><td>Short Term</td><td style=\"text-align: right;\">           nan</td><td style=\"text-align: right;\">            nan</td><td>10+ years             </td><td>Home Mortgage   </td><td>Debt Consolidation</td><td style=\"text-align: right;\">         33296</td><td style=\"text-align: right;\">                     21.1</td><td style=\"text-align: right;\">                             8</td><td style=\"text-align: right;\">                       35</td><td style=\"text-align: right;\">                          0</td><td style=\"text-align: right;\">                  229976</td><td style=\"text-align: right;\">               850784</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models Using H2O's AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the features and target\n",
    "X=df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Loan ID', 'Customer ID', 'Current Loan Amount', 'Term', 'Credit Score', 'Annual Income', 'Years in current job', 'Home Ownership', 'Purpose', 'Monthly Debt', 'Years of Credit History', 'Months since last delinquent', 'Number of Open Accounts', 'Number of Credit Problems', 'Current Credit Balance', 'Maximum Open Credit', 'Bankruptcies', 'Tax Liens']\n"
     ]
    }
   ],
   "source": [
    "# Set target and predictor variables\n",
    "target ='Loan Status'\n",
    "X.remove(target)\n",
    "df_train[target]=df_train[target].asfactor()\n",
    "df_test[target]=df_test[target].asfactor()\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "H20 AutoML will automatically perform regression or classification depedending on the target data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "15:42:20.811: Project: AutoML_6_20220211_154220\n",
      "15:42:20.812: 5-fold cross-validation will be used.\n",
      "15:42:20.816: Setting stopping tolerance adaptively based on the training frame: 0.0035241429027194466\n",
      "15:42:20.816: Build control seed: 1\n",
      "15:42:20.818: training frame: Frame key: AutoML_6_20220211_154220_training_py_27_sid_9826    cols: 19    rows: 80518  chunks: 32    size: 5237594  checksum: -4210142017087432970\n",
      "15:42:20.818: validation frame: NULL\n",
      "15:42:20.818: leaderboard frame: NULL\n",
      "15:42:20.818: blending frame: NULL\n",
      "15:42:20.818: response column: Loan Status\n",
      "15:42:20.818: fold column: null\n",
      "15:42:20.818: weights column: null\n",
      "15:42:20.821: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_xgboost (6g, 10w), best_of_family_gbm (6g, 10w), all_xgboost (7g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]\n",
      "15:42:20.828: AutoML job created: 2022.02.11 15:42:20.805\n",
      "15:42:20.831: AutoML build started: 2022.02.11 15:42:20.830\n",
      "15:42:20.834: AutoML: starting XGBoost_1_AutoML_6_20220211_154220 model training\n",
      "15:42:20.850: _train param, Dropping bad and constant columns: [Customer ID, Loan ID]\n",
      "\n",
      "\n",
      "15:42:21.896: XGBoost_1_AutoML_6_20220211_154220 [XGBoost def_2] failed: water.exceptions.H2OModelBuilderIllegalArgumentException: Illegal argument(s) for XGBoost model: XGBoost_1_AutoML_6_20220211_154220_cv_1.  Details: ERRR on field: _response_column: Response contains missing values (NAs) - not supported by XGBoost.\n",
      "\n",
      "15:42:21.906: AutoML: starting GLM_1_AutoML_6_20220211_154220 model training\n",
      "15:42:21.915: _train param, Dropping bad and constant columns: [Customer ID, Loan ID]\n",
      "\n",
      "███████████████\n",
      "15:43:29.736: New leader: GLM_1_AutoML_6_20220211_154220, auc: 0.7433923073938888\n",
      "15:43:29.740: AutoML: starting GBM_1_AutoML_6_20220211_154220 model training\n",
      "15:43:29.769: _train param, Dropping bad and constant columns: [Customer ID, Loan ID]\n",
      "\n",
      "████████\n",
      "15:44:07.986: New leader: GBM_1_AutoML_6_20220211_154220, auc: 0.7653204355283812\n",
      "15:44:07.991: AutoML: starting StackedEnsemble_BestOfFamily_1_AutoML_6_20220211_154220 model training\n",
      "15:44:07.997: _train param, Dropping unused columns: [Customer ID, Loan ID]\n",
      "\n",
      "█\n",
      "15:44:14.84: New leader: StackedEnsemble_BestOfFamily_1_AutoML_6_20220211_154220, auc: 0.7664410867802438\n",
      "15:44:14.89: AutoML: starting XGBoost_2_AutoML_6_20220211_154220 model training\n",
      "15:44:14.100: _train param, Dropping bad and constant columns: [Customer ID, Loan ID]\n",
      "15:44:15.135: XGBoost_2_AutoML_6_20220211_154220 [XGBoost def_1] failed: water.exceptions.H2OModelBuilderIllegalArgumentException: Illegal argument(s) for XGBoost model: XGBoost_2_AutoML_6_20220211_154220_cv_1.  Details: ERRR on field: _response_column: Response contains missing values (NAs) - not supported by XGBoost.\n",
      "\n",
      "15:44:15.143: AutoML: starting DRF_1_AutoML_6_20220211_154220 model training\n",
      "15:44:15.152: _train param, Dropping bad and constant columns: [Customer ID, Loan ID]\n",
      "\n",
      "████████\n",
      "15:44:51.397: New leader: DRF_1_AutoML_6_20220211_154220, auc: 0.7763699069566031\n",
      "15:44:51.403: AutoML: starting GBM_2_AutoML_6_20220211_154220 model training\n",
      "15:44:51.410: _train param, Dropping bad and constant columns: [Customer ID, Loan ID]\n",
      "\n",
      "██████\n",
      "15:45:19.600: AutoML: starting GBM_3_AutoML_6_20220211_154220 model training\n",
      "15:45:19.614: _train param, Dropping bad and constant columns: [Customer ID, Loan ID]\n",
      "\n",
      "██████\n",
      "15:45:48.822: AutoML: starting GBM_4_AutoML_6_20220211_154220 model training\n",
      "15:45:48.828: _train param, Dropping bad and constant columns: [Customer ID, Loan ID]\n",
      "\n",
      "██████\n",
      "15:46:20.13: AutoML: starting StackedEnsemble_BestOfFamily_2_AutoML_6_20220211_154220 model training\n",
      "15:46:20.18: _train param, Dropping unused columns: [Customer ID, Loan ID]\n",
      "\n",
      "█\n",
      "15:46:27.67: New leader: StackedEnsemble_BestOfFamily_2_AutoML_6_20220211_154220, auc: 0.779193217843913\n",
      "15:46:27.71: AutoML: starting StackedEnsemble_AllModels_1_AutoML_6_20220211_154220 model training\n",
      "15:46:27.74: _train param, Dropping unused columns: [Customer ID, Loan ID]\n",
      "\n",
      "██\n",
      "15:46:34.142: New leader: StackedEnsemble_AllModels_1_AutoML_6_20220211_154220, auc: 0.7797212673547402\n",
      "15:46:34.145: AutoML: starting XGBoost_3_AutoML_6_20220211_154220 model training\n",
      "15:46:34.154: _train param, Dropping bad and constant columns: [Customer ID, Loan ID]\n",
      "\n",
      "\n",
      "15:46:35.185: XGBoost_3_AutoML_6_20220211_154220 [XGBoost def_3] failed: water.exceptions.H2OModelBuilderIllegalArgumentException: Illegal argument(s) for XGBoost model: XGBoost_3_AutoML_6_20220211_154220_cv_1.  Details: ERRR on field: _response_column: Response contains missing values (NAs) - not supported by XGBoost.\n",
      "\n",
      "15:46:35.188: AutoML: starting XRT_1_AutoML_6_20220211_154220 model training\n",
      "15:46:35.193: _train param, Dropping bad and constant columns: [Customer ID, Loan ID]\n",
      "\n",
      "███\n",
      "15:46:47.294: AutoML: starting GBM_5_AutoML_6_20220211_154220 model training\n",
      "15:46:47.299: _train param, Dropping bad and constant columns: [Customer ID, Loan ID]\n",
      "\n",
      "██\n",
      "15:46:58.405: AutoML: starting DeepLearning_1_AutoML_6_20220211_154220 model training\n",
      "15:46:58.410: _train param, Dropping bad and constant columns: [Customer ID, Loan ID]\n",
      "\n",
      "██\n",
      "15:47:07.475: AutoML: starting StackedEnsemble_BestOfFamily_3_AutoML_6_20220211_154220 model training\n",
      "15:47:07.477: _train param, Dropping unused columns: [Customer ID, Loan ID]\n",
      "\n",
      "█\n",
      "15:47:14.535: New leader: StackedEnsemble_BestOfFamily_3_AutoML_6_20220211_154220, auc: 0.7801806905064458\n",
      "15:47:14.539: AutoML: starting StackedEnsemble_AllModels_2_AutoML_6_20220211_154220 model training\n",
      "15:47:14.543: _train param, Dropping unused columns: [Customer ID, Loan ID]\n",
      "\n",
      "██| (done) 100%\n",
      "\n",
      "15:47:22.598: New leader: StackedEnsemble_AllModels_2_AutoML_6_20220211_154220, auc: 0.7806707220739665\n",
      "15:47:22.612: Actual modeling steps: [{GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {StackedEnsemble : [best_of_family_2 (2g, 5w), all_2 (2g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {GBM : [def_1 (3g, 10w)]}, {DeepLearning : [def_1 (3g, 10w)]}, {StackedEnsemble : [best_of_family_3 (3g, 5w), all_3 (3g, 10w)]}]\n",
      "15:47:22.613: AutoML build stopped: 2022.02.11 15:47:22.612\n",
      "15:47:22.613: AutoML build done: built 9 models\n",
      "15:47:22.614: AutoML duration:  5 min  1.782 sec\n",
      "\n",
      "Model Details\n",
      "=============\n",
      "H2OStackedEnsembleEstimator :  Stacked Ensemble\n",
      "Model Key:  StackedEnsemble_AllModels_2_AutoML_6_20220211_154220\n",
      "\n",
      "No model summary for this model\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.08727230038534711\n",
      "RMSE: 0.29541885583920857\n",
      "LogLoss: 0.2925481911749993\n",
      "Null degrees of freedom: 9868\n",
      "Residual degrees of freedom: 9861\n",
      "Null deviance: 10527.37156155715\n",
      "Residual deviance: 5774.316197412137\n",
      "AIC: 5790.316197412137\n",
      "AUC: 0.9665535992594944\n",
      "AUCPR: 0.9896455490053936\n",
      "Gini: 0.9331071985189887\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6964519784347294: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Charged Off</th>\n",
       "      <th>Fully Paid</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Charged Off</td>\n",
       "      <td>1772.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>(450.0/2222.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>333.0</td>\n",
       "      <td>7314.0</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>(333.0/7647.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>2105.0</td>\n",
       "      <td>7764.0</td>\n",
       "      <td>0.0793</td>\n",
       "      <td>(783.0/9869.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Charged Off  Fully Paid   Error             Rate\n",
       "0  Charged Off       1772.0       450.0  0.2025   (450.0/2222.0)\n",
       "1   Fully Paid        333.0      7314.0  0.0435   (333.0/7647.0)\n",
       "2        Total       2105.0      7764.0  0.0793   (783.0/9869.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.696452</td>\n",
       "      <td>0.949192</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.569225</td>\n",
       "      <td>0.970324</td>\n",
       "      <td>289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.744256</td>\n",
       "      <td>0.955739</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.697842</td>\n",
       "      <td>0.920661</td>\n",
       "      <td>223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.470698</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.716298</td>\n",
       "      <td>0.773105</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.747231</td>\n",
       "      <td>0.900540</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.744256</td>\n",
       "      <td>0.903143</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2222.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>6815.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2222.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.470698</td>\n",
       "      <td>7647.000000</td>\n",
       "      <td>326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.891199</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.470698</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>326.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold        value    idx\n",
       "0                        max f1   0.696452     0.949192  224.0\n",
       "1                        max f2   0.569225     0.970324  289.0\n",
       "2                  max f0point5   0.744256     0.955739  196.0\n",
       "3                  max accuracy   0.697842     0.920661  223.0\n",
       "4                 max precision   0.999999     1.000000    0.0\n",
       "5                    max recall   0.470698     1.000000  326.0\n",
       "6               max specificity   0.999999     1.000000    0.0\n",
       "7              max absolute_mcc   0.716298     0.773105  213.0\n",
       "8    max min_per_class_accuracy   0.747231     0.900540  194.0\n",
       "9   max mean_per_class_accuracy   0.744256     0.903143  196.0\n",
       "10                      max tns   0.999999  2222.000000    0.0\n",
       "11                      max fns   0.999999  6815.000000    0.0\n",
       "12                      max fps   0.000003  2222.000000  399.0\n",
       "13                      max tps   0.470698  7647.000000  326.0\n",
       "14                      max tnr   0.999999     1.000000    0.0\n",
       "15                      max fnr   0.999999     0.891199    0.0\n",
       "16                      max fpr   0.000003     1.000000  399.0\n",
       "17                      max tpr   0.470698     1.000000  326.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 77.49 %, avg score: 77.08 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010133</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013077</td>\n",
       "      <td>0.013077</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>0.013077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020164</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012946</td>\n",
       "      <td>0.026023</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>0.026023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030196</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012946</td>\n",
       "      <td>0.038970</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>0.038970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040227</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012946</td>\n",
       "      <td>0.051916</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>0.051916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050258</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012946</td>\n",
       "      <td>0.064862</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>0.064862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100517</td>\n",
       "      <td>9.994302e-01</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.064862</td>\n",
       "      <td>0.129724</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>0.129724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150674</td>\n",
       "      <td>9.348057e-01</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956578</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985511</td>\n",
       "      <td>0.064731</td>\n",
       "      <td>0.194455</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>0.194455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200932</td>\n",
       "      <td>9.135582e-01</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923547</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970012</td>\n",
       "      <td>0.064862</td>\n",
       "      <td>0.259317</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>0.259317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.301348</td>\n",
       "      <td>8.821687e-01</td>\n",
       "      <td>1.286665</td>\n",
       "      <td>1.289270</td>\n",
       "      <td>0.996973</td>\n",
       "      <td>0.897583</td>\n",
       "      <td>0.998991</td>\n",
       "      <td>0.945877</td>\n",
       "      <td>0.129201</td>\n",
       "      <td>0.388518</td>\n",
       "      <td>28.666459</td>\n",
       "      <td>28.926961</td>\n",
       "      <td>0.387168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.401763</td>\n",
       "      <td>8.562679e-01</td>\n",
       "      <td>1.285362</td>\n",
       "      <td>1.288293</td>\n",
       "      <td>0.995964</td>\n",
       "      <td>0.868934</td>\n",
       "      <td>0.998235</td>\n",
       "      <td>0.926646</td>\n",
       "      <td>0.129070</td>\n",
       "      <td>0.517589</td>\n",
       "      <td>28.536230</td>\n",
       "      <td>28.829303</td>\n",
       "      <td>0.514438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.502280</td>\n",
       "      <td>8.306344e-01</td>\n",
       "      <td>1.265853</td>\n",
       "      <td>1.283802</td>\n",
       "      <td>0.980847</td>\n",
       "      <td>0.843749</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.910057</td>\n",
       "      <td>0.127239</td>\n",
       "      <td>0.644828</td>\n",
       "      <td>26.585286</td>\n",
       "      <td>28.380228</td>\n",
       "      <td>0.633127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.602695</td>\n",
       "      <td>7.982943e-01</td>\n",
       "      <td>1.228061</td>\n",
       "      <td>1.274515</td>\n",
       "      <td>0.951564</td>\n",
       "      <td>0.815124</td>\n",
       "      <td>0.987559</td>\n",
       "      <td>0.894240</td>\n",
       "      <td>0.123316</td>\n",
       "      <td>0.768144</td>\n",
       "      <td>22.806145</td>\n",
       "      <td>27.451526</td>\n",
       "      <td>0.734841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.703111</td>\n",
       "      <td>7.562734e-01</td>\n",
       "      <td>1.152529</td>\n",
       "      <td>1.257094</td>\n",
       "      <td>0.893037</td>\n",
       "      <td>0.779593</td>\n",
       "      <td>0.974060</td>\n",
       "      <td>0.877867</td>\n",
       "      <td>0.115732</td>\n",
       "      <td>0.883876</td>\n",
       "      <td>15.252850</td>\n",
       "      <td>25.709361</td>\n",
       "      <td>0.802868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799068</td>\n",
       "      <td>6.832883e-01</td>\n",
       "      <td>0.823131</td>\n",
       "      <td>1.204981</td>\n",
       "      <td>0.637804</td>\n",
       "      <td>0.724100</td>\n",
       "      <td>0.933680</td>\n",
       "      <td>0.859401</td>\n",
       "      <td>0.078985</td>\n",
       "      <td>0.962861</td>\n",
       "      <td>-17.686889</td>\n",
       "      <td>20.498069</td>\n",
       "      <td>0.727488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899483</td>\n",
       "      <td>5.075427e-01</td>\n",
       "      <td>0.360735</td>\n",
       "      <td>1.110732</td>\n",
       "      <td>0.279516</td>\n",
       "      <td>0.610897</td>\n",
       "      <td>0.860651</td>\n",
       "      <td>0.831659</td>\n",
       "      <td>0.036223</td>\n",
       "      <td>0.999085</td>\n",
       "      <td>-63.926509</td>\n",
       "      <td>11.073178</td>\n",
       "      <td>0.442379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.406168e-07</td>\n",
       "      <td>0.009107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007056</td>\n",
       "      <td>0.225985</td>\n",
       "      <td>0.774851</td>\n",
       "      <td>0.770779</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-99.089314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010133     9.999999e-01  1.290571   \n",
       "1       2                  0.020164     9.999999e-01  1.290571   \n",
       "2       3                  0.030196     9.999999e-01  1.290571   \n",
       "3       4                  0.040227     9.999999e-01  1.290571   \n",
       "4       5                  0.050258     9.999999e-01  1.290571   \n",
       "5       6                  0.100517     9.994302e-01  1.290571   \n",
       "6       7                  0.150674     9.348057e-01  1.290571   \n",
       "7       8                  0.200932     9.135582e-01  1.290571   \n",
       "8       9                  0.301348     8.821687e-01  1.286665   \n",
       "9      10                  0.401763     8.562679e-01  1.285362   \n",
       "10     11                  0.502280     8.306344e-01  1.265853   \n",
       "11     12                  0.602695     7.982943e-01  1.228061   \n",
       "12     13                  0.703111     7.562734e-01  1.152529   \n",
       "13     14                  0.799068     6.832883e-01  0.823131   \n",
       "14     15                  0.899483     5.075427e-01  0.360735   \n",
       "15     16                  1.000000     1.406168e-07  0.009107   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.290571       1.000000  1.000000                  1.000000   \n",
       "1          1.290571       1.000000  1.000000                  1.000000   \n",
       "2          1.290571       1.000000  1.000000                  1.000000   \n",
       "3          1.290571       1.000000  1.000000                  1.000000   \n",
       "4          1.290571       1.000000  1.000000                  1.000000   \n",
       "5          1.290571       1.000000  0.999898                  1.000000   \n",
       "6          1.290571       1.000000  0.956578                  1.000000   \n",
       "7          1.290571       1.000000  0.923547                  1.000000   \n",
       "8          1.289270       0.996973  0.897583                  0.998991   \n",
       "9          1.288293       0.995964  0.868934                  0.998235   \n",
       "10         1.283802       0.980847  0.843749                  0.994755   \n",
       "11         1.274515       0.951564  0.815124                  0.987559   \n",
       "12         1.257094       0.893037  0.779593                  0.974060   \n",
       "13         1.204981       0.637804  0.724100                  0.933680   \n",
       "14         1.110732       0.279516  0.610897                  0.860651   \n",
       "15         1.000000       0.007056  0.225985                  0.774851   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n",
       "0           1.000000      0.013077                 0.013077  29.057147   \n",
       "1           1.000000      0.012946                 0.026023  29.057147   \n",
       "2           1.000000      0.012946                 0.038970  29.057147   \n",
       "3           1.000000      0.012946                 0.051916  29.057147   \n",
       "4           1.000000      0.012946                 0.064862  29.057147   \n",
       "5           0.999949      0.064862                 0.129724  29.057147   \n",
       "6           0.985511      0.064731                 0.194455  29.057147   \n",
       "7           0.970012      0.064862                 0.259317  29.057147   \n",
       "8           0.945877      0.129201                 0.388518  28.666459   \n",
       "9           0.926646      0.129070                 0.517589  28.536230   \n",
       "10          0.910057      0.127239                 0.644828  26.585286   \n",
       "11          0.894240      0.123316                 0.768144  22.806145   \n",
       "12          0.877867      0.115732                 0.883876  15.252850   \n",
       "13          0.859401      0.078985                 0.962861 -17.686889   \n",
       "14          0.831659      0.036223                 0.999085 -63.926509   \n",
       "15          0.770779      0.000915                 1.000000 -99.089314   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0         29.057147            0.013077  \n",
       "1         29.057147            0.026023  \n",
       "2         29.057147            0.038970  \n",
       "3         29.057147            0.051916  \n",
       "4         29.057147            0.064862  \n",
       "5         29.057147            0.129724  \n",
       "6         29.057147            0.194455  \n",
       "7         29.057147            0.259317  \n",
       "8         28.926961            0.387168  \n",
       "9         28.829303            0.514438  \n",
       "10        28.380228            0.633127  \n",
       "11        27.451526            0.734841  \n",
       "12        25.709361            0.802868  \n",
       "13        20.498069            0.727488  \n",
       "14        11.073178            0.442379  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.13235859234904712\n",
      "RMSE: 0.36381120426540897\n",
      "LogLoss: 0.409214155024947\n",
      "Null degrees of freedom: 80103\n",
      "Residual degrees of freedom: 80097\n",
      "Null deviance: 85761.4088420349\n",
      "Residual deviance: 65559.38134823671\n",
      "AIC: 65573.38134823671\n",
      "AUC: 0.7806707220739665\n",
      "AUCPR: 0.9207661355436089\n",
      "Gini: 0.561341444147933\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4170691696861526: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Charged Off</th>\n",
       "      <th>Fully Paid</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Charged Off</td>\n",
       "      <td>3821.0</td>\n",
       "      <td>14339.0</td>\n",
       "      <td>0.7896</td>\n",
       "      <td>(14339.0/18160.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>112.0</td>\n",
       "      <td>61832.0</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>(112.0/61944.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>3933.0</td>\n",
       "      <td>76171.0</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>(14451.0/80104.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Charged Off  Fully Paid   Error                Rate\n",
       "0  Charged Off       3821.0     14339.0  0.7896   (14339.0/18160.0)\n",
       "1   Fully Paid        112.0     61832.0  0.0018     (112.0/61944.0)\n",
       "2        Total       3933.0     76171.0  0.1804   (14451.0/80104.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.417069</td>\n",
       "      <td>0.895370</td>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.228960</td>\n",
       "      <td>0.955295</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.697226</td>\n",
       "      <td>0.854126</td>\n",
       "      <td>244.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.490715</td>\n",
       "      <td>0.819747</td>\n",
       "      <td>348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.228960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.296850</td>\n",
       "      <td>0.404644</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.781946</td>\n",
       "      <td>0.692511</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.786392</td>\n",
       "      <td>0.693833</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>18160.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>54395.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>18160.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.228960</td>\n",
       "      <td>61944.000000</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.878132</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.228960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.417069      0.895370  372.0\n",
       "1                        max f2   0.228960      0.955295  393.0\n",
       "2                  max f0point5   0.697226      0.854126  244.0\n",
       "3                  max accuracy   0.490715      0.819747  348.0\n",
       "4                 max precision   0.999985      1.000000    0.0\n",
       "5                    max recall   0.228960      1.000000  393.0\n",
       "6               max specificity   0.999985      1.000000    0.0\n",
       "7              max absolute_mcc   0.296850      0.404644  389.0\n",
       "8    max min_per_class_accuracy   0.781946      0.692511  170.0\n",
       "9   max mean_per_class_accuracy   0.786392      0.693833  166.0\n",
       "10                      max tns   0.999985  18160.000000    0.0\n",
       "11                      max fns   0.999985  54395.000000    0.0\n",
       "12                      max fps   0.000003  18160.000000  399.0\n",
       "13                      max tps   0.228960  61944.000000  393.0\n",
       "14                      max tnr   0.999985      1.000000    0.0\n",
       "15                      max fnr   0.999985      0.878132    0.0\n",
       "16                      max fpr   0.000003      1.000000  399.0\n",
       "17                      max tpr   0.228960      1.000000  393.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 77.33 %, avg score: 77.33 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015130</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.293168</td>\n",
       "      <td>1.293168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019566</td>\n",
       "      <td>0.019566</td>\n",
       "      <td>29.316802</td>\n",
       "      <td>29.316802</td>\n",
       "      <td>0.019566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.033569</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.293168</td>\n",
       "      <td>1.293168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023844</td>\n",
       "      <td>0.043410</td>\n",
       "      <td>29.316802</td>\n",
       "      <td>29.316802</td>\n",
       "      <td>0.043410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.060471</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.293168</td>\n",
       "      <td>1.293168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034789</td>\n",
       "      <td>0.078200</td>\n",
       "      <td>29.316802</td>\n",
       "      <td>29.316802</td>\n",
       "      <td>0.078200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.100519</td>\n",
       "      <td>9.995014e-01</td>\n",
       "      <td>1.293168</td>\n",
       "      <td>1.293168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.051789</td>\n",
       "      <td>0.129988</td>\n",
       "      <td>29.316802</td>\n",
       "      <td>29.316802</td>\n",
       "      <td>0.129988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.150779</td>\n",
       "      <td>9.247551e-01</td>\n",
       "      <td>1.250127</td>\n",
       "      <td>1.278821</td>\n",
       "      <td>0.966716</td>\n",
       "      <td>0.958173</td>\n",
       "      <td>0.988905</td>\n",
       "      <td>0.986036</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.192819</td>\n",
       "      <td>25.012666</td>\n",
       "      <td>27.882090</td>\n",
       "      <td>0.185440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.201039</td>\n",
       "      <td>8.996701e-01</td>\n",
       "      <td>1.191989</td>\n",
       "      <td>1.257113</td>\n",
       "      <td>0.921759</td>\n",
       "      <td>0.911280</td>\n",
       "      <td>0.972119</td>\n",
       "      <td>0.967347</td>\n",
       "      <td>0.059909</td>\n",
       "      <td>0.252728</td>\n",
       "      <td>19.198871</td>\n",
       "      <td>25.711285</td>\n",
       "      <td>0.228004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.301558</td>\n",
       "      <td>8.666497e-01</td>\n",
       "      <td>1.144932</td>\n",
       "      <td>1.219719</td>\n",
       "      <td>0.885370</td>\n",
       "      <td>0.882411</td>\n",
       "      <td>0.943203</td>\n",
       "      <td>0.939035</td>\n",
       "      <td>0.115088</td>\n",
       "      <td>0.367816</td>\n",
       "      <td>14.493229</td>\n",
       "      <td>21.971933</td>\n",
       "      <td>0.292265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.402065</td>\n",
       "      <td>8.384194e-01</td>\n",
       "      <td>1.112950</td>\n",
       "      <td>1.193030</td>\n",
       "      <td>0.860638</td>\n",
       "      <td>0.852263</td>\n",
       "      <td>0.922563</td>\n",
       "      <td>0.917344</td>\n",
       "      <td>0.111859</td>\n",
       "      <td>0.479675</td>\n",
       "      <td>11.295010</td>\n",
       "      <td>19.302951</td>\n",
       "      <td>0.342340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.502584</td>\n",
       "      <td>8.114166e-01</td>\n",
       "      <td>1.077961</td>\n",
       "      <td>1.170015</td>\n",
       "      <td>0.833582</td>\n",
       "      <td>0.824892</td>\n",
       "      <td>0.904767</td>\n",
       "      <td>0.898853</td>\n",
       "      <td>0.108356</td>\n",
       "      <td>0.588031</td>\n",
       "      <td>7.796122</td>\n",
       "      <td>17.001528</td>\n",
       "      <td>0.376908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.603103</td>\n",
       "      <td>7.825984e-01</td>\n",
       "      <td>1.023999</td>\n",
       "      <td>1.145679</td>\n",
       "      <td>0.791853</td>\n",
       "      <td>0.797213</td>\n",
       "      <td>0.885947</td>\n",
       "      <td>0.881913</td>\n",
       "      <td>0.102932</td>\n",
       "      <td>0.690963</td>\n",
       "      <td>2.399892</td>\n",
       "      <td>14.567872</td>\n",
       "      <td>0.387549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.702587</td>\n",
       "      <td>7.476005e-01</td>\n",
       "      <td>0.977544</td>\n",
       "      <td>1.121872</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>0.765763</td>\n",
       "      <td>0.867537</td>\n",
       "      <td>0.865466</td>\n",
       "      <td>0.097249</td>\n",
       "      <td>0.788212</td>\n",
       "      <td>-2.245650</td>\n",
       "      <td>12.187151</td>\n",
       "      <td>0.377694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.801034</td>\n",
       "      <td>7.001732e-01</td>\n",
       "      <td>0.916172</td>\n",
       "      <td>1.096591</td>\n",
       "      <td>0.708471</td>\n",
       "      <td>0.725608</td>\n",
       "      <td>0.847988</td>\n",
       "      <td>0.848278</td>\n",
       "      <td>0.090194</td>\n",
       "      <td>0.878406</td>\n",
       "      <td>-8.382834</td>\n",
       "      <td>9.659101</td>\n",
       "      <td>0.341292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.899481</td>\n",
       "      <td>6.016914e-01</td>\n",
       "      <td>0.848119</td>\n",
       "      <td>1.069396</td>\n",
       "      <td>0.655846</td>\n",
       "      <td>0.659279</td>\n",
       "      <td>0.826958</td>\n",
       "      <td>0.827592</td>\n",
       "      <td>0.083495</td>\n",
       "      <td>0.961901</td>\n",
       "      <td>-15.188118</td>\n",
       "      <td>6.939604</td>\n",
       "      <td>0.275337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.400000e-07</td>\n",
       "      <td>0.379021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.293095</td>\n",
       "      <td>0.287395</td>\n",
       "      <td>0.773295</td>\n",
       "      <td>0.773292</td>\n",
       "      <td>0.038099</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-62.097907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.015130     9.999999e-01  1.293168   \n",
       "1       2                  0.033569     9.999999e-01  1.293168   \n",
       "2       3                  0.060471     9.999999e-01  1.293168   \n",
       "3       4                  0.100519     9.995014e-01  1.293168   \n",
       "4       5                  0.150779     9.247551e-01  1.250127   \n",
       "5       6                  0.201039     8.996701e-01  1.191989   \n",
       "6       7                  0.301558     8.666497e-01  1.144932   \n",
       "7       8                  0.402065     8.384194e-01  1.112950   \n",
       "8       9                  0.502584     8.114166e-01  1.077961   \n",
       "9      10                  0.603103     7.825984e-01  1.023999   \n",
       "10     11                  0.702587     7.476005e-01  0.977544   \n",
       "11     12                  0.801034     7.001732e-01  0.916172   \n",
       "12     13                  0.899481     6.016914e-01  0.848119   \n",
       "13     14                  1.000000     1.400000e-07  0.379021   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.293168       1.000000  1.000000                  1.000000   \n",
       "1          1.293168       1.000000  1.000000                  1.000000   \n",
       "2          1.293168       1.000000  1.000000                  1.000000   \n",
       "3          1.293168       1.000000  0.999917                  1.000000   \n",
       "4          1.278821       0.966716  0.958173                  0.988905   \n",
       "5          1.257113       0.921759  0.911280                  0.972119   \n",
       "6          1.219719       0.885370  0.882411                  0.943203   \n",
       "7          1.193030       0.860638  0.852263                  0.922563   \n",
       "8          1.170015       0.833582  0.824892                  0.904767   \n",
       "9          1.145679       0.791853  0.797213                  0.885947   \n",
       "10         1.121872       0.755929  0.765763                  0.867537   \n",
       "11         1.096591       0.708471  0.725608                  0.847988   \n",
       "12         1.069396       0.655846  0.659279                  0.826958   \n",
       "13         1.000000       0.293095  0.287395                  0.773295   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n",
       "0           1.000000      0.019566                 0.019566  29.316802   \n",
       "1           1.000000      0.023844                 0.043410  29.316802   \n",
       "2           1.000000      0.034789                 0.078200  29.316802   \n",
       "3           0.999967      0.051789                 0.129988  29.316802   \n",
       "4           0.986036      0.062831                 0.192819  25.012666   \n",
       "5           0.967347      0.059909                 0.252728  19.198871   \n",
       "6           0.939035      0.115088                 0.367816  14.493229   \n",
       "7           0.917344      0.111859                 0.479675  11.295010   \n",
       "8           0.898853      0.108356                 0.588031   7.796122   \n",
       "9           0.881913      0.102932                 0.690963   2.399892   \n",
       "10          0.865466      0.097249                 0.788212  -2.245650   \n",
       "11          0.848278      0.090194                 0.878406  -8.382834   \n",
       "12          0.827592      0.083495                 0.961901 -15.188118   \n",
       "13          0.773292      0.038099                 1.000000 -62.097907   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0         29.316802            0.019566  \n",
       "1         29.316802            0.043410  \n",
       "2         29.316802            0.078200  \n",
       "3         29.316802            0.129988  \n",
       "4         27.882090            0.185440  \n",
       "5         25.711285            0.228004  \n",
       "6         21.971933            0.292265  \n",
       "7         19.302951            0.342340  \n",
       "8         17.001528            0.376908  \n",
       "9         14.567872            0.387549  \n",
       "10        12.187151            0.377694  \n",
       "11         9.659101            0.341292  \n",
       "12         6.939604            0.275337  \n",
       "13         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up AutoML\n",
    "aml = H2OAutoML(seed=1,max_runtime_secs=run_time,verbosity=\"info\")\n",
    "aml.train(x=X,y=target,training_frame=df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Loan Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5q/w_y2sfjj2bv130sh86slry7r0000gq/T/ipykernel_6057/568088017.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaderboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'aml' is not defined"
     ]
    }
   ],
   "source": [
    "print(aml.leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('Loan ID')\n",
    "df=df.drop('Customer ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na_omit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 80/20 train/test splie\n",
    "pct_rows=0.80\n",
    "df_train, df_test = df.split_frame([pct_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the features and target\n",
    "X=df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Current Loan Amount', 'Term', 'Credit Score', 'Annual Income', 'Years in current job', 'Home Ownership', 'Purpose', 'Monthly Debt', 'Years of Credit History', 'Months since last delinquent', 'Number of Open Accounts', 'Number of Credit Problems', 'Current Credit Balance', 'Maximum Open Credit', 'Bankruptcies', 'Tax Liens']\n"
     ]
    }
   ],
   "source": [
    "# Set target and predictor variables\n",
    "target ='Loan Status'\n",
    "X.remove(target)\n",
    "df_train[target]=df_train[target].asfactor()\n",
    "df_test[target]=df_test[target].asfactor()\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "15:52:16.91: Project: AutoML_8_20220211_155216\n",
      "15:52:16.92: 5-fold cross-validation will be used.\n",
      "15:52:16.93: Setting stopping tolerance adaptively based on the training frame: 0.005743333704607962\n",
      "15:52:16.93: Build control seed: 1\n",
      "15:52:16.95: training frame: Frame key: AutoML_8_20220211_155216_training_py_40_sid_9826    cols: 17    rows: 30316  chunks: 32    size: 1376936  checksum: 5949230540301545051\n",
      "15:52:16.95: validation frame: NULL\n",
      "15:52:16.95: leaderboard frame: NULL\n",
      "15:52:16.95: blending frame: NULL\n",
      "15:52:16.95: response column: Loan Status\n",
      "15:52:16.95: fold column: null\n",
      "15:52:16.95: weights column: null\n",
      "15:52:16.97: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_xgboost (6g, 10w), best_of_family_gbm (6g, 10w), all_xgboost (7g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]\n",
      "15:52:16.103: Disabling Algo: StackedEnsemble as requested by the user.\n",
      "15:52:16.105: AutoML job created: 2022.02.11 15:52:16.87\n",
      "15:52:16.107: AutoML build started: 2022.02.11 15:52:16.107\n",
      "15:52:16.115: AutoML: starting XGBoost_1_AutoML_8_20220211_155216 model training\n",
      "\n",
      "████████\n",
      "15:52:48.485: New leader: XGBoost_1_AutoML_8_20220211_155216, auc: 0.7597437478249296\n",
      "15:52:48.488: AutoML: starting GLM_1_AutoML_8_20220211_155216 model training\n",
      "\n",
      "███\n",
      "15:53:05.588: AutoML: starting GBM_1_AutoML_8_20220211_155216 model training\n",
      "\n",
      "███\n",
      "15:53:19.659: New leader: GBM_1_AutoML_8_20220211_155216, auc: 0.7794757640415607\n",
      "15:53:19.660: Skipping StackedEnsemble 'best_of_family_1' due to the exclude_algos option or it is already trained.\n",
      "15:53:19.660: AutoML: starting XGBoost_2_AutoML_8_20220211_155216 model training\n",
      "\n",
      "█████\n",
      "15:53:43.800: AutoML: starting DRF_1_AutoML_8_20220211_155216 model training\n",
      "\n",
      "████\n",
      "15:54:03.935: New leader: DRF_1_AutoML_8_20220211_155216, auc: 0.8053609431720982\n",
      "15:54:03.938: AutoML: starting GBM_2_AutoML_8_20220211_155216 model training\n",
      "\n",
      "███\n",
      "15:54:17.131: AutoML: starting GBM_3_AutoML_8_20220211_155216 model training\n",
      "\n",
      "██\n",
      "15:54:30.227: AutoML: starting GBM_4_AutoML_8_20220211_155216 model training\n",
      "\n",
      "███\n",
      "15:54:44.324: Skipping StackedEnsemble 'best_of_family_2' due to the exclude_algos option or it is already trained.\n",
      "15:54:44.324: Skipping StackedEnsemble 'all_2' due to the exclude_algos option or it is already trained.\n",
      "15:54:44.326: AutoML: starting XGBoost_3_AutoML_8_20220211_155216 model training\n",
      "\n",
      "████\n",
      "15:55:01.473: AutoML: starting XRT_1_AutoML_8_20220211_155216 model training\n",
      "\n",
      "████\n",
      "15:55:21.606: AutoML: starting GBM_5_AutoML_8_20220211_155216 model training\n",
      "\n",
      "██\n",
      "15:55:32.693: AutoML: starting DeepLearning_1_AutoML_8_20220211_155216 model training\n",
      "\n",
      "██\n",
      "15:55:40.783: Skipping StackedEnsemble 'best_of_family_3' due to the exclude_algos option or it is already trained.\n",
      "15:55:40.786: Skipping StackedEnsemble 'all_3' due to the exclude_algos option or it is already trained.\n",
      "15:55:40.791: AutoML: starting XGBoost_grid_1_AutoML_8_20220211_155216 hyperparameter search\n",
      "\n",
      "██████████\n",
      "15:56:31.103: AutoML: starting GBM_grid_1_AutoML_8_20220211_155216 hyperparameter search\n",
      "\n",
      "███████\n",
      "15:57:02.345: AutoML: starting DeepLearning_grid_1_AutoML_8_20220211_155216 hyperparameter search\n",
      "\n",
      "███| (done) 100%\n",
      "\n",
      "15:57:17.439: Actual modeling steps: [{XGBoost : [def_2 (1g, 10w)]}, {GLM : [def_1 (1g, 10w)]}, {GBM : [def_5 (1g, 10w)]}, {XGBoost : [def_1 (2g, 10w)]}, {DRF : [def_1 (2g, 10w)]}, {GBM : [def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w)]}, {XGBoost : [def_3 (3g, 10w)]}, {DRF : [XRT (3g, 10w)]}, {GBM : [def_1 (3g, 10w)]}, {DeepLearning : [def_1 (3g, 10w)]}, {XGBoost : [grid_1 (4g, 90w)]}, {GBM : [grid_1 (4g, 60w)]}, {DeepLearning : [grid_1 (4g, 30w)]}]\n",
      "15:57:17.441: AutoML build stopped: 2022.02.11 15:57:17.439\n",
      "15:57:17.441: AutoML build done: built 17 models\n",
      "15:57:17.441: AutoML duration:  5 min  1.332 sec\n",
      "\n",
      "Model Details\n",
      "=============\n",
      "H2ORandomForestEstimator :  Distributed Random Forest\n",
      "Model Key:  DRF_1_AutoML_8_20220211_155216\n",
      "\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>number_of_internal_trees</th>\n",
       "      <th>model_size_in_bytes</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>min_leaves</th>\n",
       "      <th>max_leaves</th>\n",
       "      <th>mean_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1364253.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>2536.0</td>\n",
       "      <td>2162.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n",
       "0               50.0                      50.0            1364253.0   \n",
       "\n",
       "   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n",
       "0       20.0       20.0        20.0      1689.0      2536.0      2162.28  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.11681543562180387\n",
      "RMSE: 0.3417827316027009\n",
      "LogLoss: 0.37119178672634245\n",
      "Mean Per-Class Error: 0.36899600438442137\n",
      "AUC: 0.7989703494631009\n",
      "AUCPR: 0.9345480912440519\n",
      "Gini: 0.5979406989262017\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.33373530464943013: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Charged Off</th>\n",
       "      <th>Fully Paid</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Charged Off</td>\n",
       "      <td>1637.0</td>\n",
       "      <td>4602.0</td>\n",
       "      <td>0.7376</td>\n",
       "      <td>(4602.0/6239.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>9.0</td>\n",
       "      <td>24068.0</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>(9.0/24077.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>1646.0</td>\n",
       "      <td>28670.0</td>\n",
       "      <td>0.1521</td>\n",
       "      <td>(4611.0/30316.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Charged Off  Fully Paid   Error               Rate\n",
       "0  Charged Off       1637.0      4602.0  0.7376    (4602.0/6239.0)\n",
       "1   Fully Paid          9.0     24068.0  0.0004      (9.0/24077.0)\n",
       "2        Total       1646.0     28670.0  0.1521   (4611.0/30316.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.333735</td>\n",
       "      <td>0.912583</td>\n",
       "      <td>365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.211706</td>\n",
       "      <td>0.963088</td>\n",
       "      <td>373.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.692224</td>\n",
       "      <td>0.874945</td>\n",
       "      <td>247.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.333735</td>\n",
       "      <td>0.847902</td>\n",
       "      <td>365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.211706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>373.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.211706</td>\n",
       "      <td>0.467517</td>\n",
       "      <td>373.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.812510</td>\n",
       "      <td>0.710370</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.808271</td>\n",
       "      <td>0.712032</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>6239.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>20479.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6239.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.211706</td>\n",
       "      <td>24077.000000</td>\n",
       "      <td>373.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.850563</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.211706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>373.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.333735      0.912583  365.0\n",
       "1                        max f2   0.211706      0.963088  373.0\n",
       "2                  max f0point5   0.692224      0.874945  247.0\n",
       "3                  max accuracy   0.333735      0.847902  365.0\n",
       "4                 max precision   0.999997      1.000000    0.0\n",
       "5                    max recall   0.211706      1.000000  373.0\n",
       "6               max specificity   0.999997      1.000000    0.0\n",
       "7              max absolute_mcc   0.211706      0.467517  373.0\n",
       "8    max min_per_class_accuracy   0.812510      0.710370  155.0\n",
       "9   max mean_per_class_accuracy   0.808271      0.712032  158.0\n",
       "10                      max tns   0.999997   6239.000000    0.0\n",
       "11                      max fns   0.999997  20479.000000    0.0\n",
       "12                      max fps   0.000000   6239.000000  399.0\n",
       "13                      max tps   0.211706  24077.000000  373.0\n",
       "14                      max tnr   0.999997      1.000000    0.0\n",
       "15                      max fnr   0.999997      0.850563    0.0\n",
       "16                      max fpr   0.000000      1.000000  399.0\n",
       "17                      max tpr   0.211706      1.000000  373.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 79.42 %, avg score: 79.87 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.118254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.259127</td>\n",
       "      <td>1.259127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148897</td>\n",
       "      <td>0.148897</td>\n",
       "      <td>25.912697</td>\n",
       "      <td>25.912697</td>\n",
       "      <td>0.148897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.150020</td>\n",
       "      <td>0.967785</td>\n",
       "      <td>1.206827</td>\n",
       "      <td>1.248053</td>\n",
       "      <td>0.958463</td>\n",
       "      <td>0.981937</td>\n",
       "      <td>0.991205</td>\n",
       "      <td>0.996175</td>\n",
       "      <td>0.038335</td>\n",
       "      <td>0.187233</td>\n",
       "      <td>20.682678</td>\n",
       "      <td>24.805285</td>\n",
       "      <td>0.180821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.200026</td>\n",
       "      <td>0.943467</td>\n",
       "      <td>1.176902</td>\n",
       "      <td>1.230265</td>\n",
       "      <td>0.934697</td>\n",
       "      <td>0.954232</td>\n",
       "      <td>0.977078</td>\n",
       "      <td>0.985689</td>\n",
       "      <td>0.058853</td>\n",
       "      <td>0.246085</td>\n",
       "      <td>17.690166</td>\n",
       "      <td>23.026505</td>\n",
       "      <td>0.223806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.300007</td>\n",
       "      <td>0.910914</td>\n",
       "      <td>1.155273</td>\n",
       "      <td>1.205273</td>\n",
       "      <td>0.917519</td>\n",
       "      <td>0.926229</td>\n",
       "      <td>0.957229</td>\n",
       "      <td>0.965874</td>\n",
       "      <td>0.115504</td>\n",
       "      <td>0.361590</td>\n",
       "      <td>15.527288</td>\n",
       "      <td>20.527316</td>\n",
       "      <td>0.299240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.400020</td>\n",
       "      <td>0.881562</td>\n",
       "      <td>1.112533</td>\n",
       "      <td>1.182086</td>\n",
       "      <td>0.883575</td>\n",
       "      <td>0.895820</td>\n",
       "      <td>0.938814</td>\n",
       "      <td>0.948359</td>\n",
       "      <td>0.111268</td>\n",
       "      <td>0.472858</td>\n",
       "      <td>11.253336</td>\n",
       "      <td>18.208630</td>\n",
       "      <td>0.353929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.852442</td>\n",
       "      <td>1.077175</td>\n",
       "      <td>1.161108</td>\n",
       "      <td>0.855493</td>\n",
       "      <td>0.867074</td>\n",
       "      <td>0.922153</td>\n",
       "      <td>0.932105</td>\n",
       "      <td>0.107696</td>\n",
       "      <td>0.580554</td>\n",
       "      <td>7.717460</td>\n",
       "      <td>16.110811</td>\n",
       "      <td>0.391421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.600013</td>\n",
       "      <td>0.820788</td>\n",
       "      <td>1.050241</td>\n",
       "      <td>1.142628</td>\n",
       "      <td>0.834103</td>\n",
       "      <td>0.837020</td>\n",
       "      <td>0.907477</td>\n",
       "      <td>0.916256</td>\n",
       "      <td>0.105038</td>\n",
       "      <td>0.685592</td>\n",
       "      <td>5.024146</td>\n",
       "      <td>14.262830</td>\n",
       "      <td>0.415837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>0.782064</td>\n",
       "      <td>0.998245</td>\n",
       "      <td>1.122006</td>\n",
       "      <td>0.792808</td>\n",
       "      <td>0.802170</td>\n",
       "      <td>0.891098</td>\n",
       "      <td>0.899961</td>\n",
       "      <td>0.099805</td>\n",
       "      <td>0.785397</td>\n",
       "      <td>-0.175450</td>\n",
       "      <td>12.200608</td>\n",
       "      <td>0.414985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.800007</td>\n",
       "      <td>0.725193</td>\n",
       "      <td>0.936040</td>\n",
       "      <td>1.098757</td>\n",
       "      <td>0.743404</td>\n",
       "      <td>0.755499</td>\n",
       "      <td>0.872634</td>\n",
       "      <td>0.881901</td>\n",
       "      <td>0.093616</td>\n",
       "      <td>0.879013</td>\n",
       "      <td>-6.396036</td>\n",
       "      <td>9.875740</td>\n",
       "      <td>0.383902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.899987</td>\n",
       "      <td>0.612980</td>\n",
       "      <td>0.864066</td>\n",
       "      <td>1.072685</td>\n",
       "      <td>0.686242</td>\n",
       "      <td>0.678375</td>\n",
       "      <td>0.851928</td>\n",
       "      <td>0.859291</td>\n",
       "      <td>0.086390</td>\n",
       "      <td>0.965403</td>\n",
       "      <td>-13.593398</td>\n",
       "      <td>7.268536</td>\n",
       "      <td>0.317863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345928</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.274736</td>\n",
       "      <td>0.253299</td>\n",
       "      <td>0.794201</td>\n",
       "      <td>0.798684</td>\n",
       "      <td>0.034597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-65.407231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.118254         1.000000  1.259127   \n",
       "1       2                  0.150020         0.967785  1.206827   \n",
       "2       3                  0.200026         0.943467  1.176902   \n",
       "3       4                  0.300007         0.910914  1.155273   \n",
       "4       5                  0.400020         0.881562  1.112533   \n",
       "5       6                  0.500000         0.852442  1.077175   \n",
       "6       7                  0.600013         0.820788  1.050241   \n",
       "7       8                  0.699993         0.782064  0.998245   \n",
       "8       9                  0.800007         0.725193  0.936040   \n",
       "9      10                  0.899987         0.612980  0.864066   \n",
       "10     11                  1.000000         0.000000  0.345928   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.259127       1.000000  1.000000                  1.000000   \n",
       "1          1.248053       0.958463  0.981937                  0.991205   \n",
       "2          1.230265       0.934697  0.954232                  0.977078   \n",
       "3          1.205273       0.917519  0.926229                  0.957229   \n",
       "4          1.182086       0.883575  0.895820                  0.938814   \n",
       "5          1.161108       0.855493  0.867074                  0.922153   \n",
       "6          1.142628       0.834103  0.837020                  0.907477   \n",
       "7          1.122006       0.792808  0.802170                  0.891098   \n",
       "8          1.098757       0.743404  0.755499                  0.872634   \n",
       "9          1.072685       0.686242  0.678375                  0.851928   \n",
       "10         1.000000       0.274736  0.253299                  0.794201   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n",
       "0           1.000000      0.148897                 0.148897  25.912697   \n",
       "1           0.996175      0.038335                 0.187233  20.682678   \n",
       "2           0.985689      0.058853                 0.246085  17.690166   \n",
       "3           0.965874      0.115504                 0.361590  15.527288   \n",
       "4           0.948359      0.111268                 0.472858  11.253336   \n",
       "5           0.932105      0.107696                 0.580554   7.717460   \n",
       "6           0.916256      0.105038                 0.685592   5.024146   \n",
       "7           0.899961      0.099805                 0.785397  -0.175450   \n",
       "8           0.881901      0.093616                 0.879013  -6.396036   \n",
       "9           0.859291      0.086390                 0.965403 -13.593398   \n",
       "10          0.798684      0.034597                 1.000000 -65.407231   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0         25.912697            0.148897  \n",
       "1         24.805285            0.180821  \n",
       "2         23.026505            0.223806  \n",
       "3         20.527316            0.299240  \n",
       "4         18.208630            0.353929  \n",
       "5         16.110811            0.391421  \n",
       "6         14.262830            0.415837  \n",
       "7         12.200608            0.414985  \n",
       "8          9.875740            0.383902  \n",
       "9          7.268536            0.317863  \n",
       "10         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.11587111598844034\n",
      "RMSE: 0.34039846648955446\n",
      "LogLoss: 0.3671609676597733\n",
      "Mean Per-Class Error: 0.36649057892832115\n",
      "AUC: 0.8053609431720982\n",
      "AUCPR: 0.9378867528434499\n",
      "Gini: 0.6107218863441963\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47729287940594883: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Charged Off</th>\n",
       "      <th>Fully Paid</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Charged Off</td>\n",
       "      <td>1675.0</td>\n",
       "      <td>4564.0</td>\n",
       "      <td>0.7315</td>\n",
       "      <td>(4564.0/6239.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>35.0</td>\n",
       "      <td>24042.0</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>(35.0/24077.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>28606.0</td>\n",
       "      <td>0.1517</td>\n",
       "      <td>(4599.0/30316.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Charged Off  Fully Paid   Error               Rate\n",
       "0  Charged Off       1675.0      4564.0  0.7315    (4564.0/6239.0)\n",
       "1   Fully Paid         35.0     24042.0  0.0015     (35.0/24077.0)\n",
       "2        Total       1710.0     28606.0  0.1517   (4599.0/30316.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.477293</td>\n",
       "      <td>0.912704</td>\n",
       "      <td>367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.355358</td>\n",
       "      <td>0.963103</td>\n",
       "      <td>383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.721480</td>\n",
       "      <td>0.874726</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.477293</td>\n",
       "      <td>0.848298</td>\n",
       "      <td>367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.355358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.477293</td>\n",
       "      <td>0.467923</td>\n",
       "      <td>367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.811178</td>\n",
       "      <td>0.711426</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.801411</td>\n",
       "      <td>0.714019</td>\n",
       "      <td>186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>6239.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>21446.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>6239.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.355358</td>\n",
       "      <td>24077.000000</td>\n",
       "      <td>383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.890726</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.355358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>383.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.477293      0.912704  367.0\n",
       "1                        max f2   0.355358      0.963103  383.0\n",
       "2                  max f0point5   0.721480      0.874726  253.0\n",
       "3                  max accuracy   0.477293      0.848298  367.0\n",
       "4                 max precision   0.999995      1.000000    0.0\n",
       "5                    max recall   0.355358      1.000000  383.0\n",
       "6               max specificity   0.999995      1.000000    0.0\n",
       "7              max absolute_mcc   0.477293      0.467923  367.0\n",
       "8    max min_per_class_accuracy   0.811178      0.711426  176.0\n",
       "9   max mean_per_class_accuracy   0.801411      0.714019  186.0\n",
       "10                      max tns   0.999995   6239.000000    0.0\n",
       "11                      max fns   0.999995  21446.000000    0.0\n",
       "12                      max fps   0.000003   6239.000000  399.0\n",
       "13                      max tps   0.355358  24077.000000  383.0\n",
       "14                      max tnr   0.999995      1.000000    0.0\n",
       "15                      max fnr   0.999995      0.890726    0.0\n",
       "16                      max fpr   0.000003      1.000000  399.0\n",
       "17                      max tpr   0.355358      1.000000  383.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 79.42 %, avg score: 79.77 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.085038</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.259127</td>\n",
       "      <td>1.259127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.107073</td>\n",
       "      <td>0.107073</td>\n",
       "      <td>25.912697</td>\n",
       "      <td>25.912697</td>\n",
       "      <td>0.107073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.100310</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>1.259127</td>\n",
       "      <td>1.259127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999723</td>\n",
       "      <td>0.019230</td>\n",
       "      <td>0.126303</td>\n",
       "      <td>25.912697</td>\n",
       "      <td>25.912697</td>\n",
       "      <td>0.126303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.150020</td>\n",
       "      <td>0.955069</td>\n",
       "      <td>1.247430</td>\n",
       "      <td>1.255251</td>\n",
       "      <td>0.990710</td>\n",
       "      <td>0.974765</td>\n",
       "      <td>0.996922</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.062009</td>\n",
       "      <td>0.188312</td>\n",
       "      <td>24.742970</td>\n",
       "      <td>25.525103</td>\n",
       "      <td>0.186069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.200026</td>\n",
       "      <td>0.927872</td>\n",
       "      <td>1.190191</td>\n",
       "      <td>1.238986</td>\n",
       "      <td>0.945251</td>\n",
       "      <td>0.939489</td>\n",
       "      <td>0.984004</td>\n",
       "      <td>0.978462</td>\n",
       "      <td>0.059517</td>\n",
       "      <td>0.247830</td>\n",
       "      <td>19.019060</td>\n",
       "      <td>23.898592</td>\n",
       "      <td>0.232283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.300007</td>\n",
       "      <td>0.897786</td>\n",
       "      <td>1.159012</td>\n",
       "      <td>1.212334</td>\n",
       "      <td>0.920488</td>\n",
       "      <td>0.912138</td>\n",
       "      <td>0.962837</td>\n",
       "      <td>0.956359</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.363708</td>\n",
       "      <td>15.901163</td>\n",
       "      <td>21.233368</td>\n",
       "      <td>0.309533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.400020</td>\n",
       "      <td>0.871633</td>\n",
       "      <td>1.117517</td>\n",
       "      <td>1.188627</td>\n",
       "      <td>0.887533</td>\n",
       "      <td>0.884343</td>\n",
       "      <td>0.944009</td>\n",
       "      <td>0.938353</td>\n",
       "      <td>0.111766</td>\n",
       "      <td>0.475475</td>\n",
       "      <td>11.751671</td>\n",
       "      <td>18.862749</td>\n",
       "      <td>0.366643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.847808</td>\n",
       "      <td>1.079667</td>\n",
       "      <td>1.166840</td>\n",
       "      <td>0.857473</td>\n",
       "      <td>0.859906</td>\n",
       "      <td>0.926705</td>\n",
       "      <td>0.922667</td>\n",
       "      <td>0.107945</td>\n",
       "      <td>0.583420</td>\n",
       "      <td>7.966710</td>\n",
       "      <td>16.683972</td>\n",
       "      <td>0.405346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.600013</td>\n",
       "      <td>0.818713</td>\n",
       "      <td>1.036537</td>\n",
       "      <td>1.145120</td>\n",
       "      <td>0.823219</td>\n",
       "      <td>0.833685</td>\n",
       "      <td>0.909456</td>\n",
       "      <td>0.907835</td>\n",
       "      <td>0.103667</td>\n",
       "      <td>0.687087</td>\n",
       "      <td>3.653724</td>\n",
       "      <td>14.512025</td>\n",
       "      <td>0.423103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>0.783165</td>\n",
       "      <td>0.988691</td>\n",
       "      <td>1.122777</td>\n",
       "      <td>0.785219</td>\n",
       "      <td>0.801526</td>\n",
       "      <td>0.891711</td>\n",
       "      <td>0.892651</td>\n",
       "      <td>0.098850</td>\n",
       "      <td>0.785937</td>\n",
       "      <td>-1.130908</td>\n",
       "      <td>12.277742</td>\n",
       "      <td>0.417609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.800007</td>\n",
       "      <td>0.732873</td>\n",
       "      <td>0.938116</td>\n",
       "      <td>1.099692</td>\n",
       "      <td>0.745053</td>\n",
       "      <td>0.759444</td>\n",
       "      <td>0.873376</td>\n",
       "      <td>0.875998</td>\n",
       "      <td>0.093824</td>\n",
       "      <td>0.879761</td>\n",
       "      <td>-6.188396</td>\n",
       "      <td>9.969189</td>\n",
       "      <td>0.387534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.899987</td>\n",
       "      <td>0.638836</td>\n",
       "      <td>0.854096</td>\n",
       "      <td>1.072408</td>\n",
       "      <td>0.678324</td>\n",
       "      <td>0.694041</td>\n",
       "      <td>0.851708</td>\n",
       "      <td>0.855784</td>\n",
       "      <td>0.085393</td>\n",
       "      <td>0.965153</td>\n",
       "      <td>-14.590398</td>\n",
       "      <td>7.240846</td>\n",
       "      <td>0.316652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.348419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276715</td>\n",
       "      <td>0.274597</td>\n",
       "      <td>0.794201</td>\n",
       "      <td>0.797658</td>\n",
       "      <td>0.034847</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-65.158063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.085038         1.000000  1.259127   \n",
       "1       2                  0.100310         0.996000  1.259127   \n",
       "2       3                  0.150020         0.955069  1.247430   \n",
       "3       4                  0.200026         0.927872  1.190191   \n",
       "4       5                  0.300007         0.897786  1.159012   \n",
       "5       6                  0.400020         0.871633  1.117517   \n",
       "6       7                  0.500000         0.847808  1.079667   \n",
       "7       8                  0.600013         0.818713  1.036537   \n",
       "8       9                  0.699993         0.783165  0.988691   \n",
       "9      10                  0.800007         0.732873  0.938116   \n",
       "10     11                  0.899987         0.638836  0.854096   \n",
       "11     12                  1.000000         0.000000  0.348419   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.259127       1.000000  1.000000                  1.000000   \n",
       "1          1.259127       1.000000  0.998183                  1.000000   \n",
       "2          1.255251       0.990710  0.974765                  0.996922   \n",
       "3          1.238986       0.945251  0.939489                  0.984004   \n",
       "4          1.212334       0.920488  0.912138                  0.962837   \n",
       "5          1.188627       0.887533  0.884343                  0.944009   \n",
       "6          1.166840       0.857473  0.859906                  0.926705   \n",
       "7          1.145120       0.823219  0.833685                  0.909456   \n",
       "8          1.122777       0.785219  0.801526                  0.891711   \n",
       "9          1.099692       0.745053  0.759444                  0.873376   \n",
       "10         1.072408       0.678324  0.694041                  0.851708   \n",
       "11         1.000000       0.276715  0.274597                  0.794201   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n",
       "0           1.000000      0.107073                 0.107073  25.912697   \n",
       "1           0.999723      0.019230                 0.126303  25.912697   \n",
       "2           0.991453      0.062009                 0.188312  24.742970   \n",
       "3           0.978462      0.059517                 0.247830  19.019060   \n",
       "4           0.956359      0.115878                 0.363708  15.901163   \n",
       "5           0.938353      0.111766                 0.475475  11.751671   \n",
       "6           0.922667      0.107945                 0.583420   7.966710   \n",
       "7           0.907835      0.103667                 0.687087   3.653724   \n",
       "8           0.892651      0.098850                 0.785937  -1.130908   \n",
       "9           0.875998      0.093824                 0.879761  -6.188396   \n",
       "10          0.855784      0.085393                 0.965153 -14.590398   \n",
       "11          0.797658      0.034847                 1.000000 -65.158063   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0         25.912697            0.107073  \n",
       "1         25.912697            0.126303  \n",
       "2         25.525103            0.186069  \n",
       "3         23.898592            0.232283  \n",
       "4         21.233368            0.309533  \n",
       "5         18.862749            0.366643  \n",
       "6         16.683972            0.405346  \n",
       "7         14.512025            0.423103  \n",
       "8         12.277742            0.417609  \n",
       "9          9.969189            0.387534  \n",
       "10         7.240846            0.316652  \n",
       "11         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>cv_1_valid</th>\n",
       "      <th>cv_2_valid</th>\n",
       "      <th>cv_3_valid</th>\n",
       "      <th>cv_4_valid</th>\n",
       "      <th>cv_5_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.849155</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>0.853067</td>\n",
       "      <td>0.845621</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.848095</td>\n",
       "      <td>0.846281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.805422</td>\n",
       "      <td>0.008270</td>\n",
       "      <td>0.798919</td>\n",
       "      <td>0.800813</td>\n",
       "      <td>0.817122</td>\n",
       "      <td>0.811168</td>\n",
       "      <td>0.799087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>err</td>\n",
       "      <td>0.150845</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>0.146933</td>\n",
       "      <td>0.154379</td>\n",
       "      <td>0.147287</td>\n",
       "      <td>0.151905</td>\n",
       "      <td>0.153719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>err_count</td>\n",
       "      <td>914.600000</td>\n",
       "      <td>21.361180</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>936.000000</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>921.000000</td>\n",
       "      <td>932.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f0point5</td>\n",
       "      <td>0.868401</td>\n",
       "      <td>0.003078</td>\n",
       "      <td>0.871932</td>\n",
       "      <td>0.865582</td>\n",
       "      <td>0.871527</td>\n",
       "      <td>0.866907</td>\n",
       "      <td>0.866059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.913192</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>0.915920</td>\n",
       "      <td>0.911464</td>\n",
       "      <td>0.915380</td>\n",
       "      <td>0.911858</td>\n",
       "      <td>0.911339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f2</td>\n",
       "      <td>0.962857</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.964581</td>\n",
       "      <td>0.962484</td>\n",
       "      <td>0.963879</td>\n",
       "      <td>0.961725</td>\n",
       "      <td>0.961616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lift_top_group</td>\n",
       "      <td>1.259169</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>1.249536</td>\n",
       "      <td>1.258145</td>\n",
       "      <td>1.254241</td>\n",
       "      <td>1.270270</td>\n",
       "      <td>1.263651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>logloss</td>\n",
       "      <td>0.367161</td>\n",
       "      <td>0.007120</td>\n",
       "      <td>0.364113</td>\n",
       "      <td>0.372451</td>\n",
       "      <td>0.356698</td>\n",
       "      <td>0.367940</td>\n",
       "      <td>0.374604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max_per_class_error</td>\n",
       "      <td>0.729625</td>\n",
       "      <td>0.016384</td>\n",
       "      <td>0.735756</td>\n",
       "      <td>0.751608</td>\n",
       "      <td>0.723352</td>\n",
       "      <td>0.706977</td>\n",
       "      <td>0.730435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mcc</td>\n",
       "      <td>0.472327</td>\n",
       "      <td>0.012256</td>\n",
       "      <td>0.472499</td>\n",
       "      <td>0.455026</td>\n",
       "      <td>0.479310</td>\n",
       "      <td>0.487430</td>\n",
       "      <td>0.467371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mean_per_class_accuracy</td>\n",
       "      <td>0.634729</td>\n",
       "      <td>0.007877</td>\n",
       "      <td>0.632122</td>\n",
       "      <td>0.624092</td>\n",
       "      <td>0.637910</td>\n",
       "      <td>0.645569</td>\n",
       "      <td>0.633949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mean_per_class_error</td>\n",
       "      <td>0.365272</td>\n",
       "      <td>0.007877</td>\n",
       "      <td>0.367878</td>\n",
       "      <td>0.375908</td>\n",
       "      <td>0.362090</td>\n",
       "      <td>0.354431</td>\n",
       "      <td>0.366051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mse</td>\n",
       "      <td>0.115871</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0.114354</td>\n",
       "      <td>0.117789</td>\n",
       "      <td>0.112109</td>\n",
       "      <td>0.116437</td>\n",
       "      <td>0.118667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pr_auc</td>\n",
       "      <td>0.937922</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.937715</td>\n",
       "      <td>0.936465</td>\n",
       "      <td>0.942800</td>\n",
       "      <td>0.937472</td>\n",
       "      <td>0.935159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.840905</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>0.844882</td>\n",
       "      <td>0.837476</td>\n",
       "      <td>0.844553</td>\n",
       "      <td>0.839323</td>\n",
       "      <td>0.838292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.290934</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>0.284491</td>\n",
       "      <td>0.277726</td>\n",
       "      <td>0.306326</td>\n",
       "      <td>0.304840</td>\n",
       "      <td>0.281286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.999082</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999792</td>\n",
       "      <td>0.999173</td>\n",
       "      <td>0.998114</td>\n",
       "      <td>0.998333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rmse</td>\n",
       "      <td>0.340381</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.338163</td>\n",
       "      <td>0.343204</td>\n",
       "      <td>0.334826</td>\n",
       "      <td>0.341229</td>\n",
       "      <td>0.344481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>specificity</td>\n",
       "      <td>0.270375</td>\n",
       "      <td>0.016384</td>\n",
       "      <td>0.264244</td>\n",
       "      <td>0.248392</td>\n",
       "      <td>0.276648</td>\n",
       "      <td>0.293023</td>\n",
       "      <td>0.269565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean         sd  cv_1_valid  cv_2_valid  \\\n",
       "0                  accuracy    0.849155   0.003530    0.853067    0.845621   \n",
       "1                       auc    0.805422   0.008270    0.798919    0.800813   \n",
       "2                       err    0.150845   0.003530    0.146933    0.154379   \n",
       "3                 err_count  914.600000  21.361180  891.000000  936.000000   \n",
       "4                  f0point5    0.868401   0.003078    0.871932    0.865582   \n",
       "5                        f1    0.913192   0.002260    0.915920    0.911464   \n",
       "6                        f2    0.962857   0.001321    0.964581    0.962484   \n",
       "7            lift_top_group    1.259169   0.008085    1.249536    1.258145   \n",
       "8                   logloss    0.367161   0.007120    0.364113    0.372451   \n",
       "9       max_per_class_error    0.729625   0.016384    0.735756    0.751608   \n",
       "10                      mcc    0.472327   0.012256    0.472499    0.455026   \n",
       "11  mean_per_class_accuracy    0.634729   0.007877    0.632122    0.624092   \n",
       "12     mean_per_class_error    0.365272   0.007877    0.367878    0.375908   \n",
       "13                      mse    0.115871   0.002659    0.114354    0.117789   \n",
       "14                   pr_auc    0.937922   0.002907    0.937715    0.936465   \n",
       "15                precision    0.840905   0.003543    0.844882    0.837476   \n",
       "16                       r2    0.290934   0.013596    0.284491    0.277726   \n",
       "17                   recall    0.999082   0.000845    1.000000    0.999792   \n",
       "18                     rmse    0.340381   0.003914    0.338163    0.343204   \n",
       "19              specificity    0.270375   0.016384    0.264244    0.248392   \n",
       "\n",
       "    cv_3_valid  cv_4_valid  cv_5_valid  \n",
       "0     0.852713    0.848095    0.846281  \n",
       "1     0.817122    0.811168    0.799087  \n",
       "2     0.147287    0.151905    0.153719  \n",
       "3   893.000000  921.000000  932.000000  \n",
       "4     0.871527    0.866907    0.866059  \n",
       "5     0.915380    0.911858    0.911339  \n",
       "6     0.963879    0.961725    0.961616  \n",
       "7     1.254241    1.270270    1.263651  \n",
       "8     0.356698    0.367940    0.374604  \n",
       "9     0.723352    0.706977    0.730435  \n",
       "10    0.479310    0.487430    0.467371  \n",
       "11    0.637910    0.645569    0.633949  \n",
       "12    0.362090    0.354431    0.366051  \n",
       "13    0.112109    0.116437    0.118667  \n",
       "14    0.942800    0.937472    0.935159  \n",
       "15    0.844553    0.839323    0.838292  \n",
       "16    0.306326    0.304840    0.281286  \n",
       "17    0.999173    0.998114    0.998333  \n",
       "18    0.334826    0.341229    0.344481  \n",
       "19    0.276648    0.293023    0.269565  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_auc</th>\n",
       "      <th>training_pr_auc</th>\n",
       "      <th>training_lift</th>\n",
       "      <th>training_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2022-02-11 15:54:00</td>\n",
       "      <td>16.376 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2022-02-11 15:54:00</td>\n",
       "      <td>16.598 sec</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.397514</td>\n",
       "      <td>2.563933</td>\n",
       "      <td>0.712633</td>\n",
       "      <td>0.880043</td>\n",
       "      <td>1.124767</td>\n",
       "      <td>0.169005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2022-02-11 15:54:00</td>\n",
       "      <td>16.841 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.368755</td>\n",
       "      <td>1.122075</td>\n",
       "      <td>0.744101</td>\n",
       "      <td>0.899445</td>\n",
       "      <td>1.170969</td>\n",
       "      <td>0.155975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2022-02-11 15:54:00</td>\n",
       "      <td>17.103 sec</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.357396</td>\n",
       "      <td>0.650509</td>\n",
       "      <td>0.760727</td>\n",
       "      <td>0.912927</td>\n",
       "      <td>1.212219</td>\n",
       "      <td>0.153257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2022-02-11 15:54:01</td>\n",
       "      <td>17.362 sec</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.351968</td>\n",
       "      <td>0.499551</td>\n",
       "      <td>0.769265</td>\n",
       "      <td>0.919458</td>\n",
       "      <td>1.234577</td>\n",
       "      <td>0.152471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2022-02-11 15:54:01</td>\n",
       "      <td>17.636 sec</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.348467</td>\n",
       "      <td>0.439022</td>\n",
       "      <td>0.776998</td>\n",
       "      <td>0.924072</td>\n",
       "      <td>1.245999</td>\n",
       "      <td>0.152164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2022-02-11 15:54:01</td>\n",
       "      <td>17.899 sec</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.345951</td>\n",
       "      <td>0.407058</td>\n",
       "      <td>0.783456</td>\n",
       "      <td>0.927399</td>\n",
       "      <td>1.251574</td>\n",
       "      <td>0.151966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2022-02-11 15:54:02</td>\n",
       "      <td>18.200 sec</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.344262</td>\n",
       "      <td>0.386129</td>\n",
       "      <td>0.788824</td>\n",
       "      <td>0.930055</td>\n",
       "      <td>1.256506</td>\n",
       "      <td>0.152164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>2022-02-11 15:54:02</td>\n",
       "      <td>18.447 sec</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.342970</td>\n",
       "      <td>0.377126</td>\n",
       "      <td>0.792984</td>\n",
       "      <td>0.931797</td>\n",
       "      <td>1.258443</td>\n",
       "      <td>0.151933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>2022-02-11 15:54:02</td>\n",
       "      <td>18.715 sec</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.342302</td>\n",
       "      <td>0.372775</td>\n",
       "      <td>0.796353</td>\n",
       "      <td>0.933442</td>\n",
       "      <td>1.259127</td>\n",
       "      <td>0.151999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>2022-02-11 15:54:02</td>\n",
       "      <td>18.978 sec</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.341783</td>\n",
       "      <td>0.371192</td>\n",
       "      <td>0.798970</td>\n",
       "      <td>0.934548</td>\n",
       "      <td>1.259127</td>\n",
       "      <td>0.152098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp    duration  number_of_trees  training_rmse  \\\n",
       "0     2022-02-11 15:54:00  16.376 sec              0.0            NaN   \n",
       "1     2022-02-11 15:54:00  16.598 sec              5.0       0.397514   \n",
       "2     2022-02-11 15:54:00  16.841 sec             10.0       0.368755   \n",
       "3     2022-02-11 15:54:00  17.103 sec             15.0       0.357396   \n",
       "4     2022-02-11 15:54:01  17.362 sec             20.0       0.351968   \n",
       "5     2022-02-11 15:54:01  17.636 sec             25.0       0.348467   \n",
       "6     2022-02-11 15:54:01  17.899 sec             30.0       0.345951   \n",
       "7     2022-02-11 15:54:02  18.200 sec             35.0       0.344262   \n",
       "8     2022-02-11 15:54:02  18.447 sec             40.0       0.342970   \n",
       "9     2022-02-11 15:54:02  18.715 sec             45.0       0.342302   \n",
       "10    2022-02-11 15:54:02  18.978 sec             50.0       0.341783   \n",
       "\n",
       "    training_logloss  training_auc  training_pr_auc  training_lift  \\\n",
       "0                NaN           NaN              NaN            NaN   \n",
       "1           2.563933      0.712633         0.880043       1.124767   \n",
       "2           1.122075      0.744101         0.899445       1.170969   \n",
       "3           0.650509      0.760727         0.912927       1.212219   \n",
       "4           0.499551      0.769265         0.919458       1.234577   \n",
       "5           0.439022      0.776998         0.924072       1.245999   \n",
       "6           0.407058      0.783456         0.927399       1.251574   \n",
       "7           0.386129      0.788824         0.930055       1.256506   \n",
       "8           0.377126      0.792984         0.931797       1.258443   \n",
       "9           0.372775      0.796353         0.933442       1.259127   \n",
       "10          0.371192      0.798970         0.934548       1.259127   \n",
       "\n",
       "    training_classification_error  \n",
       "0                             NaN  \n",
       "1                        0.169005  \n",
       "2                        0.155975  \n",
       "3                        0.153257  \n",
       "4                        0.152471  \n",
       "5                        0.152164  \n",
       "6                        0.151966  \n",
       "7                        0.152164  \n",
       "8                        0.151933  \n",
       "9                        0.151999  \n",
       "10                       0.152098  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Credit Score</td>\n",
       "      <td>44863.031250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.370073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Current Loan Amount</td>\n",
       "      <td>12147.786133</td>\n",
       "      <td>0.270775</td>\n",
       "      <td>0.100207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Years in current job</td>\n",
       "      <td>8138.504883</td>\n",
       "      <td>0.181408</td>\n",
       "      <td>0.067134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Annual Income</td>\n",
       "      <td>7469.480957</td>\n",
       "      <td>0.166495</td>\n",
       "      <td>0.061615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Years of Credit History</td>\n",
       "      <td>7444.440918</td>\n",
       "      <td>0.165937</td>\n",
       "      <td>0.061409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Months since last delinquent</td>\n",
       "      <td>7280.359863</td>\n",
       "      <td>0.162280</td>\n",
       "      <td>0.060055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Monthly Debt</td>\n",
       "      <td>7062.839355</td>\n",
       "      <td>0.157431</td>\n",
       "      <td>0.058261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Number of Open Accounts</td>\n",
       "      <td>6300.431152</td>\n",
       "      <td>0.140437</td>\n",
       "      <td>0.051972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Current Credit Balance</td>\n",
       "      <td>5635.642090</td>\n",
       "      <td>0.125619</td>\n",
       "      <td>0.046488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Maximum Open Credit</td>\n",
       "      <td>4645.382812</td>\n",
       "      <td>0.103546</td>\n",
       "      <td>0.038320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Purpose</td>\n",
       "      <td>4411.562988</td>\n",
       "      <td>0.098334</td>\n",
       "      <td>0.036391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Home Ownership</td>\n",
       "      <td>1760.941406</td>\n",
       "      <td>0.039252</td>\n",
       "      <td>0.014526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Term</td>\n",
       "      <td>1425.872681</td>\n",
       "      <td>0.031783</td>\n",
       "      <td>0.011762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Number of Credit Problems</td>\n",
       "      <td>1233.237915</td>\n",
       "      <td>0.027489</td>\n",
       "      <td>0.010173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bankruptcies</td>\n",
       "      <td>890.442383</td>\n",
       "      <td>0.019848</td>\n",
       "      <td>0.007345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Tax Liens</td>\n",
       "      <td>517.514404</td>\n",
       "      <td>0.011535</td>\n",
       "      <td>0.004269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        variable  relative_importance  scaled_importance  \\\n",
       "0                   Credit Score         44863.031250           1.000000   \n",
       "1            Current Loan Amount         12147.786133           0.270775   \n",
       "2           Years in current job          8138.504883           0.181408   \n",
       "3                  Annual Income          7469.480957           0.166495   \n",
       "4        Years of Credit History          7444.440918           0.165937   \n",
       "5   Months since last delinquent          7280.359863           0.162280   \n",
       "6                   Monthly Debt          7062.839355           0.157431   \n",
       "7        Number of Open Accounts          6300.431152           0.140437   \n",
       "8         Current Credit Balance          5635.642090           0.125619   \n",
       "9            Maximum Open Credit          4645.382812           0.103546   \n",
       "10                       Purpose          4411.562988           0.098334   \n",
       "11                Home Ownership          1760.941406           0.039252   \n",
       "12                          Term          1425.872681           0.031783   \n",
       "13     Number of Credit Problems          1233.237915           0.027489   \n",
       "14                  Bankruptcies           890.442383           0.019848   \n",
       "15                     Tax Liens           517.514404           0.011535   \n",
       "\n",
       "    percentage  \n",
       "0     0.370073  \n",
       "1     0.100207  \n",
       "2     0.067134  \n",
       "3     0.061615  \n",
       "4     0.061409  \n",
       "5     0.060055  \n",
       "6     0.058261  \n",
       "7     0.051972  \n",
       "8     0.046488  \n",
       "9     0.038320  \n",
       "10    0.036391  \n",
       "11    0.014526  \n",
       "12    0.011762  \n",
       "13    0.010173  \n",
       "14    0.007345  \n",
       "15    0.004269  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up AutoML\n",
    "aml2 = H2OAutoML(seed=1,max_runtime_secs=run_time, exclude_algos=[\"StackedEnsemble\"],verbosity=\"info\")\n",
    "aml2.train(x=X,y=target,training_frame=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                   </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DRF_1_AutoML_8_20220211_155216             </td><td style=\"text-align: right;\">0.805361</td><td style=\"text-align: right;\"> 0.367161</td><td style=\"text-align: right;\">0.937887</td><td style=\"text-align: right;\">              0.366491</td><td style=\"text-align: right;\">0.340398</td><td style=\"text-align: right;\">0.115871</td></tr>\n",
       "<tr><td>XRT_1_AutoML_8_20220211_155216             </td><td style=\"text-align: right;\">0.797614</td><td style=\"text-align: right;\"> 0.370979</td><td style=\"text-align: right;\">0.933949</td><td style=\"text-align: right;\">              0.369851</td><td style=\"text-align: right;\">0.341674</td><td style=\"text-align: right;\">0.116741</td></tr>\n",
       "<tr><td>GBM_2_AutoML_8_20220211_155216             </td><td style=\"text-align: right;\">0.783153</td><td style=\"text-align: right;\"> 0.376407</td><td style=\"text-align: right;\">0.928678</td><td style=\"text-align: right;\">              0.366232</td><td style=\"text-align: right;\">0.343954</td><td style=\"text-align: right;\">0.118304</td></tr>\n",
       "<tr><td>GBM_3_AutoML_8_20220211_155216             </td><td style=\"text-align: right;\">0.782676</td><td style=\"text-align: right;\"> 0.376784</td><td style=\"text-align: right;\">0.928363</td><td style=\"text-align: right;\">              0.369213</td><td style=\"text-align: right;\">0.343994</td><td style=\"text-align: right;\">0.118332</td></tr>\n",
       "<tr><td>GBM_5_AutoML_8_20220211_155216             </td><td style=\"text-align: right;\">0.78157 </td><td style=\"text-align: right;\"> 0.37739 </td><td style=\"text-align: right;\">0.928292</td><td style=\"text-align: right;\">              0.367111</td><td style=\"text-align: right;\">0.34429 </td><td style=\"text-align: right;\">0.118535</td></tr>\n",
       "<tr><td>GBM_4_AutoML_8_20220211_155216             </td><td style=\"text-align: right;\">0.781134</td><td style=\"text-align: right;\"> 0.378452</td><td style=\"text-align: right;\">0.927639</td><td style=\"text-align: right;\">              0.367565</td><td style=\"text-align: right;\">0.344704</td><td style=\"text-align: right;\">0.118821</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_8_20220211_155216_model_2</td><td style=\"text-align: right;\">0.780398</td><td style=\"text-align: right;\"> 0.378874</td><td style=\"text-align: right;\">0.928244</td><td style=\"text-align: right;\">              0.369691</td><td style=\"text-align: right;\">0.344867</td><td style=\"text-align: right;\">0.118933</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_8_20220211_155216_model_1</td><td style=\"text-align: right;\">0.779683</td><td style=\"text-align: right;\"> 0.390921</td><td style=\"text-align: right;\">0.926538</td><td style=\"text-align: right;\">              0.367666</td><td style=\"text-align: right;\">0.347354</td><td style=\"text-align: right;\">0.120655</td></tr>\n",
       "<tr><td>GBM_1_AutoML_8_20220211_155216             </td><td style=\"text-align: right;\">0.779476</td><td style=\"text-align: right;\"> 0.379118</td><td style=\"text-align: right;\">0.927435</td><td style=\"text-align: right;\">              0.369851</td><td style=\"text-align: right;\">0.345126</td><td style=\"text-align: right;\">0.119112</td></tr>\n",
       "<tr><td>XGBoost_3_AutoML_8_20220211_155216         </td><td style=\"text-align: right;\">0.778348</td><td style=\"text-align: right;\"> 0.377463</td><td style=\"text-align: right;\">0.927409</td><td style=\"text-align: right;\">              0.369851</td><td style=\"text-align: right;\">0.345264</td><td style=\"text-align: right;\">0.119207</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(aml2.leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'H2OAutoML' object has no attribute 'corr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5q/w_y2sfjj2bv130sh86slry7r0000gq/T/ipykernel_2688/3239309480.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'H2OAutoML' object has no attribute 'corr'"
     ]
    }
   ],
   "source": [
    "aml.corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "best=aml.get_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OStackedEnsembleEstimator :  Stacked Ensemble\n",
      "Model Key:  StackedEnsemble_AllModels_2_AutoML_6_20220211_154220\n",
      "\n",
      "No model summary for this model\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.08727230038534711\n",
      "RMSE: 0.29541885583920857\n",
      "LogLoss: 0.2925481911749993\n",
      "Null degrees of freedom: 9868\n",
      "Residual degrees of freedom: 9861\n",
      "Null deviance: 10527.37156155715\n",
      "Residual deviance: 5774.316197412137\n",
      "AIC: 5790.316197412137\n",
      "AUC: 0.9665535992594944\n",
      "AUCPR: 0.9896455490053936\n",
      "Gini: 0.9331071985189887\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6964519784347294: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Charged Off</th>\n",
       "      <th>Fully Paid</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Charged Off</td>\n",
       "      <td>1772.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>(450.0/2222.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>333.0</td>\n",
       "      <td>7314.0</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>(333.0/7647.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>2105.0</td>\n",
       "      <td>7764.0</td>\n",
       "      <td>0.0793</td>\n",
       "      <td>(783.0/9869.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Charged Off  Fully Paid   Error             Rate\n",
       "0  Charged Off       1772.0       450.0  0.2025   (450.0/2222.0)\n",
       "1   Fully Paid        333.0      7314.0  0.0435   (333.0/7647.0)\n",
       "2        Total       2105.0      7764.0  0.0793   (783.0/9869.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.696452</td>\n",
       "      <td>0.949192</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.569225</td>\n",
       "      <td>0.970324</td>\n",
       "      <td>289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.744256</td>\n",
       "      <td>0.955739</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.697842</td>\n",
       "      <td>0.920661</td>\n",
       "      <td>223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.470698</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.716298</td>\n",
       "      <td>0.773105</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.747231</td>\n",
       "      <td>0.900540</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.744256</td>\n",
       "      <td>0.903143</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2222.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>6815.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2222.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.470698</td>\n",
       "      <td>7647.000000</td>\n",
       "      <td>326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.891199</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.470698</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>326.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold        value    idx\n",
       "0                        max f1   0.696452     0.949192  224.0\n",
       "1                        max f2   0.569225     0.970324  289.0\n",
       "2                  max f0point5   0.744256     0.955739  196.0\n",
       "3                  max accuracy   0.697842     0.920661  223.0\n",
       "4                 max precision   0.999999     1.000000    0.0\n",
       "5                    max recall   0.470698     1.000000  326.0\n",
       "6               max specificity   0.999999     1.000000    0.0\n",
       "7              max absolute_mcc   0.716298     0.773105  213.0\n",
       "8    max min_per_class_accuracy   0.747231     0.900540  194.0\n",
       "9   max mean_per_class_accuracy   0.744256     0.903143  196.0\n",
       "10                      max tns   0.999999  2222.000000    0.0\n",
       "11                      max fns   0.999999  6815.000000    0.0\n",
       "12                      max fps   0.000003  2222.000000  399.0\n",
       "13                      max tps   0.470698  7647.000000  326.0\n",
       "14                      max tnr   0.999999     1.000000    0.0\n",
       "15                      max fnr   0.999999     0.891199    0.0\n",
       "16                      max fpr   0.000003     1.000000  399.0\n",
       "17                      max tpr   0.470698     1.000000  326.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 77.49 %, avg score: 77.08 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010133</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013077</td>\n",
       "      <td>0.013077</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>0.013077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020164</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012946</td>\n",
       "      <td>0.026023</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>0.026023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030196</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012946</td>\n",
       "      <td>0.038970</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>0.038970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040227</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012946</td>\n",
       "      <td>0.051916</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>0.051916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050258</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012946</td>\n",
       "      <td>0.064862</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>0.064862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100517</td>\n",
       "      <td>9.994302e-01</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.064862</td>\n",
       "      <td>0.129724</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>0.129724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150674</td>\n",
       "      <td>9.348057e-01</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956578</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985511</td>\n",
       "      <td>0.064731</td>\n",
       "      <td>0.194455</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>0.194455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200932</td>\n",
       "      <td>9.135582e-01</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.290571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923547</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970012</td>\n",
       "      <td>0.064862</td>\n",
       "      <td>0.259317</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>29.057147</td>\n",
       "      <td>0.259317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.301348</td>\n",
       "      <td>8.821687e-01</td>\n",
       "      <td>1.286665</td>\n",
       "      <td>1.289270</td>\n",
       "      <td>0.996973</td>\n",
       "      <td>0.897583</td>\n",
       "      <td>0.998991</td>\n",
       "      <td>0.945877</td>\n",
       "      <td>0.129201</td>\n",
       "      <td>0.388518</td>\n",
       "      <td>28.666459</td>\n",
       "      <td>28.926961</td>\n",
       "      <td>0.387168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.401763</td>\n",
       "      <td>8.562679e-01</td>\n",
       "      <td>1.285362</td>\n",
       "      <td>1.288293</td>\n",
       "      <td>0.995964</td>\n",
       "      <td>0.868934</td>\n",
       "      <td>0.998235</td>\n",
       "      <td>0.926646</td>\n",
       "      <td>0.129070</td>\n",
       "      <td>0.517589</td>\n",
       "      <td>28.536230</td>\n",
       "      <td>28.829303</td>\n",
       "      <td>0.514438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.502280</td>\n",
       "      <td>8.306344e-01</td>\n",
       "      <td>1.265853</td>\n",
       "      <td>1.283802</td>\n",
       "      <td>0.980847</td>\n",
       "      <td>0.843749</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.910057</td>\n",
       "      <td>0.127239</td>\n",
       "      <td>0.644828</td>\n",
       "      <td>26.585286</td>\n",
       "      <td>28.380228</td>\n",
       "      <td>0.633127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.602695</td>\n",
       "      <td>7.982943e-01</td>\n",
       "      <td>1.228061</td>\n",
       "      <td>1.274515</td>\n",
       "      <td>0.951564</td>\n",
       "      <td>0.815124</td>\n",
       "      <td>0.987559</td>\n",
       "      <td>0.894240</td>\n",
       "      <td>0.123316</td>\n",
       "      <td>0.768144</td>\n",
       "      <td>22.806145</td>\n",
       "      <td>27.451526</td>\n",
       "      <td>0.734841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.703111</td>\n",
       "      <td>7.562734e-01</td>\n",
       "      <td>1.152529</td>\n",
       "      <td>1.257094</td>\n",
       "      <td>0.893037</td>\n",
       "      <td>0.779593</td>\n",
       "      <td>0.974060</td>\n",
       "      <td>0.877867</td>\n",
       "      <td>0.115732</td>\n",
       "      <td>0.883876</td>\n",
       "      <td>15.252850</td>\n",
       "      <td>25.709361</td>\n",
       "      <td>0.802868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799068</td>\n",
       "      <td>6.832883e-01</td>\n",
       "      <td>0.823131</td>\n",
       "      <td>1.204981</td>\n",
       "      <td>0.637804</td>\n",
       "      <td>0.724100</td>\n",
       "      <td>0.933680</td>\n",
       "      <td>0.859401</td>\n",
       "      <td>0.078985</td>\n",
       "      <td>0.962861</td>\n",
       "      <td>-17.686889</td>\n",
       "      <td>20.498069</td>\n",
       "      <td>0.727488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899483</td>\n",
       "      <td>5.075427e-01</td>\n",
       "      <td>0.360735</td>\n",
       "      <td>1.110732</td>\n",
       "      <td>0.279516</td>\n",
       "      <td>0.610897</td>\n",
       "      <td>0.860651</td>\n",
       "      <td>0.831659</td>\n",
       "      <td>0.036223</td>\n",
       "      <td>0.999085</td>\n",
       "      <td>-63.926509</td>\n",
       "      <td>11.073178</td>\n",
       "      <td>0.442379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.406168e-07</td>\n",
       "      <td>0.009107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007056</td>\n",
       "      <td>0.225985</td>\n",
       "      <td>0.774851</td>\n",
       "      <td>0.770779</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-99.089314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010133     9.999999e-01  1.290571   \n",
       "1       2                  0.020164     9.999999e-01  1.290571   \n",
       "2       3                  0.030196     9.999999e-01  1.290571   \n",
       "3       4                  0.040227     9.999999e-01  1.290571   \n",
       "4       5                  0.050258     9.999999e-01  1.290571   \n",
       "5       6                  0.100517     9.994302e-01  1.290571   \n",
       "6       7                  0.150674     9.348057e-01  1.290571   \n",
       "7       8                  0.200932     9.135582e-01  1.290571   \n",
       "8       9                  0.301348     8.821687e-01  1.286665   \n",
       "9      10                  0.401763     8.562679e-01  1.285362   \n",
       "10     11                  0.502280     8.306344e-01  1.265853   \n",
       "11     12                  0.602695     7.982943e-01  1.228061   \n",
       "12     13                  0.703111     7.562734e-01  1.152529   \n",
       "13     14                  0.799068     6.832883e-01  0.823131   \n",
       "14     15                  0.899483     5.075427e-01  0.360735   \n",
       "15     16                  1.000000     1.406168e-07  0.009107   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.290571       1.000000  1.000000                  1.000000   \n",
       "1          1.290571       1.000000  1.000000                  1.000000   \n",
       "2          1.290571       1.000000  1.000000                  1.000000   \n",
       "3          1.290571       1.000000  1.000000                  1.000000   \n",
       "4          1.290571       1.000000  1.000000                  1.000000   \n",
       "5          1.290571       1.000000  0.999898                  1.000000   \n",
       "6          1.290571       1.000000  0.956578                  1.000000   \n",
       "7          1.290571       1.000000  0.923547                  1.000000   \n",
       "8          1.289270       0.996973  0.897583                  0.998991   \n",
       "9          1.288293       0.995964  0.868934                  0.998235   \n",
       "10         1.283802       0.980847  0.843749                  0.994755   \n",
       "11         1.274515       0.951564  0.815124                  0.987559   \n",
       "12         1.257094       0.893037  0.779593                  0.974060   \n",
       "13         1.204981       0.637804  0.724100                  0.933680   \n",
       "14         1.110732       0.279516  0.610897                  0.860651   \n",
       "15         1.000000       0.007056  0.225985                  0.774851   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n",
       "0           1.000000      0.013077                 0.013077  29.057147   \n",
       "1           1.000000      0.012946                 0.026023  29.057147   \n",
       "2           1.000000      0.012946                 0.038970  29.057147   \n",
       "3           1.000000      0.012946                 0.051916  29.057147   \n",
       "4           1.000000      0.012946                 0.064862  29.057147   \n",
       "5           0.999949      0.064862                 0.129724  29.057147   \n",
       "6           0.985511      0.064731                 0.194455  29.057147   \n",
       "7           0.970012      0.064862                 0.259317  29.057147   \n",
       "8           0.945877      0.129201                 0.388518  28.666459   \n",
       "9           0.926646      0.129070                 0.517589  28.536230   \n",
       "10          0.910057      0.127239                 0.644828  26.585286   \n",
       "11          0.894240      0.123316                 0.768144  22.806145   \n",
       "12          0.877867      0.115732                 0.883876  15.252850   \n",
       "13          0.859401      0.078985                 0.962861 -17.686889   \n",
       "14          0.831659      0.036223                 0.999085 -63.926509   \n",
       "15          0.770779      0.000915                 1.000000 -99.089314   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0         29.057147            0.013077  \n",
       "1         29.057147            0.026023  \n",
       "2         29.057147            0.038970  \n",
       "3         29.057147            0.051916  \n",
       "4         29.057147            0.064862  \n",
       "5         29.057147            0.129724  \n",
       "6         29.057147            0.194455  \n",
       "7         29.057147            0.259317  \n",
       "8         28.926961            0.387168  \n",
       "9         28.829303            0.514438  \n",
       "10        28.380228            0.633127  \n",
       "11        27.451526            0.734841  \n",
       "12        25.709361            0.802868  \n",
       "13        20.498069            0.727488  \n",
       "14        11.073178            0.442379  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.13235859234904712\n",
      "RMSE: 0.36381120426540897\n",
      "LogLoss: 0.409214155024947\n",
      "Null degrees of freedom: 80103\n",
      "Residual degrees of freedom: 80097\n",
      "Null deviance: 85761.4088420349\n",
      "Residual deviance: 65559.38134823671\n",
      "AIC: 65573.38134823671\n",
      "AUC: 0.7806707220739665\n",
      "AUCPR: 0.9207661355436089\n",
      "Gini: 0.561341444147933\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4170691696861526: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Charged Off</th>\n",
       "      <th>Fully Paid</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Charged Off</td>\n",
       "      <td>3821.0</td>\n",
       "      <td>14339.0</td>\n",
       "      <td>0.7896</td>\n",
       "      <td>(14339.0/18160.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>112.0</td>\n",
       "      <td>61832.0</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>(112.0/61944.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>3933.0</td>\n",
       "      <td>76171.0</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>(14451.0/80104.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Charged Off  Fully Paid   Error                Rate\n",
       "0  Charged Off       3821.0     14339.0  0.7896   (14339.0/18160.0)\n",
       "1   Fully Paid        112.0     61832.0  0.0018     (112.0/61944.0)\n",
       "2        Total       3933.0     76171.0  0.1804   (14451.0/80104.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.417069</td>\n",
       "      <td>0.895370</td>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.228960</td>\n",
       "      <td>0.955295</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.697226</td>\n",
       "      <td>0.854126</td>\n",
       "      <td>244.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.490715</td>\n",
       "      <td>0.819747</td>\n",
       "      <td>348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.228960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.296850</td>\n",
       "      <td>0.404644</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.781946</td>\n",
       "      <td>0.692511</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.786392</td>\n",
       "      <td>0.693833</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>18160.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>54395.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>18160.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.228960</td>\n",
       "      <td>61944.000000</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.878132</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.228960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.417069      0.895370  372.0\n",
       "1                        max f2   0.228960      0.955295  393.0\n",
       "2                  max f0point5   0.697226      0.854126  244.0\n",
       "3                  max accuracy   0.490715      0.819747  348.0\n",
       "4                 max precision   0.999985      1.000000    0.0\n",
       "5                    max recall   0.228960      1.000000  393.0\n",
       "6               max specificity   0.999985      1.000000    0.0\n",
       "7              max absolute_mcc   0.296850      0.404644  389.0\n",
       "8    max min_per_class_accuracy   0.781946      0.692511  170.0\n",
       "9   max mean_per_class_accuracy   0.786392      0.693833  166.0\n",
       "10                      max tns   0.999985  18160.000000    0.0\n",
       "11                      max fns   0.999985  54395.000000    0.0\n",
       "12                      max fps   0.000003  18160.000000  399.0\n",
       "13                      max tps   0.228960  61944.000000  393.0\n",
       "14                      max tnr   0.999985      1.000000    0.0\n",
       "15                      max fnr   0.999985      0.878132    0.0\n",
       "16                      max fpr   0.000003      1.000000  399.0\n",
       "17                      max tpr   0.228960      1.000000  393.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 77.33 %, avg score: 77.33 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015130</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.293168</td>\n",
       "      <td>1.293168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019566</td>\n",
       "      <td>0.019566</td>\n",
       "      <td>29.316802</td>\n",
       "      <td>29.316802</td>\n",
       "      <td>0.019566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.033569</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.293168</td>\n",
       "      <td>1.293168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023844</td>\n",
       "      <td>0.043410</td>\n",
       "      <td>29.316802</td>\n",
       "      <td>29.316802</td>\n",
       "      <td>0.043410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.060471</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.293168</td>\n",
       "      <td>1.293168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034789</td>\n",
       "      <td>0.078200</td>\n",
       "      <td>29.316802</td>\n",
       "      <td>29.316802</td>\n",
       "      <td>0.078200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.100519</td>\n",
       "      <td>9.995014e-01</td>\n",
       "      <td>1.293168</td>\n",
       "      <td>1.293168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.051789</td>\n",
       "      <td>0.129988</td>\n",
       "      <td>29.316802</td>\n",
       "      <td>29.316802</td>\n",
       "      <td>0.129988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.150779</td>\n",
       "      <td>9.247551e-01</td>\n",
       "      <td>1.250127</td>\n",
       "      <td>1.278821</td>\n",
       "      <td>0.966716</td>\n",
       "      <td>0.958173</td>\n",
       "      <td>0.988905</td>\n",
       "      <td>0.986036</td>\n",
       "      <td>0.062831</td>\n",
       "      <td>0.192819</td>\n",
       "      <td>25.012666</td>\n",
       "      <td>27.882090</td>\n",
       "      <td>0.185440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.201039</td>\n",
       "      <td>8.996701e-01</td>\n",
       "      <td>1.191989</td>\n",
       "      <td>1.257113</td>\n",
       "      <td>0.921759</td>\n",
       "      <td>0.911280</td>\n",
       "      <td>0.972119</td>\n",
       "      <td>0.967347</td>\n",
       "      <td>0.059909</td>\n",
       "      <td>0.252728</td>\n",
       "      <td>19.198871</td>\n",
       "      <td>25.711285</td>\n",
       "      <td>0.228004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.301558</td>\n",
       "      <td>8.666497e-01</td>\n",
       "      <td>1.144932</td>\n",
       "      <td>1.219719</td>\n",
       "      <td>0.885370</td>\n",
       "      <td>0.882411</td>\n",
       "      <td>0.943203</td>\n",
       "      <td>0.939035</td>\n",
       "      <td>0.115088</td>\n",
       "      <td>0.367816</td>\n",
       "      <td>14.493229</td>\n",
       "      <td>21.971933</td>\n",
       "      <td>0.292265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.402065</td>\n",
       "      <td>8.384194e-01</td>\n",
       "      <td>1.112950</td>\n",
       "      <td>1.193030</td>\n",
       "      <td>0.860638</td>\n",
       "      <td>0.852263</td>\n",
       "      <td>0.922563</td>\n",
       "      <td>0.917344</td>\n",
       "      <td>0.111859</td>\n",
       "      <td>0.479675</td>\n",
       "      <td>11.295010</td>\n",
       "      <td>19.302951</td>\n",
       "      <td>0.342340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.502584</td>\n",
       "      <td>8.114166e-01</td>\n",
       "      <td>1.077961</td>\n",
       "      <td>1.170015</td>\n",
       "      <td>0.833582</td>\n",
       "      <td>0.824892</td>\n",
       "      <td>0.904767</td>\n",
       "      <td>0.898853</td>\n",
       "      <td>0.108356</td>\n",
       "      <td>0.588031</td>\n",
       "      <td>7.796122</td>\n",
       "      <td>17.001528</td>\n",
       "      <td>0.376908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.603103</td>\n",
       "      <td>7.825984e-01</td>\n",
       "      <td>1.023999</td>\n",
       "      <td>1.145679</td>\n",
       "      <td>0.791853</td>\n",
       "      <td>0.797213</td>\n",
       "      <td>0.885947</td>\n",
       "      <td>0.881913</td>\n",
       "      <td>0.102932</td>\n",
       "      <td>0.690963</td>\n",
       "      <td>2.399892</td>\n",
       "      <td>14.567872</td>\n",
       "      <td>0.387549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.702587</td>\n",
       "      <td>7.476005e-01</td>\n",
       "      <td>0.977544</td>\n",
       "      <td>1.121872</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>0.765763</td>\n",
       "      <td>0.867537</td>\n",
       "      <td>0.865466</td>\n",
       "      <td>0.097249</td>\n",
       "      <td>0.788212</td>\n",
       "      <td>-2.245650</td>\n",
       "      <td>12.187151</td>\n",
       "      <td>0.377694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.801034</td>\n",
       "      <td>7.001732e-01</td>\n",
       "      <td>0.916172</td>\n",
       "      <td>1.096591</td>\n",
       "      <td>0.708471</td>\n",
       "      <td>0.725608</td>\n",
       "      <td>0.847988</td>\n",
       "      <td>0.848278</td>\n",
       "      <td>0.090194</td>\n",
       "      <td>0.878406</td>\n",
       "      <td>-8.382834</td>\n",
       "      <td>9.659101</td>\n",
       "      <td>0.341292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.899481</td>\n",
       "      <td>6.016914e-01</td>\n",
       "      <td>0.848119</td>\n",
       "      <td>1.069396</td>\n",
       "      <td>0.655846</td>\n",
       "      <td>0.659279</td>\n",
       "      <td>0.826958</td>\n",
       "      <td>0.827592</td>\n",
       "      <td>0.083495</td>\n",
       "      <td>0.961901</td>\n",
       "      <td>-15.188118</td>\n",
       "      <td>6.939604</td>\n",
       "      <td>0.275337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.400000e-07</td>\n",
       "      <td>0.379021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.293095</td>\n",
       "      <td>0.287395</td>\n",
       "      <td>0.773295</td>\n",
       "      <td>0.773292</td>\n",
       "      <td>0.038099</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-62.097907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.015130     9.999999e-01  1.293168   \n",
       "1       2                  0.033569     9.999999e-01  1.293168   \n",
       "2       3                  0.060471     9.999999e-01  1.293168   \n",
       "3       4                  0.100519     9.995014e-01  1.293168   \n",
       "4       5                  0.150779     9.247551e-01  1.250127   \n",
       "5       6                  0.201039     8.996701e-01  1.191989   \n",
       "6       7                  0.301558     8.666497e-01  1.144932   \n",
       "7       8                  0.402065     8.384194e-01  1.112950   \n",
       "8       9                  0.502584     8.114166e-01  1.077961   \n",
       "9      10                  0.603103     7.825984e-01  1.023999   \n",
       "10     11                  0.702587     7.476005e-01  0.977544   \n",
       "11     12                  0.801034     7.001732e-01  0.916172   \n",
       "12     13                  0.899481     6.016914e-01  0.848119   \n",
       "13     14                  1.000000     1.400000e-07  0.379021   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.293168       1.000000  1.000000                  1.000000   \n",
       "1          1.293168       1.000000  1.000000                  1.000000   \n",
       "2          1.293168       1.000000  1.000000                  1.000000   \n",
       "3          1.293168       1.000000  0.999917                  1.000000   \n",
       "4          1.278821       0.966716  0.958173                  0.988905   \n",
       "5          1.257113       0.921759  0.911280                  0.972119   \n",
       "6          1.219719       0.885370  0.882411                  0.943203   \n",
       "7          1.193030       0.860638  0.852263                  0.922563   \n",
       "8          1.170015       0.833582  0.824892                  0.904767   \n",
       "9          1.145679       0.791853  0.797213                  0.885947   \n",
       "10         1.121872       0.755929  0.765763                  0.867537   \n",
       "11         1.096591       0.708471  0.725608                  0.847988   \n",
       "12         1.069396       0.655846  0.659279                  0.826958   \n",
       "13         1.000000       0.293095  0.287395                  0.773295   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n",
       "0           1.000000      0.019566                 0.019566  29.316802   \n",
       "1           1.000000      0.023844                 0.043410  29.316802   \n",
       "2           1.000000      0.034789                 0.078200  29.316802   \n",
       "3           0.999967      0.051789                 0.129988  29.316802   \n",
       "4           0.986036      0.062831                 0.192819  25.012666   \n",
       "5           0.967347      0.059909                 0.252728  19.198871   \n",
       "6           0.939035      0.115088                 0.367816  14.493229   \n",
       "7           0.917344      0.111859                 0.479675  11.295010   \n",
       "8           0.898853      0.108356                 0.588031   7.796122   \n",
       "9           0.881913      0.102932                 0.690963   2.399892   \n",
       "10          0.865466      0.097249                 0.788212  -2.245650   \n",
       "11          0.848278      0.090194                 0.878406  -8.382834   \n",
       "12          0.827592      0.083495                 0.961901 -15.188118   \n",
       "13          0.773292      0.038099                 1.000000 -62.097907   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0         29.316802            0.019566  \n",
       "1         29.316802            0.043410  \n",
       "2         29.316802            0.078200  \n",
       "3         29.316802            0.129988  \n",
       "4         27.882090            0.185440  \n",
       "5         25.711285            0.228004  \n",
       "6         21.971933            0.292265  \n",
       "7         19.302951            0.342340  \n",
       "8         17.001528            0.376908  \n",
       "9         14.567872            0.387549  \n",
       "10        12.187151            0.377694  \n",
       "11         9.659101            0.341292  \n",
       "12         6.939604            0.275337  \n",
       "13         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best.accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Credit Score</td>\n",
       "      <td>51540.671875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.382307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Current Loan Amount</td>\n",
       "      <td>15733.151367</td>\n",
       "      <td>0.305257</td>\n",
       "      <td>0.116702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annual Income</td>\n",
       "      <td>10849.063477</td>\n",
       "      <td>0.210495</td>\n",
       "      <td>0.080474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Months since last delinquent</td>\n",
       "      <td>10305.916992</td>\n",
       "      <td>0.199957</td>\n",
       "      <td>0.076445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Monthly Debt</td>\n",
       "      <td>10281.466797</td>\n",
       "      <td>0.199483</td>\n",
       "      <td>0.076264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Years of Credit History</td>\n",
       "      <td>10143.557617</td>\n",
       "      <td>0.196807</td>\n",
       "      <td>0.075241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Years in current job</td>\n",
       "      <td>9169.430664</td>\n",
       "      <td>0.177907</td>\n",
       "      <td>0.068015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Current Credit Balance</td>\n",
       "      <td>8438.510742</td>\n",
       "      <td>0.163725</td>\n",
       "      <td>0.062593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Number of Open Accounts</td>\n",
       "      <td>8352.965820</td>\n",
       "      <td>0.162066</td>\n",
       "      <td>0.061959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       variable  relative_importance  scaled_importance  \\\n",
       "0                  Credit Score         51540.671875           1.000000   \n",
       "1           Current Loan Amount         15733.151367           0.305257   \n",
       "2                 Annual Income         10849.063477           0.210495   \n",
       "3  Months since last delinquent         10305.916992           0.199957   \n",
       "4                  Monthly Debt         10281.466797           0.199483   \n",
       "5       Years of Credit History         10143.557617           0.196807   \n",
       "6          Years in current job          9169.430664           0.177907   \n",
       "7        Current Credit Balance          8438.510742           0.163725   \n",
       "8       Number of Open Accounts          8352.965820           0.162066   \n",
       "\n",
       "   percentage  \n",
       "0    0.382307  \n",
       "1    0.116702  \n",
       "2    0.080474  \n",
       "3    0.076445  \n",
       "4    0.076264  \n",
       "5    0.075241  \n",
       "6    0.068015  \n",
       "7    0.062593  \n",
       "8    0.061959  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.varimp(use_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.363627214865251, 0.8455543864264107]]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stackedensemble'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "k =pd.read_csv(\"https://raw.githubusercontent.com/sanapsanket/Bank-Loan-Status-Predictive-Analysis/main/KaggleDataset/BankLoanStatusDataset/credit_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current Loan Amount</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Monthly Debt</th>\n",
       "      <th>Years of Credit History</th>\n",
       "      <th>Months since last delinquent</th>\n",
       "      <th>Number of Open Accounts</th>\n",
       "      <th>Number of Credit Problems</th>\n",
       "      <th>Current Credit Balance</th>\n",
       "      <th>Maximum Open Credit</th>\n",
       "      <th>Bankruptcies</th>\n",
       "      <th>Tax Liens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Current Loan Amount</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.096652</td>\n",
       "      <td>0.013112</td>\n",
       "      <td>-0.006643</td>\n",
       "      <td>0.019282</td>\n",
       "      <td>0.011248</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>-0.002795</td>\n",
       "      <td>0.003880</td>\n",
       "      <td>-0.001271</td>\n",
       "      <td>-0.000608</td>\n",
       "      <td>-0.002048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit Score</th>\n",
       "      <td>-0.096652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.017078</td>\n",
       "      <td>-0.001674</td>\n",
       "      <td>-0.009720</td>\n",
       "      <td>-0.003739</td>\n",
       "      <td>0.006435</td>\n",
       "      <td>-0.003022</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.002827</td>\n",
       "      <td>-0.006935</td>\n",
       "      <td>0.005146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual Income</th>\n",
       "      <td>0.013112</td>\n",
       "      <td>-0.017078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.485230</td>\n",
       "      <td>0.161669</td>\n",
       "      <td>-0.077577</td>\n",
       "      <td>0.146175</td>\n",
       "      <td>-0.017006</td>\n",
       "      <td>0.312340</td>\n",
       "      <td>0.053064</td>\n",
       "      <td>-0.047672</td>\n",
       "      <td>0.040167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthly Debt</th>\n",
       "      <td>-0.006643</td>\n",
       "      <td>-0.001674</td>\n",
       "      <td>0.485230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.199289</td>\n",
       "      <td>-0.056818</td>\n",
       "      <td>0.411353</td>\n",
       "      <td>-0.055383</td>\n",
       "      <td>0.481348</td>\n",
       "      <td>0.039268</td>\n",
       "      <td>-0.078979</td>\n",
       "      <td>0.020119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Years of Credit History</th>\n",
       "      <td>0.019282</td>\n",
       "      <td>-0.009720</td>\n",
       "      <td>0.161669</td>\n",
       "      <td>0.199289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.044292</td>\n",
       "      <td>0.132349</td>\n",
       "      <td>0.061588</td>\n",
       "      <td>0.208470</td>\n",
       "      <td>0.031124</td>\n",
       "      <td>0.066247</td>\n",
       "      <td>0.017245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Months since last delinquent</th>\n",
       "      <td>0.011248</td>\n",
       "      <td>-0.003739</td>\n",
       "      <td>-0.077577</td>\n",
       "      <td>-0.056818</td>\n",
       "      <td>-0.044292</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.032569</td>\n",
       "      <td>0.104642</td>\n",
       "      <td>-0.028662</td>\n",
       "      <td>-0.008785</td>\n",
       "      <td>0.123951</td>\n",
       "      <td>0.012624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Open Accounts</th>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.006435</td>\n",
       "      <td>0.146175</td>\n",
       "      <td>0.411353</td>\n",
       "      <td>0.132349</td>\n",
       "      <td>-0.032569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.013995</td>\n",
       "      <td>0.228136</td>\n",
       "      <td>0.031341</td>\n",
       "      <td>-0.024575</td>\n",
       "      <td>0.006545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Credit Problems</th>\n",
       "      <td>-0.002795</td>\n",
       "      <td>-0.003022</td>\n",
       "      <td>-0.017006</td>\n",
       "      <td>-0.055383</td>\n",
       "      <td>0.061588</td>\n",
       "      <td>0.104642</td>\n",
       "      <td>-0.013995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.112516</td>\n",
       "      <td>-0.012072</td>\n",
       "      <td>0.752942</td>\n",
       "      <td>0.581290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Current Credit Balance</th>\n",
       "      <td>0.003880</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>0.312340</td>\n",
       "      <td>0.481348</td>\n",
       "      <td>0.208470</td>\n",
       "      <td>-0.028662</td>\n",
       "      <td>0.228136</td>\n",
       "      <td>-0.112516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.139204</td>\n",
       "      <td>-0.122603</td>\n",
       "      <td>-0.015645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maximum Open Credit</th>\n",
       "      <td>-0.001271</td>\n",
       "      <td>-0.002827</td>\n",
       "      <td>0.053064</td>\n",
       "      <td>0.039268</td>\n",
       "      <td>0.031124</td>\n",
       "      <td>-0.008785</td>\n",
       "      <td>0.031341</td>\n",
       "      <td>-0.012072</td>\n",
       "      <td>0.139204</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014574</td>\n",
       "      <td>-0.001029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bankruptcies</th>\n",
       "      <td>-0.000608</td>\n",
       "      <td>-0.006935</td>\n",
       "      <td>-0.047672</td>\n",
       "      <td>-0.078979</td>\n",
       "      <td>0.066247</td>\n",
       "      <td>0.123951</td>\n",
       "      <td>-0.024575</td>\n",
       "      <td>0.752942</td>\n",
       "      <td>-0.122603</td>\n",
       "      <td>-0.014574</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tax Liens</th>\n",
       "      <td>-0.002048</td>\n",
       "      <td>0.005146</td>\n",
       "      <td>0.040167</td>\n",
       "      <td>0.020119</td>\n",
       "      <td>0.017245</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>0.006545</td>\n",
       "      <td>0.581290</td>\n",
       "      <td>-0.015645</td>\n",
       "      <td>-0.001029</td>\n",
       "      <td>0.046110</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Current Loan Amount  Credit Score  \\\n",
       "Current Loan Amount                      1.000000     -0.096652   \n",
       "Credit Score                            -0.096652      1.000000   \n",
       "Annual Income                            0.013112     -0.017078   \n",
       "Monthly Debt                            -0.006643     -0.001674   \n",
       "Years of Credit History                  0.019282     -0.009720   \n",
       "Months since last delinquent             0.011248     -0.003739   \n",
       "Number of Open Accounts                  0.001478      0.006435   \n",
       "Number of Credit Problems               -0.002795     -0.003022   \n",
       "Current Credit Balance                   0.003880     -0.000104   \n",
       "Maximum Open Credit                     -0.001271     -0.002827   \n",
       "Bankruptcies                            -0.000608     -0.006935   \n",
       "Tax Liens                               -0.002048      0.005146   \n",
       "\n",
       "                              Annual Income  Monthly Debt  \\\n",
       "Current Loan Amount                0.013112     -0.006643   \n",
       "Credit Score                      -0.017078     -0.001674   \n",
       "Annual Income                      1.000000      0.485230   \n",
       "Monthly Debt                       0.485230      1.000000   \n",
       "Years of Credit History            0.161669      0.199289   \n",
       "Months since last delinquent      -0.077577     -0.056818   \n",
       "Number of Open Accounts            0.146175      0.411353   \n",
       "Number of Credit Problems         -0.017006     -0.055383   \n",
       "Current Credit Balance             0.312340      0.481348   \n",
       "Maximum Open Credit                0.053064      0.039268   \n",
       "Bankruptcies                      -0.047672     -0.078979   \n",
       "Tax Liens                          0.040167      0.020119   \n",
       "\n",
       "                              Years of Credit History  \\\n",
       "Current Loan Amount                          0.019282   \n",
       "Credit Score                                -0.009720   \n",
       "Annual Income                                0.161669   \n",
       "Monthly Debt                                 0.199289   \n",
       "Years of Credit History                      1.000000   \n",
       "Months since last delinquent                -0.044292   \n",
       "Number of Open Accounts                      0.132349   \n",
       "Number of Credit Problems                    0.061588   \n",
       "Current Credit Balance                       0.208470   \n",
       "Maximum Open Credit                          0.031124   \n",
       "Bankruptcies                                 0.066247   \n",
       "Tax Liens                                    0.017245   \n",
       "\n",
       "                              Months since last delinquent  \\\n",
       "Current Loan Amount                               0.011248   \n",
       "Credit Score                                     -0.003739   \n",
       "Annual Income                                    -0.077577   \n",
       "Monthly Debt                                     -0.056818   \n",
       "Years of Credit History                          -0.044292   \n",
       "Months since last delinquent                      1.000000   \n",
       "Number of Open Accounts                          -0.032569   \n",
       "Number of Credit Problems                         0.104642   \n",
       "Current Credit Balance                           -0.028662   \n",
       "Maximum Open Credit                              -0.008785   \n",
       "Bankruptcies                                      0.123951   \n",
       "Tax Liens                                         0.012624   \n",
       "\n",
       "                              Number of Open Accounts  \\\n",
       "Current Loan Amount                          0.001478   \n",
       "Credit Score                                 0.006435   \n",
       "Annual Income                                0.146175   \n",
       "Monthly Debt                                 0.411353   \n",
       "Years of Credit History                      0.132349   \n",
       "Months since last delinquent                -0.032569   \n",
       "Number of Open Accounts                      1.000000   \n",
       "Number of Credit Problems                   -0.013995   \n",
       "Current Credit Balance                       0.228136   \n",
       "Maximum Open Credit                          0.031341   \n",
       "Bankruptcies                                -0.024575   \n",
       "Tax Liens                                    0.006545   \n",
       "\n",
       "                              Number of Credit Problems  \\\n",
       "Current Loan Amount                           -0.002795   \n",
       "Credit Score                                  -0.003022   \n",
       "Annual Income                                 -0.017006   \n",
       "Monthly Debt                                  -0.055383   \n",
       "Years of Credit History                        0.061588   \n",
       "Months since last delinquent                   0.104642   \n",
       "Number of Open Accounts                       -0.013995   \n",
       "Number of Credit Problems                      1.000000   \n",
       "Current Credit Balance                        -0.112516   \n",
       "Maximum Open Credit                           -0.012072   \n",
       "Bankruptcies                                   0.752942   \n",
       "Tax Liens                                      0.581290   \n",
       "\n",
       "                              Current Credit Balance  Maximum Open Credit  \\\n",
       "Current Loan Amount                         0.003880            -0.001271   \n",
       "Credit Score                               -0.000104            -0.002827   \n",
       "Annual Income                               0.312340             0.053064   \n",
       "Monthly Debt                                0.481348             0.039268   \n",
       "Years of Credit History                     0.208470             0.031124   \n",
       "Months since last delinquent               -0.028662            -0.008785   \n",
       "Number of Open Accounts                     0.228136             0.031341   \n",
       "Number of Credit Problems                  -0.112516            -0.012072   \n",
       "Current Credit Balance                      1.000000             0.139204   \n",
       "Maximum Open Credit                         0.139204             1.000000   \n",
       "Bankruptcies                               -0.122603            -0.014574   \n",
       "Tax Liens                                  -0.015645            -0.001029   \n",
       "\n",
       "                              Bankruptcies  Tax Liens  \n",
       "Current Loan Amount              -0.000608  -0.002048  \n",
       "Credit Score                     -0.006935   0.005146  \n",
       "Annual Income                    -0.047672   0.040167  \n",
       "Monthly Debt                     -0.078979   0.020119  \n",
       "Years of Credit History           0.066247   0.017245  \n",
       "Months since last delinquent      0.123951   0.012624  \n",
       "Number of Open Accounts          -0.024575   0.006545  \n",
       "Number of Credit Problems         0.752942   0.581290  \n",
       "Current Credit Balance           -0.122603  -0.015645  \n",
       "Maximum Open Credit              -0.014574  -0.001029  \n",
       "Bankruptcies                      1.000000   0.046110  \n",
       "Tax Liens                         0.046110   1.000000  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSME comparison and understanding the leader board\n",
    "\n",
    "The best models after running for a little under four minutes is around 0.005 about half of that of the 0.010 RSME that we got our simple MLP in notebook one and a quarter of the  0.017 RSME that we got with a simple MLP with the same independent variables. \n",
    "\n",
    "When we run for a short time, under 10 minutes, out leaderboard with be biased towards trre-based methods as the deep learners take much more time to converge.  It is rare to see deep learners in the top 500 models when we run for less than 5 moinutes.\n",
    "\n",
    "We should still plot the results but before we do that let's discuss a big advantage of these models, model interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'StackedEnsemble_AllModels_2_AutoML_6_20220211_154220': 0,\n",
       " 'StackedEnsemble_BestOfFamily_3_AutoML_6_20220211_154220': 1,\n",
       " 'StackedEnsemble_AllModels_1_AutoML_6_20220211_154220': 2,\n",
       " 'StackedEnsemble_BestOfFamily_2_AutoML_6_20220211_154220': 3,\n",
       " 'DRF_1_AutoML_6_20220211_154220': 4,\n",
       " 'GLM_1_AutoML_6_20220211_154220': 12}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_index=0\n",
    "glm_index=0\n",
    "glm_model=''\n",
    "aml_leaderboard_df=aml.leaderboard.as_data_frame()\n",
    "\n",
    "models_dict={}\n",
    "for m in aml_leaderboard_df['model_id']:\n",
    "  models_dict[m]=model_index\n",
    "  if 'StackedEnsemble' not in m:\n",
    "    break\n",
    "  model_index=model_index+1\n",
    "\n",
    "for m in aml_leaderboard_df['model_id']:\n",
    "  if 'GLM' in m:\n",
    "    models_dict[m]=glm_index\n",
    "    break  \n",
    "  glm_index=glm_index+1     \n",
    "models_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(0)\n",
    "StackedEnsemble = h2o.get_model(aml.leaderboard[0,'model_id'])\n",
    "DRF = h2o.get_model(aml.leaderboard[6,'model_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gbm'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DRF.algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9574771394427867"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf = aml.leader.model_performance(df_test)\n",
    "perf.auc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stackedensemble'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StackedEnsemble.algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "import matplotlib.cbook\n",
    "warnings.filterwarnings(\"ignore\", category = matplotlib.cbook.mplDeprecation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable importance plot\n",
    "\n",
    "Variable importance plots in tree-based methods provides a list of the most significant variables in descending order by a measure of the information in each variable. Remember that tree calculates the information content of each variable. A variable importance plot is just a bar chart of each variables information content in decreasing order.\n",
    "\n",
    "It can show actual information estimates or standardized plots like the one below. In a standardized plot the most important variable is always given a value of 1.0. The other variables scores represent their percentage of information relative to the most important variable.\n",
    "\n",
    "Notice that some varibales have almost no information content. Knowing this allows for feature selection by removing unimportant variables. This makes a model more effecient to run and helps prevent overfitting as the unimportant variables can fit noise and, as we saw in notebook one, make strange predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if DRF.algo in ['gbm','drf','xrt','xgboost']:\n",
    "  DRF.varimp_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "glm\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if glm_index != 0:\n",
    "  print(glm_index)\n",
    "  glm_model=h2o.get_model(aml.leaderboard[glm_index,'model_id'])\n",
    "  print(glm_model.algo) \n",
    "  glm_model.std_coef_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\n",
      "StackedEnsemble 0:  0.29541885583920857\n",
      "DRF:  0.33529301532913486\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE:\")\n",
    "print(\"StackedEnsemble 0: \",StackedEnsemble.rmse(train = True))\n",
    "print(\"DRF: \",DRF.rmse(train = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackedEnsemble1:  0.19770487601221942\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRF:  0.34506297343856407\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance_stats(perf):\n",
    "    d={}\n",
    "    try:    \n",
    "      d['mse']=perf.mse()\n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['rmse']=perf.rmse() \n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['null_degrees_of_freedom']=perf.null_degrees_of_freedom()\n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['residual_degrees_of_freedom']=perf.residual_degrees_of_freedom()\n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['residual_deviance']=perf.residual_deviance() \n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['null_deviance']=perf.null_deviance() \n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['aic']=perf.aic() \n",
    "    except:\n",
    "      pass      \n",
    "    try:\n",
    "      d['logloss']=perf.logloss() \n",
    "    except:\n",
    "      pass    \n",
    "    try:\n",
    "      d['auc']=perf.auc()\n",
    "    except:\n",
    "      pass  \n",
    "    try:\n",
    "      d['gini']=perf.gini()\n",
    "    except:\n",
    "      pass    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse': 0.08141213810452512,\n",
       " 'rmse': 0.28532812357796966,\n",
       " 'null_degrees_of_freedom': 7693,\n",
       " 'residual_degrees_of_freedom': 7686,\n",
       " 'residual_deviance': 4193.72753713561,\n",
       " 'null_deviance': 8010.21744969159,\n",
       " 'aic': 4209.72753713561,\n",
       " 'logloss': 0.2725323328005986,\n",
       " 'auc': 0.9574771394427867,\n",
       " 'gini': 0.9149542788855733}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_perf=StackedEnsemble.model_performance(df_test)\n",
    "stats_test={}\n",
    "stats_test=model_performance_stats(mod_perf)\n",
    "stats_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "predictions = DRF.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>Charged Off</th>\n",
       "      <th>Fully Paid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>0.993518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>0.005650</td>\n",
       "      <td>0.994350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>0.257682</td>\n",
       "      <td>0.742318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>0.233283</td>\n",
       "      <td>0.766717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>0.159281</td>\n",
       "      <td>0.840719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      predict  Charged Off  Fully Paid\n",
       "0  Fully Paid     0.006482    0.993518\n",
       "1  Fully Paid     0.005650    0.994350\n",
       "2  Fully Paid     0.257682    0.742318\n",
       "3  Fully Paid     0.233283    0.766717\n",
       "4  Fully Paid     0.159281    0.840719"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=h2o.as_list(predictions)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Dependence Plots\n",
    "\n",
    "Partial dependence plots (PDP) show the dependence between the target response and a set of features, marginalizing over the values of all other features. Intuitively, we can interpret the partial dependence as the expected target response as a function of the feature.\n",
    "\n",
    "The partial dependence plot gives a graphical depiction of the marginal effect of a variable on the response. The effect of a variable is measured in change in the mean response. This helps one answer the question of how changing a variables values would change the outcome.\n",
    "\n",
    "The partial dependence plots show only impact of single variable if others are kept constant. But in many cases, there is interaction between variables. Never-the-less, they are very useful in estimating whether, for example, doubling some predictor varible will double a response or whether that predictor varible is already saturated.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Current Loan Amount', 'Credit Score', 'Annual Income', 'Years in current job', 'Monthly Debt', 'Years of Credit History', 'Months since last delinquent', 'Number of Open Accounts', 'Current Credit Balance']\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PartialDependencePlot progress: |████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      "PartialDependence: Partial Dependence Plot of model StackedEnsemble_BestOfFamily_3_AutoML_5_20220206_22133 on column 'Credit Score'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>mean_response</th>\n",
       "      <th>stddev_response</th>\n",
       "      <th>std_error_mean_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>585.000000</td>\n",
       "      <td>0.618883</td>\n",
       "      <td>0.182664</td>\n",
       "      <td>0.000937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>949.473684</td>\n",
       "      <td>0.852308</td>\n",
       "      <td>0.111566</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1313.947368</td>\n",
       "      <td>0.849681</td>\n",
       "      <td>0.113615</td>\n",
       "      <td>0.000583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1678.421053</td>\n",
       "      <td>0.845109</td>\n",
       "      <td>0.116747</td>\n",
       "      <td>0.000599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2042.894737</td>\n",
       "      <td>0.838447</td>\n",
       "      <td>0.120877</td>\n",
       "      <td>0.000620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2407.368421</td>\n",
       "      <td>0.829953</td>\n",
       "      <td>0.125891</td>\n",
       "      <td>0.000646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2771.842105</td>\n",
       "      <td>0.820060</td>\n",
       "      <td>0.131549</td>\n",
       "      <td>0.000675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3136.315789</td>\n",
       "      <td>0.808097</td>\n",
       "      <td>0.138008</td>\n",
       "      <td>0.000708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3500.789474</td>\n",
       "      <td>0.075017</td>\n",
       "      <td>0.128509</td>\n",
       "      <td>0.000659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3865.263158</td>\n",
       "      <td>0.053367</td>\n",
       "      <td>0.129564</td>\n",
       "      <td>0.000665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4229.736842</td>\n",
       "      <td>0.049854</td>\n",
       "      <td>0.125228</td>\n",
       "      <td>0.000642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4594.210526</td>\n",
       "      <td>0.047821</td>\n",
       "      <td>0.120546</td>\n",
       "      <td>0.000618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4958.684211</td>\n",
       "      <td>0.045973</td>\n",
       "      <td>0.115945</td>\n",
       "      <td>0.000595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5323.157895</td>\n",
       "      <td>0.044186</td>\n",
       "      <td>0.111490</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5687.631579</td>\n",
       "      <td>0.042464</td>\n",
       "      <td>0.107195</td>\n",
       "      <td>0.000550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6052.105263</td>\n",
       "      <td>0.040809</td>\n",
       "      <td>0.103061</td>\n",
       "      <td>0.000529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6416.578947</td>\n",
       "      <td>0.039221</td>\n",
       "      <td>0.099091</td>\n",
       "      <td>0.000508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6781.052632</td>\n",
       "      <td>0.037695</td>\n",
       "      <td>0.095274</td>\n",
       "      <td>0.000489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7145.526316</td>\n",
       "      <td>0.036218</td>\n",
       "      <td>0.091580</td>\n",
       "      <td>0.000470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7510.000000</td>\n",
       "      <td>0.034781</td>\n",
       "      <td>0.087987</td>\n",
       "      <td>0.000451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    credit_score  mean_response  stddev_response  std_error_mean_response\n",
       "0     585.000000       0.618883         0.182664                 0.000937\n",
       "1     949.473684       0.852308         0.111566                 0.000572\n",
       "2    1313.947368       0.849681         0.113615                 0.000583\n",
       "3    1678.421053       0.845109         0.116747                 0.000599\n",
       "4    2042.894737       0.838447         0.120877                 0.000620\n",
       "5    2407.368421       0.829953         0.125891                 0.000646\n",
       "6    2771.842105       0.820060         0.131549                 0.000675\n",
       "7    3136.315789       0.808097         0.138008                 0.000708\n",
       "8    3500.789474       0.075017         0.128509                 0.000659\n",
       "9    3865.263158       0.053367         0.129564                 0.000665\n",
       "10   4229.736842       0.049854         0.125228                 0.000642\n",
       "11   4594.210526       0.047821         0.120546                 0.000618\n",
       "12   4958.684211       0.045973         0.115945                 0.000595\n",
       "13   5323.157895       0.044186         0.111490                 0.000572\n",
       "14   5687.631579       0.042464         0.107195                 0.000550\n",
       "15   6052.105263       0.040809         0.103061                 0.000529\n",
       "16   6416.578947       0.039221         0.099091                 0.000508\n",
       "17   6781.052632       0.037695         0.095274                 0.000489\n",
       "18   7145.526316       0.036218         0.091580                 0.000470\n",
       "19   7510.000000       0.034781         0.087987                 0.000451"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model.partial_plot(df, cols=['Credit Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PartialDependencePlot progress: |████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      "PartialDependence: Partial Dependence Plot of model XGBoost_grid_1_AutoML_2_20220105_04416_model_38 on column 'total_night_minutes'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>mean_response</th>\n",
       "      <th>stddev_response</th>\n",
       "      <th>std_error_mean_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145492</td>\n",
       "      <td>0.292157</td>\n",
       "      <td>0.004481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.789474</td>\n",
       "      <td>0.155559</td>\n",
       "      <td>0.273375</td>\n",
       "      <td>0.004193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.578947</td>\n",
       "      <td>0.155559</td>\n",
       "      <td>0.273375</td>\n",
       "      <td>0.004193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62.368421</td>\n",
       "      <td>0.155559</td>\n",
       "      <td>0.273375</td>\n",
       "      <td>0.004193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.157895</td>\n",
       "      <td>0.146292</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.004232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>103.947368</td>\n",
       "      <td>0.139571</td>\n",
       "      <td>0.278033</td>\n",
       "      <td>0.004265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>124.736842</td>\n",
       "      <td>0.128394</td>\n",
       "      <td>0.281864</td>\n",
       "      <td>0.004324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>145.526316</td>\n",
       "      <td>0.138995</td>\n",
       "      <td>0.291898</td>\n",
       "      <td>0.004478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>166.315789</td>\n",
       "      <td>0.132286</td>\n",
       "      <td>0.294610</td>\n",
       "      <td>0.004519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>187.105263</td>\n",
       "      <td>0.132010</td>\n",
       "      <td>0.299338</td>\n",
       "      <td>0.004592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>207.894737</td>\n",
       "      <td>0.131962</td>\n",
       "      <td>0.300427</td>\n",
       "      <td>0.004608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>228.684211</td>\n",
       "      <td>0.143154</td>\n",
       "      <td>0.309527</td>\n",
       "      <td>0.004748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>249.473684</td>\n",
       "      <td>0.153509</td>\n",
       "      <td>0.312596</td>\n",
       "      <td>0.004795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>270.263158</td>\n",
       "      <td>0.161694</td>\n",
       "      <td>0.305106</td>\n",
       "      <td>0.004680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>291.052632</td>\n",
       "      <td>0.151753</td>\n",
       "      <td>0.301781</td>\n",
       "      <td>0.004629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>311.842105</td>\n",
       "      <td>0.150226</td>\n",
       "      <td>0.302285</td>\n",
       "      <td>0.004637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>332.631579</td>\n",
       "      <td>0.154091</td>\n",
       "      <td>0.301428</td>\n",
       "      <td>0.004624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>353.421053</td>\n",
       "      <td>0.154091</td>\n",
       "      <td>0.301428</td>\n",
       "      <td>0.004624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>374.210526</td>\n",
       "      <td>0.154091</td>\n",
       "      <td>0.301428</td>\n",
       "      <td>0.004624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>395.000000</td>\n",
       "      <td>0.154091</td>\n",
       "      <td>0.301428</td>\n",
       "      <td>0.004624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    total_night_minutes  mean_response  stddev_response  \\\n",
       "0              0.000000       0.145492         0.292157   \n",
       "1             20.789474       0.155559         0.273375   \n",
       "2             41.578947       0.155559         0.273375   \n",
       "3             62.368421       0.155559         0.273375   \n",
       "4             83.157895       0.146292         0.275862   \n",
       "5            103.947368       0.139571         0.278033   \n",
       "6            124.736842       0.128394         0.281864   \n",
       "7            145.526316       0.138995         0.291898   \n",
       "8            166.315789       0.132286         0.294610   \n",
       "9            187.105263       0.132010         0.299338   \n",
       "10           207.894737       0.131962         0.300427   \n",
       "11           228.684211       0.143154         0.309527   \n",
       "12           249.473684       0.153509         0.312596   \n",
       "13           270.263158       0.161694         0.305106   \n",
       "14           291.052632       0.151753         0.301781   \n",
       "15           311.842105       0.150226         0.302285   \n",
       "16           332.631579       0.154091         0.301428   \n",
       "17           353.421053       0.154091         0.301428   \n",
       "18           374.210526       0.154091         0.301428   \n",
       "19           395.000000       0.154091         0.301428   \n",
       "\n",
       "    std_error_mean_response  \n",
       "0                  0.004481  \n",
       "1                  0.004193  \n",
       "2                  0.004193  \n",
       "3                  0.004193  \n",
       "4                  0.004232  \n",
       "5                  0.004265  \n",
       "6                  0.004324  \n",
       "7                  0.004478  \n",
       "8                  0.004519  \n",
       "9                  0.004592  \n",
       "10                 0.004608  \n",
       "11                 0.004748  \n",
       "12                 0.004795  \n",
       "13                 0.004680  \n",
       "14                 0.004629  \n",
       "15                 0.004637  \n",
       "16                 0.004624  \n",
       "17                 0.004624  \n",
       "18                 0.004624  \n",
       "19                 0.004624  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PartialDependence: Partial Dependence Plot of model XGBoost_grid_1_AutoML_2_20220105_04416_model_38 on column 'total_night_calls'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>mean_response</th>\n",
       "      <th>stddev_response</th>\n",
       "      <th>std_error_mean_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150574</td>\n",
       "      <td>0.301262</td>\n",
       "      <td>0.004621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.210526</td>\n",
       "      <td>0.145746</td>\n",
       "      <td>0.300862</td>\n",
       "      <td>0.004615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.421053</td>\n",
       "      <td>0.145746</td>\n",
       "      <td>0.300862</td>\n",
       "      <td>0.004615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.631579</td>\n",
       "      <td>0.145746</td>\n",
       "      <td>0.300862</td>\n",
       "      <td>0.004615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.842105</td>\n",
       "      <td>0.145746</td>\n",
       "      <td>0.300862</td>\n",
       "      <td>0.004615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>46.052632</td>\n",
       "      <td>0.145746</td>\n",
       "      <td>0.300862</td>\n",
       "      <td>0.004615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>55.263158</td>\n",
       "      <td>0.145746</td>\n",
       "      <td>0.300862</td>\n",
       "      <td>0.004615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64.473684</td>\n",
       "      <td>0.146469</td>\n",
       "      <td>0.304787</td>\n",
       "      <td>0.004675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>73.684211</td>\n",
       "      <td>0.140882</td>\n",
       "      <td>0.304604</td>\n",
       "      <td>0.004672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>82.894737</td>\n",
       "      <td>0.144011</td>\n",
       "      <td>0.303371</td>\n",
       "      <td>0.004653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>92.105263</td>\n",
       "      <td>0.128856</td>\n",
       "      <td>0.305818</td>\n",
       "      <td>0.004691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>101.315789</td>\n",
       "      <td>0.133357</td>\n",
       "      <td>0.306105</td>\n",
       "      <td>0.004695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>110.526316</td>\n",
       "      <td>0.139868</td>\n",
       "      <td>0.308420</td>\n",
       "      <td>0.004731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>119.736842</td>\n",
       "      <td>0.148893</td>\n",
       "      <td>0.309306</td>\n",
       "      <td>0.004745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>128.947368</td>\n",
       "      <td>0.151950</td>\n",
       "      <td>0.308107</td>\n",
       "      <td>0.004726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>138.157895</td>\n",
       "      <td>0.132255</td>\n",
       "      <td>0.299722</td>\n",
       "      <td>0.004598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>147.368421</td>\n",
       "      <td>0.134927</td>\n",
       "      <td>0.299953</td>\n",
       "      <td>0.004601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>156.578947</td>\n",
       "      <td>0.136573</td>\n",
       "      <td>0.300046</td>\n",
       "      <td>0.004603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>165.789474</td>\n",
       "      <td>0.136573</td>\n",
       "      <td>0.300046</td>\n",
       "      <td>0.004603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>175.000000</td>\n",
       "      <td>0.136573</td>\n",
       "      <td>0.300046</td>\n",
       "      <td>0.004603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    total_night_calls  mean_response  stddev_response  std_error_mean_response\n",
       "0            0.000000       0.150574         0.301262                 0.004621\n",
       "1            9.210526       0.145746         0.300862                 0.004615\n",
       "2           18.421053       0.145746         0.300862                 0.004615\n",
       "3           27.631579       0.145746         0.300862                 0.004615\n",
       "4           36.842105       0.145746         0.300862                 0.004615\n",
       "5           46.052632       0.145746         0.300862                 0.004615\n",
       "6           55.263158       0.145746         0.300862                 0.004615\n",
       "7           64.473684       0.146469         0.304787                 0.004675\n",
       "8           73.684211       0.140882         0.304604                 0.004672\n",
       "9           82.894737       0.144011         0.303371                 0.004653\n",
       "10          92.105263       0.128856         0.305818                 0.004691\n",
       "11         101.315789       0.133357         0.306105                 0.004695\n",
       "12         110.526316       0.139868         0.308420                 0.004731\n",
       "13         119.736842       0.148893         0.309306                 0.004745\n",
       "14         128.947368       0.151950         0.308107                 0.004726\n",
       "15         138.157895       0.132255         0.299722                 0.004598\n",
       "16         147.368421       0.134927         0.299953                 0.004601\n",
       "17         156.578947       0.136573         0.300046                 0.004603\n",
       "18         165.789474       0.136573         0.300046                 0.004603\n",
       "19         175.000000       0.136573         0.300046                 0.004603"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PartialDependence: Partial Dependence Plot of model XGBoost_grid_1_AutoML_2_20220105_04416_model_38 on column 'total_night_charge'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>mean_response</th>\n",
       "      <th>stddev_response</th>\n",
       "      <th>std_error_mean_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148855</td>\n",
       "      <td>0.308347</td>\n",
       "      <td>0.004730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.935263</td>\n",
       "      <td>0.129909</td>\n",
       "      <td>0.296866</td>\n",
       "      <td>0.004554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.870526</td>\n",
       "      <td>0.129909</td>\n",
       "      <td>0.296866</td>\n",
       "      <td>0.004554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.805789</td>\n",
       "      <td>0.129909</td>\n",
       "      <td>0.296866</td>\n",
       "      <td>0.004554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.741053</td>\n",
       "      <td>0.129909</td>\n",
       "      <td>0.296866</td>\n",
       "      <td>0.004554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.676316</td>\n",
       "      <td>0.128446</td>\n",
       "      <td>0.296547</td>\n",
       "      <td>0.004549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.611579</td>\n",
       "      <td>0.134405</td>\n",
       "      <td>0.300846</td>\n",
       "      <td>0.004615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.546842</td>\n",
       "      <td>0.134469</td>\n",
       "      <td>0.301226</td>\n",
       "      <td>0.004621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.482105</td>\n",
       "      <td>0.136227</td>\n",
       "      <td>0.303389</td>\n",
       "      <td>0.004654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.417368</td>\n",
       "      <td>0.140720</td>\n",
       "      <td>0.312751</td>\n",
       "      <td>0.004797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.352632</td>\n",
       "      <td>0.140988</td>\n",
       "      <td>0.312812</td>\n",
       "      <td>0.004798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.287895</td>\n",
       "      <td>0.140525</td>\n",
       "      <td>0.312470</td>\n",
       "      <td>0.004793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.223158</td>\n",
       "      <td>0.143247</td>\n",
       "      <td>0.311254</td>\n",
       "      <td>0.004774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12.158421</td>\n",
       "      <td>0.144081</td>\n",
       "      <td>0.311301</td>\n",
       "      <td>0.004775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13.093684</td>\n",
       "      <td>0.158458</td>\n",
       "      <td>0.306803</td>\n",
       "      <td>0.004706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.028947</td>\n",
       "      <td>0.166586</td>\n",
       "      <td>0.306470</td>\n",
       "      <td>0.004701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.964211</td>\n",
       "      <td>0.166586</td>\n",
       "      <td>0.306470</td>\n",
       "      <td>0.004701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15.899474</td>\n",
       "      <td>0.166586</td>\n",
       "      <td>0.306470</td>\n",
       "      <td>0.004701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16.834737</td>\n",
       "      <td>0.166586</td>\n",
       "      <td>0.306470</td>\n",
       "      <td>0.004701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17.770000</td>\n",
       "      <td>0.166586</td>\n",
       "      <td>0.306470</td>\n",
       "      <td>0.004701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    total_night_charge  mean_response  stddev_response  \\\n",
       "0             0.000000       0.148855         0.308347   \n",
       "1             0.935263       0.129909         0.296866   \n",
       "2             1.870526       0.129909         0.296866   \n",
       "3             2.805789       0.129909         0.296866   \n",
       "4             3.741053       0.129909         0.296866   \n",
       "5             4.676316       0.128446         0.296547   \n",
       "6             5.611579       0.134405         0.300846   \n",
       "7             6.546842       0.134469         0.301226   \n",
       "8             7.482105       0.136227         0.303389   \n",
       "9             8.417368       0.140720         0.312751   \n",
       "10            9.352632       0.140988         0.312812   \n",
       "11           10.287895       0.140525         0.312470   \n",
       "12           11.223158       0.143247         0.311254   \n",
       "13           12.158421       0.144081         0.311301   \n",
       "14           13.093684       0.158458         0.306803   \n",
       "15           14.028947       0.166586         0.306470   \n",
       "16           14.964211       0.166586         0.306470   \n",
       "17           15.899474       0.166586         0.306470   \n",
       "18           16.834737       0.166586         0.306470   \n",
       "19           17.770000       0.166586         0.306470   \n",
       "\n",
       "    std_error_mean_response  \n",
       "0                  0.004730  \n",
       "1                  0.004554  \n",
       "2                  0.004554  \n",
       "3                  0.004554  \n",
       "4                  0.004554  \n",
       "5                  0.004549  \n",
       "6                  0.004615  \n",
       "7                  0.004621  \n",
       "8                  0.004654  \n",
       "9                  0.004797  \n",
       "10                 0.004798  \n",
       "11                 0.004793  \n",
       "12                 0.004774  \n",
       "13                 0.004775  \n",
       "14                 0.004706  \n",
       "15                 0.004701  \n",
       "16                 0.004701  \n",
       "17                 0.004701  \n",
       "18                 0.004701  \n",
       "19                 0.004701  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PartialDependence: Partial Dependence Plot of model XGBoost_grid_1_AutoML_2_20220105_04416_model_38 on column 'total_intl_minutes'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>mean_response</th>\n",
       "      <th>stddev_response</th>\n",
       "      <th>std_error_mean_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153131</td>\n",
       "      <td>0.322031</td>\n",
       "      <td>0.004940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.052632</td>\n",
       "      <td>0.122645</td>\n",
       "      <td>0.269367</td>\n",
       "      <td>0.004132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.105263</td>\n",
       "      <td>0.122645</td>\n",
       "      <td>0.269367</td>\n",
       "      <td>0.004132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.157895</td>\n",
       "      <td>0.122627</td>\n",
       "      <td>0.269373</td>\n",
       "      <td>0.004132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.210526</td>\n",
       "      <td>0.126221</td>\n",
       "      <td>0.270846</td>\n",
       "      <td>0.004155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.263158</td>\n",
       "      <td>0.148876</td>\n",
       "      <td>0.274467</td>\n",
       "      <td>0.004210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.315789</td>\n",
       "      <td>0.125597</td>\n",
       "      <td>0.276151</td>\n",
       "      <td>0.004236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.368421</td>\n",
       "      <td>0.127232</td>\n",
       "      <td>0.285701</td>\n",
       "      <td>0.004382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.421053</td>\n",
       "      <td>0.126895</td>\n",
       "      <td>0.291440</td>\n",
       "      <td>0.004470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.473684</td>\n",
       "      <td>0.126380</td>\n",
       "      <td>0.291530</td>\n",
       "      <td>0.004472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.526316</td>\n",
       "      <td>0.142623</td>\n",
       "      <td>0.293416</td>\n",
       "      <td>0.004501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.578947</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>0.294256</td>\n",
       "      <td>0.004514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.631579</td>\n",
       "      <td>0.125653</td>\n",
       "      <td>0.289760</td>\n",
       "      <td>0.004445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.684211</td>\n",
       "      <td>0.185263</td>\n",
       "      <td>0.346046</td>\n",
       "      <td>0.005308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.736842</td>\n",
       "      <td>0.183892</td>\n",
       "      <td>0.347253</td>\n",
       "      <td>0.005327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.789474</td>\n",
       "      <td>0.206687</td>\n",
       "      <td>0.347551</td>\n",
       "      <td>0.005331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.842105</td>\n",
       "      <td>0.221515</td>\n",
       "      <td>0.351010</td>\n",
       "      <td>0.005384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.894737</td>\n",
       "      <td>0.221515</td>\n",
       "      <td>0.351010</td>\n",
       "      <td>0.005384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.947368</td>\n",
       "      <td>0.221515</td>\n",
       "      <td>0.351010</td>\n",
       "      <td>0.005384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.221515</td>\n",
       "      <td>0.351010</td>\n",
       "      <td>0.005384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    total_intl_minutes  mean_response  stddev_response  \\\n",
       "0             0.000000       0.153131         0.322031   \n",
       "1             1.052632       0.122645         0.269367   \n",
       "2             2.105263       0.122645         0.269367   \n",
       "3             3.157895       0.122627         0.269373   \n",
       "4             4.210526       0.126221         0.270846   \n",
       "5             5.263158       0.148876         0.274467   \n",
       "6             6.315789       0.125597         0.276151   \n",
       "7             7.368421       0.127232         0.285701   \n",
       "8             8.421053       0.126895         0.291440   \n",
       "9             9.473684       0.126380         0.291530   \n",
       "10           10.526316       0.142623         0.293416   \n",
       "11           11.578947       0.125400         0.294256   \n",
       "12           12.631579       0.125653         0.289760   \n",
       "13           13.684211       0.185263         0.346046   \n",
       "14           14.736842       0.183892         0.347253   \n",
       "15           15.789474       0.206687         0.347551   \n",
       "16           16.842105       0.221515         0.351010   \n",
       "17           17.894737       0.221515         0.351010   \n",
       "18           18.947368       0.221515         0.351010   \n",
       "19           20.000000       0.221515         0.351010   \n",
       "\n",
       "    std_error_mean_response  \n",
       "0                  0.004940  \n",
       "1                  0.004132  \n",
       "2                  0.004132  \n",
       "3                  0.004132  \n",
       "4                  0.004155  \n",
       "5                  0.004210  \n",
       "6                  0.004236  \n",
       "7                  0.004382  \n",
       "8                  0.004470  \n",
       "9                  0.004472  \n",
       "10                 0.004501  \n",
       "11                 0.004514  \n",
       "12                 0.004445  \n",
       "13                 0.005308  \n",
       "14                 0.005327  \n",
       "15                 0.005331  \n",
       "16                 0.005384  \n",
       "17                 0.005384  \n",
       "18                 0.005384  \n",
       "19                 0.005384  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PartialDependence: Partial Dependence Plot of model XGBoost_grid_1_AutoML_2_20220105_04416_model_38 on column 'total_intl_calls'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>mean_response</th>\n",
       "      <th>stddev_response</th>\n",
       "      <th>std_error_mean_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111660</td>\n",
       "      <td>0.283546</td>\n",
       "      <td>0.004349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.052632</td>\n",
       "      <td>0.209079</td>\n",
       "      <td>0.355043</td>\n",
       "      <td>0.005446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.105263</td>\n",
       "      <td>0.202500</td>\n",
       "      <td>0.356481</td>\n",
       "      <td>0.005468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.157895</td>\n",
       "      <td>0.119923</td>\n",
       "      <td>0.288878</td>\n",
       "      <td>0.004431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.210526</td>\n",
       "      <td>0.121502</td>\n",
       "      <td>0.290763</td>\n",
       "      <td>0.004460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.263158</td>\n",
       "      <td>0.126923</td>\n",
       "      <td>0.291407</td>\n",
       "      <td>0.004470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.315789</td>\n",
       "      <td>0.126766</td>\n",
       "      <td>0.290208</td>\n",
       "      <td>0.004452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.368421</td>\n",
       "      <td>0.117001</td>\n",
       "      <td>0.286729</td>\n",
       "      <td>0.004398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.421053</td>\n",
       "      <td>0.113284</td>\n",
       "      <td>0.287555</td>\n",
       "      <td>0.004411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.473684</td>\n",
       "      <td>0.115109</td>\n",
       "      <td>0.287522</td>\n",
       "      <td>0.004410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.526316</td>\n",
       "      <td>0.126882</td>\n",
       "      <td>0.287538</td>\n",
       "      <td>0.004411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.578947</td>\n",
       "      <td>0.128065</td>\n",
       "      <td>0.287212</td>\n",
       "      <td>0.004406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.631579</td>\n",
       "      <td>0.135448</td>\n",
       "      <td>0.284843</td>\n",
       "      <td>0.004369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.684211</td>\n",
       "      <td>0.136403</td>\n",
       "      <td>0.284658</td>\n",
       "      <td>0.004366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.736842</td>\n",
       "      <td>0.161867</td>\n",
       "      <td>0.276335</td>\n",
       "      <td>0.004239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.789474</td>\n",
       "      <td>0.156694</td>\n",
       "      <td>0.275624</td>\n",
       "      <td>0.004228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.842105</td>\n",
       "      <td>0.156694</td>\n",
       "      <td>0.275624</td>\n",
       "      <td>0.004228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.894737</td>\n",
       "      <td>0.156694</td>\n",
       "      <td>0.275624</td>\n",
       "      <td>0.004228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.947368</td>\n",
       "      <td>0.156694</td>\n",
       "      <td>0.275624</td>\n",
       "      <td>0.004228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.156694</td>\n",
       "      <td>0.275624</td>\n",
       "      <td>0.004228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    total_intl_calls  mean_response  stddev_response  std_error_mean_response\n",
       "0           0.000000       0.111660         0.283546                 0.004349\n",
       "1           1.052632       0.209079         0.355043                 0.005446\n",
       "2           2.105263       0.202500         0.356481                 0.005468\n",
       "3           3.157895       0.119923         0.288878                 0.004431\n",
       "4           4.210526       0.121502         0.290763                 0.004460\n",
       "5           5.263158       0.126923         0.291407                 0.004470\n",
       "6           6.315789       0.126766         0.290208                 0.004452\n",
       "7           7.368421       0.117001         0.286729                 0.004398\n",
       "8           8.421053       0.113284         0.287555                 0.004411\n",
       "9           9.473684       0.115109         0.287522                 0.004410\n",
       "10         10.526316       0.126882         0.287538                 0.004411\n",
       "11         11.578947       0.128065         0.287212                 0.004406\n",
       "12         12.631579       0.135448         0.284843                 0.004369\n",
       "13         13.684211       0.136403         0.284658                 0.004366\n",
       "14         14.736842       0.161867         0.276335                 0.004239\n",
       "15         15.789474       0.156694         0.275624                 0.004228\n",
       "16         16.842105       0.156694         0.275624                 0.004228\n",
       "17         17.894737       0.156694         0.275624                 0.004228\n",
       "18         18.947368       0.156694         0.275624                 0.004228\n",
       "19         20.000000       0.156694         0.275624                 0.004228"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PartialDependence: Partial Dependence Plot of model XGBoost_grid_1_AutoML_2_20220105_04416_model_38 on column 'total_intl_charge'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>mean_response</th>\n",
       "      <th>stddev_response</th>\n",
       "      <th>std_error_mean_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140562</td>\n",
       "      <td>0.304946</td>\n",
       "      <td>0.004678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.284211</td>\n",
       "      <td>0.136506</td>\n",
       "      <td>0.304033</td>\n",
       "      <td>0.004664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.568421</td>\n",
       "      <td>0.136506</td>\n",
       "      <td>0.304033</td>\n",
       "      <td>0.004664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.852632</td>\n",
       "      <td>0.136506</td>\n",
       "      <td>0.304033</td>\n",
       "      <td>0.004664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.136842</td>\n",
       "      <td>0.136506</td>\n",
       "      <td>0.304033</td>\n",
       "      <td>0.004664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.421053</td>\n",
       "      <td>0.138476</td>\n",
       "      <td>0.304981</td>\n",
       "      <td>0.004678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.705263</td>\n",
       "      <td>0.138505</td>\n",
       "      <td>0.305241</td>\n",
       "      <td>0.004682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.989474</td>\n",
       "      <td>0.135278</td>\n",
       "      <td>0.307354</td>\n",
       "      <td>0.004715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.273684</td>\n",
       "      <td>0.136394</td>\n",
       "      <td>0.307468</td>\n",
       "      <td>0.004716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.557895</td>\n",
       "      <td>0.138427</td>\n",
       "      <td>0.307451</td>\n",
       "      <td>0.004716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.842105</td>\n",
       "      <td>0.139768</td>\n",
       "      <td>0.307018</td>\n",
       "      <td>0.004709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.126316</td>\n",
       "      <td>0.137676</td>\n",
       "      <td>0.305336</td>\n",
       "      <td>0.004684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.410526</td>\n",
       "      <td>0.138255</td>\n",
       "      <td>0.305479</td>\n",
       "      <td>0.004686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.694737</td>\n",
       "      <td>0.145518</td>\n",
       "      <td>0.305048</td>\n",
       "      <td>0.004679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.978947</td>\n",
       "      <td>0.146019</td>\n",
       "      <td>0.304959</td>\n",
       "      <td>0.004678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.263158</td>\n",
       "      <td>0.146019</td>\n",
       "      <td>0.304959</td>\n",
       "      <td>0.004678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.547368</td>\n",
       "      <td>0.159912</td>\n",
       "      <td>0.303405</td>\n",
       "      <td>0.004654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.831579</td>\n",
       "      <td>0.159912</td>\n",
       "      <td>0.303405</td>\n",
       "      <td>0.004654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.115789</td>\n",
       "      <td>0.159912</td>\n",
       "      <td>0.303405</td>\n",
       "      <td>0.004654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.400000</td>\n",
       "      <td>0.159912</td>\n",
       "      <td>0.303405</td>\n",
       "      <td>0.004654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    total_intl_charge  mean_response  stddev_response  std_error_mean_response\n",
       "0            0.000000       0.140562         0.304946                 0.004678\n",
       "1            0.284211       0.136506         0.304033                 0.004664\n",
       "2            0.568421       0.136506         0.304033                 0.004664\n",
       "3            0.852632       0.136506         0.304033                 0.004664\n",
       "4            1.136842       0.136506         0.304033                 0.004664\n",
       "5            1.421053       0.138476         0.304981                 0.004678\n",
       "6            1.705263       0.138505         0.305241                 0.004682\n",
       "7            1.989474       0.135278         0.307354                 0.004715\n",
       "8            2.273684       0.136394         0.307468                 0.004716\n",
       "9            2.557895       0.138427         0.307451                 0.004716\n",
       "10           2.842105       0.139768         0.307018                 0.004709\n",
       "11           3.126316       0.137676         0.305336                 0.004684\n",
       "12           3.410526       0.138255         0.305479                 0.004686\n",
       "13           3.694737       0.145518         0.305048                 0.004679\n",
       "14           3.978947       0.146019         0.304959                 0.004678\n",
       "15           4.263158       0.146019         0.304959                 0.004678\n",
       "16           4.547368       0.159912         0.303405                 0.004654\n",
       "17           4.831579       0.159912         0.303405                 0.004654\n",
       "18           5.115789       0.159912         0.303405                 0.004654\n",
       "19           5.400000       0.159912         0.303405                 0.004654"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PartialDependence: Partial Dependence Plot of model XGBoost_grid_1_AutoML_2_20220105_04416_model_38 on column 'number_customer_service_calls'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "      <th>mean_response</th>\n",
       "      <th>stddev_response</th>\n",
       "      <th>std_error_mean_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103336</td>\n",
       "      <td>0.274623</td>\n",
       "      <td>0.004213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.112095</td>\n",
       "      <td>0.275230</td>\n",
       "      <td>0.004222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.109374</td>\n",
       "      <td>0.276090</td>\n",
       "      <td>0.004235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.112979</td>\n",
       "      <td>0.275245</td>\n",
       "      <td>0.004222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.466441</td>\n",
       "      <td>0.398941</td>\n",
       "      <td>0.006119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.517436</td>\n",
       "      <td>0.366782</td>\n",
       "      <td>0.005626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.519288</td>\n",
       "      <td>0.366584</td>\n",
       "      <td>0.005623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.516813</td>\n",
       "      <td>0.367450</td>\n",
       "      <td>0.005636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.516813</td>\n",
       "      <td>0.367450</td>\n",
       "      <td>0.005636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.517334</td>\n",
       "      <td>0.367249</td>\n",
       "      <td>0.005633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_customer_service_calls  mean_response  stddev_response  \\\n",
       "0                            0.0       0.103336         0.274623   \n",
       "1                            1.0       0.112095         0.275230   \n",
       "2                            2.0       0.109374         0.276090   \n",
       "3                            3.0       0.112979         0.275245   \n",
       "4                            4.0       0.466441         0.398941   \n",
       "5                            5.0       0.517436         0.366782   \n",
       "6                            6.0       0.519288         0.366584   \n",
       "7                            7.0       0.516813         0.367450   \n",
       "8                            8.0       0.516813         0.367450   \n",
       "9                            9.0       0.517334         0.367249   \n",
       "\n",
       "   std_error_mean_response  \n",
       "0                 0.004213  \n",
       "1                 0.004222  \n",
       "2                 0.004235  \n",
       "3                 0.004222  \n",
       "4                 0.006119  \n",
       "5                 0.005626  \n",
       "6                 0.005623  \n",
       "7                 0.005636  \n",
       "8                 0.005636  \n",
       "9                 0.005633  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[, , , , , , ]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf4AAALXCAYAAABsJCJGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAADf5UlEQVR4nOydeZxcRdW/n2/3TPaQsEQkEBJkCbKJGAEXNCggyOaCggsCoiiKoj830PcF5HXDjVcF9UVkUVAWRY2IKFtYVJaELSwGQ0hICARCSMg+S5/fH1U9c6ene/r2TPf0dM95PunMvbWec6vuPVV161bJzHAcx3EcZ3iQqbcAjuM4juMMHm74HcdxHGcY4YbfcRzHcYYRbvgdx3EcZxjhht9xHMdxhhFu+B3HcRxnGOGG33Ecx3GGEW74naojaa2kV6UIN02SSWoZDLlqiaQTJd1VbznSUO3rLmm6pAclrZH02WqkWUskzZS0dIBpHCBp/mDl1x8kbR/vxexg5+0MbdzwD0MkLZK0IT4Ulku6TNK4fqY1W9LHkm5mNs7MFlZRzjWSVkn6p6RPSvJ6W4ZobHKxjNdImi/ppH6kc46kK8oE+zJwm5mNN7Mf90/iivPsd/hqYGZ3mtn0aqQV779vVCOtJGb2dLwXOweaVj2usVM7yj5AJe0i6RZJj8TzvST9V+1Fc2rMkWY2DtgHmAFUVKYKDIYBPtLMxgNTge8AXwF+OQj5NgPLYhlvRrhuv5C0Ww3ymQo82p+IzTDa4zgNh5n1+QNuB/YFHki4PVIunv+G7g9YBByUOP8ecD2wefz7AvBSPN4uEW428E3gH8AG4EqgE9gIrAUuiOEM2CkeHw48ALwMLAHOSaQ3LYZtSSNndNsXyAF7xPORwPeBp4HlwM+B0dFvJrAU+CqwIqb3oURaaeJ+AXgeeBY4KRF3S2BW1Ote4H+AuxL+uwI3ASuB+cD7E36XARcCfwHWAPcAOyb8d0/EXQ58NbpngDOAJ4EXgWuALUpcu5nA0gK3F4BjCq87MDnqshJYAHw8uh8KtAHtsXwfKpLPrQV1YBdgAvCrmN9iQqMyE8OfSKg/50cdvlGQXtE8K5UROAl4PF7fhcAn+ro2fdS/LwIPA6uBq4FRxdIgNKAfiPldG8N+o1xdAk6JsrdF+f+cQqYvRZnWERrBWwN/jXnfDGxe7P4i3L//E6//GuDvwFZ91JdFwEF9XOMJMf9ngWeAbwDZ6LcTwXasJtx7V9f7uee/RNmmqPz3xb8PJNwerLfg/htAoScMKjCF0Fv7H4Ixey8wBhgfH2B/TMSbTTCSuwMtQGt0+1hB+knDPxPYk2C09iIYsndFvx4Ppr7kLHB/Gjg1Hp9PMAhbRJn/DHw7kXcH8EOCkX9rfFhOryDuuVHPdwLrEw/VqwiGdyywR3zw3RX9xhIaOSfF6/Ta+PDbLfpfRjB6+0b/K4Grot/4+CD9AjAqnu8X/U4H7ga2i/r8H/DbEtduJvFBHq/9uwkP7umF1x24A/hpzG9vgsF+W/Q7B7iiTH3qUQcIRv9PUfZpwBPAydHvxHhdPxN1H10kvV55ViojocG5I6BY7uuBfQqvTYr75F5Co2MLQkPik0Wu7whCA+f0WFfeQzCUScPfV126jIIGUBmZ7iYY+20JDYn7CXVsFKEhdnax+yuW05OExtnoeP6dUteEns+JYtf4D4Q6OBZ4RbxWn4h+vwW+Rqh7o4A31/u557/uX5qh2hWSdowVCEnHEB5MTmPzR0mrgLsILfNvmdmLZvZ7M1tvZmsIvfu3FsS7zMweNbMOM2svl4mZzTazeWaWM7OHCQ+EwjQrZRmwhSQRekyfN7OVUeZvAccVhP9vM9tkZrcTetnvTxm3HTjXzNrN7AZCb2d6nCz1XuAsM1tnZo8AlyfiHQEsMrNL43V6APg98L5EmD+Y2b1m1kEw/Hsn4j5nZj8ws41mtsbM7ol+nwS+ZmZLzWwT4WF8TB/D5ZNjGa8AzgaON7MeE9IkTQHeBHwl5vcgcDHwkRJp9km8NscBZ0bZFwE/AI5PBFtmZj+J12ZDijQrltHM/mJmT1rgdkLv9oB+qPRjM1tmZisJDcO9i4TZn9CI+XGsK9cRjGCSonWpH/IA/MTMlpvZM8CdwD1m9oCZbSQY49f2EfdSM3siXvdrSuhTFklbExown4v3wPOEhnT+/mknvAKaHMusISa+DhfSvF/7NHARsKukZ4CngA/XVCpnMHiXmd2cdJA0hnDzHkoY9gcYLylr3ROEllSSiaT9CO/m9yD0jEYSRhIGwraEId9JhNGJucGOhyyB5Czml8xsXeJ8MaEHlybui9Ew51kPjItxW+h5LRYnjqcC+0Wjm6cF+HXi/Lki6UIYgXmS4kwF/iApl3DrJPT+nikSfpmZbVcirTyTgXzDJ89iwryP/rAVoVebvB6LCWWWp6I6RD9klHQYobGzC6HXOQaYV2G+0LucJpeQ7xkzS251WqhjqbrUH5YnjjcUOe8r3VL1rlKmEsr52cT9k6Fb7y8TRhHvlfQS8AMzu6SfeTlVpqzhtzA7+yBJYwnv6daUi+M0LF8g9EL2M7PnJO1NeG+pRBgriFN4XshvgAuAw8xso6T/JRiHfiHp9QQjchehJ7sB2D32foqxuaSxCeO/PfBIyrileIEwdDsF+Hci3TxLgNvN7OAK083HLRyxSPp91Mz+0Y90S5EfPRmfuLe3p7shUa58C1lBd2/vsSLppUmz0L8iGSWNJIywfAT4k5m1S/ojPetxNXkW2FaSEsa/rwZcIZVe41qwjtA4ArpGbiYl/AtlXAJsIswR6Cjww8yeAz4e03ozcLOkO8xsQbUFdyonzaz+0yVtRmgdni/pfkmH1F40pw6MJxjDVZK2IPSYyrEc6Oub/fGE3tpGSfsCH+yPYJI2k3QE4d36FfnXB8AvCPXyFTHctpLeURD965JGSDqAMJR+bQVxexFHP64DzpE0Js6UPyER5HpgF0nHS2qNv9dLenUKVa8HtpH0OUkjJY2PoyYQJh9+U9LUKO8kSUenSLMvXZYA/wS+LWmUpL2Ak4H8p1vLgWlpv+CI1+aaKOf4KOv/S6SXhh559kPG/MjSC0BH7P3X8pn1L8LIy2mSWmKZ7FtB/HL30GDwBDBK0uGSWgkTMkcm/AvL5FnC65MfxHszI2lHSW8FkPQ+SfnRppcIDYfkSJVTR9LczB81s5cJN86WhHd136mpVE69+F/CpJ8VhAlEN6aI8yPCe+aXJBX7hvtTwLmS1gBnEYxCJfw5xl1CmCz0Q8KkuTxfIczyvlvSy4RZzcl3p88RHjzLCO/SP2lm/04Zty9OIwyTPkeYnHVp3iP2Sg8h9NyXxTDn0fNBWpQY92DgyBjvP8CB0ftHhMmIf4/X5G5gv2LpVMgHCBPBlhHeEZ+deA2Ufy3zoqT7U6b3GUIPciFhZOY3QCXDvMXyTC1jvIafJdS1lwiNzVkV5F8RZtZGmNB3MrCK8Cr0ekKPOA2/BHZTWKvij7WQsRxmtppwr15MGElZR/gSIU+xMvkIoZH1GOE6/w7YJvq9HrhH0lrCtT/dqrC2h1Md1PO1VJEA0sNmtpekHwGzzewPkh4ws74mkDhO3ZE0kzA6UO49t+NUFUn3AD83s0vLBnacQSZNj3+upL8TZnD+TdJ4fMjGcRynC0lvlfTKONR/AuHT1TQjZo4z6KSZ1X8y4ZOPhWa2XtKW9BxqdRzHaTgkbU/3BMRCdjOzpytIbjrd6zosBI6J78HrKZPjFKXsUD+ESU+EWbpdDQUzu6OGcjmO4ziOUwPK9vglnQccS2iF5r/lNsJKWo7jOI7jNBBpJvfNB/aKK4VVlrh0KGEmcha42My+U+B/ImGd+Pz3uBeY2cWV5uM4juM4TjrSvONfSFihqSLDHxeAuJDwadJS4D5Js8ys8P3V1WZ2Wtp0J06caDvttFMlojQc69atY+zYsfUWo6Y0u47Nrh+4js1As+sHzaXj3LlzV5jZpPIh+yaN4V8PPCjpFhLG38w+WybevsCC/Lebkq4Cjqb0xJVUbL311syZM2cgSQx5Zs+ezcyZM+stRk1pdh2bXT9wHZuBZtcPmktHSYvLhypPGsM/i/4tfrEtPderXkrxxUbeK+kthJWjPh9X6XIcx3EcpwakndU/grDZBcB8S7Erm8Iufoea2cfi+fGENeBPS4TZElhrZpskfQI41szeViStUwg7qTFp0qTXXXNNpYu/NRZr165l3Lj+7p3RGDS7js2uH7iOzUCz6wfNpeOBBx4418z6u4FWF2lm9c8kbDm6iLDJxRRJJ6T4nO8ZwkYVebajYAcxM3sxcXox8N1iCZnZRYQdApk+fbo1y7BNKZppaKoUza5js+sHrmMz0Oz6wfDQsVLSDPX/ADgkv4+3pF0Ie6q/rky8+4CdJe1AMPjHUbBBi6RtEotcHAU8XoHsjuM4vTAz8gOZlj8HzMDo9qPArTAsQKcZqzcUGeCs1n56Ain0qCTFvyBE9263Pd3yYWP04JYM7DhlSGP4W/NGH8DMnoi7N/WJmXVIOg34G+FzvkvM7FFJ5wJzzGwW8FlJRxG2OF0JnNgfJRzHaUzMjJwl/iYMc866DXL+GIvH9Dbo8V+V5YON7Z3lAw4BFP9Tkd2HS7ULOnLGirXlP9gqFr3YtS725tiKhUznVBU6csbylzfWKPXGJI3hnyPpYrq3wPwQkGpavZndANxQ4HZW4vhM4Mx0osY4wAtrQkXNV+Z8pcy3mHv6dQcqFr7neSWS1I6cwfq2XltcpyKvb6EuPXoPBWEKr0dPt95+wwUrYni6eocFBqjw+uQM1m3qLsNe5VHwKO3P5e3Rcy14bPb0K4xXELbyrIGgf9HecEHiRrdxz1/LWhjp4Y7F/9Ia2jydOS+J4UYaw38q8GnCNpcAdwI/rZlEKcglx/F60BwVOGfGmo39M/yDQS8bVaRR0XWuosHozBkr17X1ci/WYOvpnj8v3mgr1fCBdD3IfK9zoIYpZ8baTUO3DKtBroF6w47jdFPW8McZ9xcAtxB25Zsf9592hil9tbd69TZKWE8D2jt9k0fHcZzBJs2s/sOBnwNPEjpYO0j6hJn9tdbCOY7jOI5TXdLO6j/QzBYASNoR+Avght9xHMdxGoxMijBr8kY/shBYUyN5HMdxHMepIWln9d8AXEN4Nfs+woY77wEws+tqKJ/jOI7jOFUkjeEfBSwH3hrPXwBGA0cSGgJu+B3HcRynQUgzq/+kwRDEcRzHcZzaU/Ydv6TvStpMUqukWyS9IOnDgyGc4ziO4zjVJc3kvkPM7GXgCMJGPTsBX6qlUI7jOI7j1IY0hj//OuBw4FozW11DeRzHcRzHqSFpJvddL+nfwAbgVEmTAN/xwHEcx3EakLI9fjM7A3gjMMPM2oH1wNG1FsxxHMdxnOqTZnLfGOBTwM+i02RgRi2FchzHcRynNqQZ6r8UmEvo9QM8A1wLXF8roRzHcYY6ZkZnzujIGR2dRkcuR3v8G86N9s5cCFPg35kzshnRmsnQ2pKhNStas5n4K36czQy/rbGd2pDG8O9oZsdK+gCAma1XHTdnX9duzHpoGR2dOdo6crTnjPaOHO2d4aYKf8NxW2cuhMv7lQnX3mnF97IeZHKdnWRun11xvKxES+Jh0ZLpfmi0dD1A+ufXkhEtWZHNiJZMeAiF48K/wa8lK7JS93GB/4YOY2N7Z1e8OlYpZwjTGY1nW7x3N8W/bZ052jss/s3Rnkucx19bR46OnHXFTT4Hwj3fd/z2TmPd+g1k7/lHScM+mIT7u+e9OqKl+37NH49oCfeYEPEfUtiyWoltroV4edUmJix+OIZRV1gKzgvTsriddc4gl7PuY7Me7lbolj/O9Q6bS26LXUXaNm5kxJx/VjXNRieN4W+TNJq4wWrcpGdTTaXqgxUbjG/+5fGifiOyGVpberaiR2QztGQz8W84HzOieLhsRmSGgAFasfxZttp6m4riGOHmae8MjaGORAMn+dDa2N5JR77hEx9g7QVh2wZru9xbZ3cdZjPqKr8R8SE2IjY+RrR0/x0RH3p5t5Et5cO0ZjN05rof8m2JB3vyPBgISxiJ4sakvcBg5HL0aPxkMyLX3sboOf8MD+tMhmy2dyOpVCOq8LhUnSxVVcPjuqhHJc5lWfFcG7et/k+fYTqj4S28xr3dihv1zioa12xGXfd6V4+6peczojUrxo9q6WrsrmvZyFaTJtKS6W78tuQbwtHgtmRDObbmG8aJxnNXnCL++UZNYUek2HFbR7xXc93HPRovieNNHeG6WTSi4S9Q5HzDhhyrc+sxwggG0OWfD9vt1n0uQUaKv8RxJjQYsgqNjNAACf7ZjGjtihPC5o8luuJU+xm8amUbE7fYrKpp1ou7qpROGsN/NnAjMEXSlcCbgBOrlH/FbDsuw3WffmOvm7WZeo3z5rzInjN2qVv+ZkanWa9GQX5YszOXH+LMdR93RnfrPu7I5QrCdx8vWfwUr9h2+664hT2uTR25XkZ5fVsHqxNh2jpyPQxIe2flRiIjejYcChqPhcYgGSZvQDJS1DvXdQ1WPP884zffrOQ1yz+cO7quX45OK7iW0b9YD8gqVLVU+IH0rnKdOTLLlvaZZzaj3o2zruPu69rV2GvpfY17uiUaeyUMdzKvgQ6Vz5vzL/acsXu/r9FQJ+i3f73FqClBxz3qLUZV+EWV0unT8EvKAJsD7wH2J3QOTjezFVXKv2JaMrDNhNH1yn5YIIkWiZYMjGrN1iSPeVrKnjOmVTVNMyvZm2zJ9DTWecNQq/em8+asbpqHTSnCA/UN9RbDcZwK6dPwm1lO0pfN7BrgL4Mkk+P0C0mMaAlD/I7jOE5x0jwhb5b0RUlTJG2R/9VcMsdxHMdxqk4aw38s8GngDsJnfXOBOWkSl3SopPmSFkg6o4j/SElXR/97JE2rQHbHcRzHcSokzba8O/TlL+lgM7upiHsWuBA4GFgK3Cdplpk9lgh2MvCSme0k6TjgPEJDw3Ecx3GcGlCNl6HnlXDfF1hgZgvNrA24it5L/R4NXB6Pfwe8vZ5rBDiO4zhOs1MNw1/KUG8LLEmcL41uRcOYWQewGtiyCjI5juM4jlOENN/xl6Pmy1dJOgU4BWDSpEnMm/OvWmdZVzasW+s6NjjNrh+4js1As+sHw0PHSqmG4S/FM8CUxPl20a1YmKWSWoAJwIuFCZnZRcBFALtMn27N/u3wcPg+utl1bHb9wHVsBppdPxgeOlZKNYb6F5Vwvw/YWdIOkkYAxwGzCsLMAk6Ix8cAt5pVuiaZ4ziO4zhpSdXjl/RGYFoyvJn9Kv59T7E4ZtYh6TTgb0AWuMTMHpV0LjDHzGYBvwR+LWkBsJLQOHAcx3Ecp0aUNfySfg3sCDwIdEZnA35VLq6Z3QDcUOB2VuJ4I/C+9OI6juM4jjMQ0vT4ZwC7+RC84ziO4zQ+ad7xPwK8staCOI7jOI5Te9L0+LcCHpN0L7Ap72hmR9VMqipRuGe0EntHq+BvPsxQoCUjXjF+ZL/idu2lnd9bm+69tPP+FHErFociYSgWjsT2rj3/OI7jOEOMNIb/nFoLUQkCRrVkUYYuY13MgDf6AoD9lb87Wv3172ogFDQGzIxsRmwxdkSPhkNhoyTZIClsjBTzs+DpjQ6nbij+J8IzSYR7OfyN7kXGWbtepBY0pJMvWIs1vAvjFzbAS1HLe0QlTlTwTJKKBqv6s1tAa9Z37EySZq3+2wdDkEqYMKa13iI4KcjfwL3vY9X8ZjSzXiMZpajGg6ZwFCSbERNjPe3x8C42+kLvh3m+kRPcrEf8ruMi+fd2T4YvEblQl9JeNaXPUijhmTcm+SLMB+uqe13nveN0/ekjbkZis1Gt3WH6MuoN2Nl4PCO23mxUL/e+7hmzgus5xPXOdzKcbtLM6t8f+AnwamAE4dO8dWa2WY1lc5x+ozgKFM8GI8deZyNbsoOQb/1IGo00c3+HuoEoRkYwekRzl2Mx+iqrBixGp4A0Q/0XEL6vv5Yww/8jwC61FMpxnMaiEY264wxXlGIYdI6ZzZD0sJntFd0eMLPXDoqEveVZA8yvR96DyFbAinoLUWOaXcdm1w9cx2ag2fWD5tJxqplNGmgiaXr86+OSuw9K+i7wLNVZ6re/zDezGXXMv+bkG1v1lqOWNLuOza4fuI7NQLPrB8NDx0pJY8CPj+FOA9YRNtV5by2FchzHcRynNqSZ1b9Y0mhgGzP7+iDI5DiO4zhOjSjb45d0JGGd/hvj+d6SCnfZG0wuqmPeg4Xr2Pg0u37gOjYDza4fDA8dKyLN5L65wNuA2fkJfZLmmdmegyCf4ziO4zhVJM07/nYzW13g5oujOY7jOE4DksbwPyrpg0BW0s6SfgL8s8ZyFUXSoZLmS1og6Yx6yFBtJC2SNE/Sg5LmRLctJN0k6T/x7+b1lrMSJF0i6XlJjyTciuqkwI9jmT4saZ/6SZ6eEjqeI+mZWJYPSnpnwu/MqON8Se+oj9TpkTRF0m2SHpP0qKTTo3vTlGMfOjZTOY6SdK+kh6KOX4/uO0i6J+pydfxyC0kj4/mC6D+trgqUoQ/9LpP0VKIM947uDVdPa0JY2rT0DxgDfBO4L/6+AYwsF6/aP8KKgU8CryKsIPgQYbvgQZWjBnotArYqcPsucEY8PgM4r95yVqjTW4B9gEfK6QS8E/grYbG7/YF76i3/AHQ8B/hikbC7xfo6Etgh1uNsvXUoo982wD7xeDzwRNSjacqxDx2bqRwFjIvHrcA9sXyuAY6L7j8HTo3HnwJ+Ho+PA66utw791O8y4Jgi4Ruuntbil6bHv1v8tQCjgKMJDYDBZl9ggZktNLM24KooSzNyNHB5PL4ceFf9RKkcM7sDWFngXEqno4FfWeBuYKKkbQZF0AFQQsdSHA1cZWabzOwpYAGhPg9ZzOxZM7s/Hq8BHge2pYnKsQ8dS9GI5WhmtjaetsafEeZt/S66F5Zjvnx/B7xdGrrLMvahXykarp7WgjSG/0rgEuA9wBHxd2QthSrBtsCSxPlS+r5JGwUD/i5prqRTotvWZvZsPH4O2Lo+olWVUjo1W7meFocQL0m8omloHeNw72sJvammLMcCHaGJylFSVtKDwPPATYSRilVm1hGDJPXo0jH6rwa2HFSBK6RQPzPLl+E3YxmeLym/z3lDlmG1SWP4XzCzP5vZU2a2OP+ruWTDhzeb2T7AYcCnJb0l6WlhfKqpJlM2o06RnwE7AnsTVrj8QV2lqQKSxgG/Bz5nZi8n/ZqlHIvo2FTlaGadZrY3sB1hhGLX+kpUXQr1k7QHcCZBz9cDWwBfqZ+EQ480hv9sSRdL+oCk9+R/NZesN88QVg3Ms110a2jM7Jn493ngD4Qbc3l++Cn+fb5+ElaNUjo1Tbma2fL4EMoBv6B7GLghdZTUSjCIV5rZddG5qcqxmI7NVo55zGwVcBvwBsIQd34Bt6QeXTpG/wnAi4Mraf9I6HdofI1jZrYJuJQmKcNqkcbwn0Ro+R5KGOI/kjDcP9jcB+wcZ6OOIEw8qedCQgNG0lhJ4/PHwCHAIwS9TojBTgD+VB8Jq0opnWYBH4mzbfcHVieGkhuKgneF7yaUJQQdj4szpncAdgbuHWz5KiG+1/0l8LiZ/TDh1TTlWErHJivHSZImxuPRwMGEuQy3AcfEYIXlmC/fY4Bb48jOkKSEfv9ONE5FmL+QLMOGqqc1odzsP8KmOHWfhWjdMzKfILyj+lq95amCPq8izBJ+CHg0rxPhndotwH+Am4Et6i1rhXr9ljBE2k54h3ZyKZ0Is2svjGU6D5hRb/kHoOOvow4PEx4w2yTCfy3qOB84rN7yp9DvzYRh/IcJK3c+GO+/pinHPnRspnLcC3gg6vIIcFZ0fxWh0bKAsOX6yOg+Kp4viP6vqrcO/dTv1liGjwBX0D3zv+HqaS1+aVbuuxT4npk91mdAx3Ecx3GGPGkM/+OEiS5PAZsILSYzs71qL57jOI7jONUkjeGfWszdfGa/4ziO4zQcZQ2/4ziO4zjNQ5pZ/Y7jOI7jNAlu+B3HcRxnGOGG33Ecx3GGEW74HWeQkDRR0qfKhJmmsA12ubSmKbElcIVy3JBf9KSPMLMlzSjivrcS29QOhLgi6G79jJvqOjmO0xs3/I4zeEwkbHvaF9OAmho0M3unheVN+8PehEVuqiHHxwawPsg0anydHKdZccPvOIPHd4AdJT0o6Xvx94ikeZKOTYQ5IIb5fOzZ3inp/vh7Y5qMJJ0o6TpJN0r6j6TvJvwWSdoqHv+3pPmS7pL0W0lfTCTzPkn3SnpC0gFxqexzgWOjfMdSBEnnSLo8yr047u/x3ajnjXF9/B6jCpLWSvqmpIck3S1p6+h+maRjEmnnt2AtvE7ZeD3vU9iR7RMx/DaS7ojhHpF0QJrr5zjNjBt+xxk8zgCetLCT2N2E3vNrgIOA78X1xc8A7jSzvc3sfMImOAdb2MHxWODHFeS3d4yzJ8FYJzcnQdLrgfdGGQ4DCof2W8xsX+BzwNlm1gacBVwd5bu6j7x3JOz5fhRhydTbzGxPYANweJHwY4G7zew1wB3Ax8voVnidTiasu/56wo5sH4/r6X8Q+Fu85q8hLMvrOMOalvJBHMepAW8GfmtmnYQd724nGKyXC8K1AhdI2hvoBHapII9bzGw1gKTHgKn03Iv8TcCfzGwjsFHSnwvi53fkm0sYWq+Ev5pZu6R5QBa4MbrPK5FWG3B9Ir+DK8zvEGCvxOjABMImOvcBl8RRhj+a2YMVpus4TYcbfscZ2nweWE7orWaAjRXE3ZQ47qTy+z0fv99xzSwnqd26VwrLlUgrGSaZXwdxZFJSBhhRIj8BnzGzv/XykN5CGGW4TNIPzexXFeriOE2FD/U7zuCxBhgfj+8kDL9nJU0C3kLYDS0ZBkLP9VkLe8MfT+g9V4t/AEdKGiVpHOm22y6Ur9YsAl4Xj48ijIAUk+NvwKmJ+QO7KGx7PRVYbma/AC4G9hkUqR1nCOOG33EGCTN7EfhH/AzvDYStRB8ibCH6ZTN7Lrp1xklunwd+Cpwg6SFgV2BdFeW5j7Dt7MPAXwnD8KvLRLsN2K2vyX1V5hfAW6P+b6Bb/8LrdDHwGHB/vL7/Rxg1mAk8JOkBwnyHHw2CzI4zpPG1+h1nGCNpnJmtlTSGMKnuFDO7v95yOY5TO/wdv+MMby6Ki+iMAi53o+84zY/3+B2ngZH0DuC8AuenzOzdg5D3ScDpBc7/MLNP1zpvx3H6jxt+x3EcxxlG+OQ+x3EcxxlGuOF3HMdxnGGEG37HcRzHGUa44Xccx3GcYYQbfsdxHMcZRrjhdxzHcZxhhBt+x3EcxxlGuOF3HMdxnGGEG36nrkhaK+lVKcJNk2SSGn6ZaUknSrqr3nKkodrXXdL0uMHPGkmfrUaatUTSTElLB5jGAZLmD1Z+A0XSIkkHxeNzJF1RT3mc6uOG3+mT+BDYEA30ckmXxS1c+5PWbEkfS7qZ2TgzW1hFOddIWiXpn5I+Gfdwd/ogGptcLOM1kubH5XgrTSeNkfgycJuZjTezH/dP4orz7Hf4amBmd5rZ9GqkFe+/b1QjLWf4UvahGPe1viVudYmkvST9V+1Fc4YQR5rZOMJe5jOAispfgcEwwEea2XhgKvAd4CvALwch32ZgWSzjzQjX7Rdx855qMxV4tD8Rm2G0x3GGAmkexr8AzgTaAczsYeC4WgrlDE3M7BnCvu17SNpc0vWSXpD0UjzeLh829u6/KekfwHrg18ABwAWxZ3lBDGeSdorHh0t6QNLLkpZIOqefcq42s1mE/ddPkLRHTH+kpO9LejqOXvxc0ujoN1PSUklflbQijiB8KKFPmrhfkPS8pGeTPWZJW0qaFfW6F9gxKa+kXSXdJGll7G2/P+F3maQLJf0l9sbvkbRjwn/3RNzlkr4a3TOSzpD0pKQXJV0jaYsU187M7I/AS0Avwy9pctRlpaQFkj4e3Q8FvgocG8v3oSJxbwUOpLsO7CJpgqRfxXq0WNJ/5RuJCq9E/iHpfEkvAucUpFc0z0pllHSSpMfj9V0o6RPlrlMR3RZJ+qKkhyWtlnS1pFHRr8fwvaR9Yj1fI+naGPYbBen1qkuSTgE+BHw5yv/nMjJNkXRdvLYvJu65HSXdGt1WSLpS0sQUOo6SdEWMt0rSfZK2rvRaOfUnjeEfY2b3Frh11EIYZ2gjaQrwTuABQt25lNCD2x7YAFxQEOV44BRgPHAicCdwWhzeP61IFuuAjwATgcOBUyW9q7/yxnq7lNDggDAKsAuwN7ATsC1wViLKK4GtovsJhC1rp1cQd0J0Pxm4UNLm0e9CYCOwDfDR+ANA0ljgJuA3wCsIjeqfqmdv+zjg68DmwALgmzHueOBm4EZgcpTrlhjnM8C7gLdGv5eiHH0SGwzvJpTBvCJBriJc08nAMcC3JL3NzG4EvgVcHcv3NYURzext9KwDTwA/idftVVHWjwDJ1wz7AQuBrfN6J9IrlWelMj4PHEEY7TgJOF/SPuWuVRHeDxwK7ADsRajzPZA0AvgDcBmwBfBboHAnxaJ1ycwuAq4EvhvlP7KUIJKywPXAYmBaTOuqvDfwbcL1eTUwhYJGVQlOiHJNAbYEPkm4750GI43hXxF7GAYg6Rjg2ZpK5Qw1/ihpFXAXcDvwLTN70cx+b2brzWwN4aH81oJ4l5nZo2bWYWbt5TIxs9lmNs/McnFk6bdF0qyUZcAWkkRohHzezFZGmb9F79Gr/zazTWZ2O/AX4P0p47YD55pZu5ndAKwFpscH8HuBs8xsnZk9AlyeiHcEsMjMLo3X6QHg98D7EmH+YGb3mlkH4cG/dyLuc2b2AzPbaGZrzOye6PdJ4GtmttTMNhEe7Meo9HD55FjGK4CzgePNrMeEtNjwexPwlZjfg8DFBGNdMfHaHAecGWVfBPyA0GDMs8zMfhKvTVkj0x8ZzewvZvZkHO24Hfg73Y3FSvixmS0zs5XAn+kupyT7Ay0xbLuZXQcUdqyK1qUKZdmXYNi/FOvdRjO7C8DMFpjZTbGevwD8kHT3WTvB4O9kZp1mNtfMXq5QLmcIkOad2aeBi4BdJT0DPAV8uKZSOUONd5nZzUkHSWOA8wk9nHzPdrykrJl1xvMllWQiaT9Cz3oPYAQwErh2IIITejorgUnAGGBusOMhSyCbCPuSma1LnC8mPDzTxH0xGuY864FxMW4LPa/F4sTxVGC/aHTztBBejeR5rki6EHpeT1KcqcAfJOUSbp2EnvMzRcIvM7PtirgnmQzkGz55FhPmffSHrYBWel6PxYQyy1NRHaIfMko6jNDY2YXQGRpD8dGOchSW0+QS8j1jPfdDL9SxVF2qhCnA4oJ0AIjD8z8iNG7GE3R+KUWav47pXhVfDVxBaFyWbdQ7Q4uyPX4zW2hmBxEeYLua2Ztjy9wZ3nyB0AvZz8w2A94S3ZUIYwVxCs8L+Q0wC5hiZhOAnxekVxGSXk8wIncRerIbgN3NbGL8TYgT2vJsHofe82xPGDFIE7cULxBejU0pSDfPEuD2RLoT4zDuqSnSXkIYIi/ld1hBuqMszNPoL/nRk/EJt+3pbkiUK99CVhB6kVNLpJcmzUL/imSUNJIwwvJ9YGszmwjcwADqXRmeBbZVogVJz7pRjrTXeAmwfYkRnm/FdPaM9+6HSaFvHIH4upntBryRMOLUr9Eep76kmdV/uqTNCK3O8yXdL+mQ2ovmDHHGE4zhKoVJY2eniLOc0oYqn+ZKM9soaV/gg/0RTNJmko4gvNO8Iv/6gDBR9XxJr4jhtpX0joLoX5c0QtIBhAfbtRXE7UUc/bgOOEfSmPju/oREkOuBXSQdL6k1/l4v6dUpVL0e2EbS5xQmH46PoyYQGk3flDQ1yjtJ0tEp0uxLlyXAP4Fvx4leexHeQec/j1sOTFPKLzjitbkmyjk+yvr/EumloUee/ZAxP7L0AtARe/+1fL79izDycpqkllgm+1YQv9w9lOdeQiPjO5LGxmvxpug3nvD6YLWkbYEvpclY0oGS9oyvaF4mNNpyZaI5Q5A0N+hH43ucQwjvd44nDMc6w5v/BUYTem13EyaYleNHhPfML0kq9g33p4BzJa0hTJy7pkKZ/hzjLgG+Rnh3mZwo9hXC5Li7Jb1MmBiXfHf6HGHIcxnhXfonzezfKeP2xWmEodrnCJO6Ls17xCHpQwjvupfFMOcRjFGfxLgHA0fGeP8hzJqHcK1nAX+P1+RuwkS5gfIBwmSxZYRJamcnXgPlX8u8KOn+lOl9hjCpcyFhZOY3wCUVyFMsz9Qyxmv4WUJde4nQ2JxVQf4VYWZtwHsIjZFVhN729cCmlEn8Etgtzqr/Yx/5dBLqxU7A04TJjsdG768TPs1dTZjHcl3KvF8J/I5g9B8nzPf5dZ8xnCGJer5qKhJAetjM9pL0I2C2mf1B0gNm9trBEdFxao+kmYTRgXLvuR2nqki6B/i5mV1aNrDjVIE0Pf65kv5O+Izrb/HdmQ/vOI7j9ANJb5X0yjjUfwLh0780I2aOUxXSzOo/mfBZykIzWy9pS3oOnzqO4zQ1krYHHivhvZuZPV1BctMJrxbGEl5xHGNmFX8iXWWZnGFE2aF+CBOZCDNvuxoKZnZHDeVyHMdxHKcGlO3xSzqPMCnkMcJsVAifgrjhdxzHcZwGI83kvvnAXnH1r8oSD2tj/4iw0MnFZvadAv8Tge/R/Y3tBWZ2caX5OI7jOI6TjjTv+BcSVteqyPDHbz0vJHxutBS4T9IsMyt8J3W1FV+3vSgTJ060nXbaqRJRhizr1q1j7Nix5QM2AM2kCzSXPq7L0KSZdIHm0meo6jJ37twVZjZpoOmkMfzrgQcl3ULC+JvZZ8vE2xdYYHGvdUlXAUdTejJKKrbeemvmzJkzkCSGDLNnz2bmzJn1FqMqNJMu0Fz6uC5Dk2bSBZpLn6Gqi6TF5UOVJ43hn0X/FrTYlp5rUC+l+AIi75X0FuAJwiYola7N7TiO4zhOStLO6h9B2MACYH6aTRniLn6HmtnH4vnxhHXdT0uE2RJYa2abFPbAPtbC1p2FaZ1C2B2NSZMmve6aaypd0G1osnbtWsaNq3TvjaFJM+kCzaWP6zI0aSZdoLn0Gaq6HHjggXPNrL+bYnWRZlb/TMI2oosIGzlMkXRCis/5nqHn5hPbUbArmJm9mDi9GPhusYQs7EN9EcD06dNtKA7B9IehOpzUH5pJF2gufVyXoUkz6QLNpU8z6VKMNEP9PwAOsbg3t6RdCPukv65MvPuAnSXtQDD4x1Gw6YqkbRILVxxFWP+5LJ0567GVVHKfq56bXjlO9UiOjpUaKMtXP6+HzUe+/M26t8gzs8Qx5M+S9aOYuwE5g7WbOnqkXTLvsrL1PJdCLy0jkZGQ8sehbub/OsOTNIa/NW/0AczsCUmt5SKZWYek04C/ET7nu8TMHpV0LjDHzGYBn5V0FGHb0pXAiWXTBVasTfeBgUqcKHHSo9GQKtXq0ZkzXkypy1BnqOuSfC4WPiQt6RsPO3LG8y9vrHif2WIUq4fl6mDah3Iag9GRs7L3jGKeIm80ugTtMiJ5fxJhuhs6+eDqEb6YnKXKwgqudjHVzGBDW2f3OdbDmCbzShpkrDt83q2v8EbPRKtRDwrJmbEuGv56kC+jwsZARj0bDEqcV9JgKFY3S1XXUtc3zavoShtFaTCgraN5V6ZPY/jnSLqY7m0tPwSkmlZvZjcQ9rZOup2VOD4TODOdqJVjJU6KPejrQf6h3Aw0ky55qqVNsXpYvg5W91p2piqboV9+nWa8vLHsFCMnBUYwrKFqpC/7YmY/f/8vf3ljdYSrM50546X1bfUWo2akMfynAp8mbF0JcCfw05pJ5DiO4wxZhn7z0ClHWcMfZ9xfANxC2JVvftxT2nEcx3GcBiPNrP7DgZ8DTxJGeXaQ9Akz+2uthXMcx3Ecp7qkndV/oJktAJC0I/AXwA2/4ziO4zQYmRRh1uSNfmQhsKZG8jiO4ziOU0PSzuq/AbiGMK/jfYQNd94DYGbX1VA+x3Ecx3GqSBrDPwpYDrw1nr8AjAaOJDQE3PA7juM4ToOQZlb/SYMhiOM4juM4tafsO35J35W0maRWSbdIekHShwdDOMdxHMdxqkuayX2HmNnLwBGEjXp2Ar5US6Ecx3Ecx6kNaQx//nXA4cC1Zra6hvI4juM4jlND0kzuu17Sv4ENwKmSJgHNsSCz4ziO4wwzyvb4zewM4I3ADDNrB9YDR9daMMdxHMdxqk+ayX1jgE8BP4tOk4EZtRTKcRzHcZzakGao/1JgLqHXD/AMcC1wfa2E6gsz2NTRSVYikwl7RDuO4zQL+a1y839zZljir9HTv1i4jMToEVnGjsjSkk0zlcsZTqQx/Dua2bGSPgBgZuul+lnbp9fkeMt3Z/dwC40AyEhkY2Mgkwnu+fNC90xsOBTGHUzF1q/dyJjH5gxijrVjKOtSuI2oWdLPerkBrFu7kTHz7uvl3yNY/kTJugbZjGjJZEJdS9S/lmRdjOf5Bmw2HmczPdPJZkKN7MsQJP/2PA5/X3xhExOfe6xoWEmMbMkwqjXb9XdUa4ZRLVlGtsbzeNztH8KMbOn+m5dzMMiZkcsZnWZ05rp/HUWOO3K5HmE6c0ZHZ4jbI3xnrnd6nUZ7Lkd7Z/AvPG/vNNo7c3Tk4t94nncreZ4LYTs6OtGtt3WVVb58q01rVowZ0cKYEdn4C8ehYdDC6OiePE6GGzMyy5jW7jgjWzIUMwEWr59ZuGu6GiqFdZWejZZiYUN64f4Mf4GC+N1husMVxiuaTgqeXNUJzzTvPPY0hr9N0mjiNYub9GyqqVR9sPlIcerMHcnlwoOrM9f9gOssdEs8HMLDAjoTD41ebrW46/ogm4HWJmmND3Vd8s+prqZdzz+9wmgTjB/T2iNMrzSiW7IedeZCXdrY0dnDiOTrZUeyjuYIhikfP/p1lKmLGYEUGgcZCRX5m5W6wnS25xixZmXvsIgcRltHjo3tOTa2d7KpI9ev6zsimwkNhUSDYWRLhozU1chI3ms5sy6989fDLJ0/f7+1XzIOlKxES1a0ZjO0ZkPjrsd5NkNLJpyPbMkwdmR3uLx/a/RvyYqVy5/lFdts26v8kuVb+Dc/wlkuXC4H69s6WN/WyYb2TtZtisdtnaxv62Ttpg5eWLOJ9W2drG/rYF1bZ+rnX76z1MOo5z1vqk/Z1IR7h2ZHphqkMfxnAzcCUyRdCbwJOLGWQvXFZiPFiW+cVq/sq8q8Of9izxn71FuMqtBMukBen73rKkPe4ImeD/ZKCbq8IVVYM2NTR45N7Tk2dnR2NQY2tnf2aByE8042duTYVBBmU0d3WDO6RtTyI24ZJUY6ioy4dY/OFfhLvPDcUrbZdkqXf0umezQl23Wc6TrOFvhXGi5vpPNhq8m8OS+y54ydqprmQGjryLGhrZN1bd2NhORxviGxvq0zjhaFxqNivXzh2aW8ctspiO6GjPpotNAjXHf9DvU9NsDzje1E/Pz9kA8HvePFf6XPy7DoP48zbedXV+/iVol3n1eddPo0/JIywObAe4D9CdfudDNbUZ3sHccpRUYikx3ct2qSuobzJ9A6qHmnYd6c59lzxqvqLUZTMqIlw4iWDBPG9K/c581Zzp4zdqiyVPVh3EtZ9txxy3qLUTP6NPxmlpP0ZTO7BvjLIMnkOI7jOE6NSPNS9mZJX5Q0RdIW+V/NJXMcx3Ecp+qkMfzHAp8G7iB81jcXSDXrQdKhkuZLWiDpjCL+IyVdHf3vkTStAtkdx3Ecx6mQNNvy9vnSRtLBZnZTEfcscCFwMLAUuE/SLDN7LBHsZOAlM9tJ0nHAeYSGhuM4juM4NaAa31+Vmme4L7DAzBaaWRtwFb2X+j0auDwe/w54ez3XCHAcx3GcZqcahr+Uod4WWJI4XxrdioYxsw5gNdC8Uykdx3Ecp86k+Y6/HDVf9UbSKcApAJMmTWLenH/VOstBYcO6ta7LEKWZ9HFdhibNpAs0lz7NpEsxqmH4S/EMMCVxvl10KxZmqaQWYALwYmFCZnYRcBHALtOnW9rFSIY6lSysMtRpJl2gufRxXYYmzaQLNJc+zaRLMaox1L+ohPt9wM6SdpA0AjgOmFUQZhZwQjw+BrjV8oswO47jOI5TdVL1+CW9EZiWDG9mv4p/31Msjpl1SDoN+BuQBS4xs0clnQvMMbNZwC+BX0taAKwkNA4cx3Ecx6kRZQ2/pF8DOwIPAp3R2YBflYtrZjcANxS4nZU43gi8L724juM4juMMhDQ9/hnAbj4E7ziO4ziNT5p3/I8Ar6y1II7jOI7j1J40Pf6tgMck3Qtsyjua2VE1k8pxHMdxnJqQxvCfU2shKkHAmBFZoOcCAj1eRBS8lLCEQ+ELi55pDO7bDAEtVd7ju140mi6FJV2s6IuuIVkknL8Dc2pNr6qowtNuh3y9NYvPvlhBvZ46edKs1X/7YAhSCeNHDb19wvtDNiO2HDey3mJUhWbSBUIj5hXjR1UcL9l4TDYmSjUwrWjY3mkkGyEqeOr39KPAT7RkxFbjRhbx684jZyHXvLHI55szi25B7nwYesTpGTdha1Kjkie99c0mGpjF9C3t13e6ydN8WHWdq+C8Zxq90lZvv8K0WjJiUuKe6Z1G9RvSZt1lmy+77uPuutcVpitsdz0oRUZi7MiWkku5llKnVzmkiNNf0qaXzYiJY5rDzhQjzaz+/YGfAK8GRhA+zVtnZpvVWDbHaTh6GJ6SD5nBHxnJ9jEaI0GmyjIlDUw+j5559i+/fCOmWcgM8iiZpIKyqF7+GcG4kbVcE27wEDCyJVtvMWpGmlK6gPB9/bWEGf4fAXappVCO4zQ2vQ2M4zhDBZV7ry1pjpnNkPSwme0V3R4ws9cOioS95VkDzK9H3jVgK2BFvYWoEs2kCzSXPq7L0KSZdIHm0meo6jLVzCYNNJE0Pf71ccndByV9F3iW6iz121/mm9mMOuZfNfKNqnrLUQ2aSRdoLn1cl6FJM+kCzaVPM+lSjDQG/PgY7jRgHWFTnffWUijHcRzHcWpDmln9iyWNBrYxs68PgkyO4ziO49SIsj1+SUcS1um/MZ7vLalwl73B5KI65l1tXJehSzPp47oMTZpJF2gufZpJl16kmdw3F3gbMDs/oU/SPDPbcxDkcxzHcRyniqR5x99uZqsL3HwRKMdxHMdpQNIY/kclfRDIStpZ0k+Af9ZYrqJIOlTSfEkLJJ1RDxn6i6Qpkm6T9JikRyWdHt23kHSTpP/Ev5vXW9a0SMpKekDS9fF8B0n3xPK5On4NMuSRNFHS7yT9W9Ljkt7QqOUi6fOxfj0i6beSRjVSuUi6RNLzkh5JuBUtCwV+HPV6WNI+9ZO8NyV0+V6sZw9L+oOkiQm/M6Mu8yW9oy5Cl6CYLgm/L0gySVvF84Yrl+j+mVg2j8Yv2PLuQ7Zc+ksaw/8ZYHfCBj2/AVYDp9dSqGJIygIXAocBuwEfkLTbYMsxADqAL5jZbsD+wKej/GcAt5jZzsAt8bxROB14PHF+HnC+me0EvAScXBepKudHwI1mtivwGoJODVcukrYFPgvMMLM9CKtsHkdjlctlwKEFbqXK4jBg5/g7BfjZIMmYlsvorctNwB5xTZQngDMB4rPgOMKz9lDgp/GZN1S4jN66IGkKcAjwdMK54cpF0oHA0cBrzGx34PvRfaiXS79IY/h3i78WYBTh4txXS6FKsC+wwMwWmlkbcFWUpSEws2fN7P54vIZgXLYl6HB5DHY58K66CFghkrYDDgcujucizAX5XQzSELpImgC8BfglgJm1mdkqGrRcCPfpaEktwBjCuhsNUy5mdgewssC5VFkcDfzKAncDEyVtMyiCpqCYLmb2dzPriKd3A9vF46OBq8xsk5k9BSwgPPOGBCXKBeB84Mv0fP3bcOUCnAp8x8w2xTDPR/chXS79JY3hvxK4BHgPcET8HVlLoUqwLbAkcb40ujUckqYBrwXuAbY2s2ej13PA1vWSq0L+l3DD5+L5lsCqxEOtUcpnB+AF4NL42uJiSWNpwHIxs2cIPZWnCQZ/NTCXxiyXJKXKotGfCR8F/hqPG04XSUcDz5jZQwVeDacLYRn6A+IrsdslvT66N6IuZUlj+F8wsz+b2VNmtjj/q7lkTYqkccDvgc+Z2ctJP7P8vmdDG0lHAM+b2dx6y1IFWoB9gJ/Fr1bWUTCs30Dlsjmhh7IDMBkYS5Hh2UamUcqiHJK+Rnj9d2W9ZekPksYAXwXOqrcsVaIF2ILwGvZLwDVxFLMpSbNk79mSLia8W9uUdzSz62omVXGeIawamGe76NYwSGolGP0rE9dvuaRtzOzZOBz2fOkUhgxvAo6S9E7C65/NCO/JJ0pqib3LRimfpcBSM7snnv+OYPgbsVwOAp4ysxcAJF1HKKtGLJckpcqiIZ8Jkk4kjJy+3bq/p240XXYkNDAfivZxO+B+SfvSeLpAeA5cF8vjXkk5wnr9jahLWdL0+E8C9ib0HI6MvyNqKFMp7gN2jjOURxAmXNRzIaGKiK3HXwKPm9kPE16zgBPi8QnAnwZbtkoxszPNbDszm0Yoh1vN7EPAbcAxMVij6PIcsETS9Oj0duAxGrBcCEP8+0saE+tbXpeGK5cCSpXFLOAjcRb5/sDqxCuBIYmkQwmvyI4ys/UJr1nAcZJGStqBMDHu3nrImAYzm2dmrzCzafE5sBTYJ95PDVcuwB+BAwEk7ULYgn4FDVYuqQn7Zpf+ETbFKRtuMH7AOwkzYZ8EvlZveSqU/c2EIcqHCSshPhj12ZIwmvIf4GZgi3rLWqFeM4Hr4/GrCDfFAsI2ziPrLV9KHfYG5sSy+SOweaOWC/B14N/AI8CvgZGNVC7AbwnzE9oJxuTkUmVB2Db9wvg8mEf4mqHuOpTRZQHhnXH+GfDzRPivRV3mA4fVW/5yuhT4LwK2auByGQFcEe+b+4G3NUK59PeXZuW+S4HvmdljfQZ0HMdxHGfIk8bwP054n/MU4R2/CHNs9qq9eI7jOI7jVJM0hn9qMXfzmf2O4ziO03CUNfyO4ziO4zQPaWb1O47jOI7TJLjhdxzHcZxhhBt+x3EcxxlGuOF3nCGEwhbBnyoTZprCVtnl0ppWbBvVlHLckNwytkSY2ZJmFHHfO67qWDWSeUlalN8C1nGcynHD7zhDi4lAn4YfmAaUNfwDwczeaWGXwv6wN2FxKsdxhiBu+B1naPEdYEdJD0r6Xvw9ImmepGMTYQ6IYT4fe/Z3Sro//t6YJiNJJ0q6TtKNkv4j6bsJv65etaT/ljRf0l2Sfivpi4lk3ifpXklPSDogLqd9LnBslO9YiiBpnKRLo14PS3pvdP+ZpDmSHpX09TLyj5X0F0kPxWtUNC/HcXqSZpMex3EGjzOAPcxs72gMPwm8hrBhyH2S7ohhvmhmR0DXTmkHm9lGSTsTliTtNQRfgr0JW0RvAuZL+omZdW1DGrcnfW+UoZWwnGlyV8YWM9s3Du2fbWYHSTqLsEzraX3k+9+ENdz3jPlsHt2/ZmYrJWWBWyTtZWYPl0jjUGCZmR0e05iQUmfHGdZ4j99xhi5vBn5rZp1mthy4HXh9kXCtwC8kzSOsxb9bBXncYmarzWwjYUOfwgW73gT8ycw2mtka4M8F/vldJucSXkGk5SDCeu4AmNlL8fD9ku4HHgB2p29d5gEHSzpP0gFmtrqC/B1n2OKG33Ean88Dywm98hmEDUfSsilx3Enlo4D5+P2J24O4+9kXCdvV7gX8hbDtc1HM7AlgH0ID4BtxpMFxnDK44XecocUaYHw8vpPwrjwraRLwFsIue8kwABOAZ80sBxwPZKsozz+AIyWNkjSOdFtyF8pXjJuAT+dP4lD/ZsA6YLWkrYHD+kpA0mRgvZldAXyP0AhwHKcMbvgdZwhhZi8C/4if4b2BsFXwQ8CtwJct7Hf+MNAZJ7V9HvgpcIKkh4BdCcazWvLcR9iT/GHgr4Tedbkh9duA3fqa3Ad8A9g8Tsp7CDjQzB4iDPH/G/gNodHRF3sC90p6EDg7puk4Thl8rX7HcfpE0jgzWxsnEd4BnGJm99dbLsdx+ofP6nccpxwXSdqN8L79cjf6jtPYeI/fcZocSe8AzitwfsrM3j0IeZ8EnF7g/A8z+3Sx8I7j1B43/I7jOI4zjPDJfY7jOI4zjHDD7ziO4zjDCDf8juM4jjOMcMPvOI7jOMMIN/yO4ziOM4xww+84juM4wwg3/I7jOI4zjHDD7ziO4zjDCDf8Ts2RtFbSq1KEmybJJDX8UtKSTpR0V73lSEO1r7uk6XGDnjWSPluNNGuJpJmSlg4wjQMkzR+s/FLk0TD1zxl83PA7SFokaUM00MslXRa3YO1PWrMlfSzpZmbjzGxhFeVcI2mVpH9K+qQkr8dliMYmF8t4jaT5cTndStM5R9IVZYJ9GbjNzMab2Y/7J3HFefY7fDUwszvNbHo10or3n+806NSMsg9MSbtIuiVuE4qkvST9V+1FcwaZI81sHGFP8xlARWWswGAY4CPNbDwwFfgO8BXgl4OQbzOwLJbxZoTr9ou4+U61mQo82p+IzTDa02x4mTQhZtbnD7gd2Bd4IOH2SLl4/mucH7AIOChx/j3gemDz+PcF4KV4vF0i3Gzgm4R90zcAVwKdwEZgLXBBDGfATvH4cMKe6y8DS4BzEulNi2Fb0sgZ3fYFcsAe8Xwk8H3gaWA58HNgdPSbCSwFvgqsiOl9KJFWmrhfAJ4HngVOSsTdkrBv/cvAvcD/AHcl/HcFbgJWAvOB9yf8LgMuBP4CrAHuAXZM+O+eiLsc+Gp0zwBnAE8CLwLXAFuUuHYzgaUFbi8AxxRed2By1GUlsAD4eHQ/FGgD2mP5PlQkn1sL6sAuwATgVzG/xYRGZSaGP5FQf86POnyjIL2ieVYqI3AS8Hi8vguBT/R1bfqof18EHgZWA1cDo4qlQWhAPxDzuzaG/Ua5ugScEmVvi/L/uYxMU4Dr4rV9ke577kTgLkJ9fgl4CjgsEa/s9SA0Dp8Dfg2MBi6PaT1OGNVJ6jsZ+H2U4yngs/V+rvmvj3pTNgDcF/8+kHB7sN6C+6+KlSBhUOOD5FGC4doSeC8wBhgfH2B/TMSbTTCSuxO2eG6Nbh8rSD9p+GcCexKM1l4EQ/au6DeNCg1/dH8aODUen08wCFtEmf8MfDuRdwfwQ4KRfyuwDpheQdxzo57vBNYDm0f/qwiGdyywB/AM0fBHtyXxYdsCvJbQ8Ngt+l9GeGjvG/2vBK6KfuMJhuELhG1xxwP7Rb/TgbuB7aI+/wf8tsS1m0l8UMdr/26CgZleeN2BO4Cfxvz2JjzM3xb9zgGuKFOfetQBgtH/U5R9GvAEcHL0OzFe189E3UcXSa9XnpXKSGhw7ggolvt6YJ/Ca5PiPrmXYOS2IBjATxa5viMIDZzTY115D8GQJw1/X3XpMgoaQCXkyQIPEert2Hgt3py4ru3Ax2O4U4FldG/MVu56dBB2dBxJMPrfIXQCNyfUt4fpWZ/mAmdF3V9FaEy8o97PNv+VqDspKtdfYwW5P54fA/y13oL7r4qVIDzQ1gKr4gPrpyUewHsDLyXOZwPnFoSZTR+Gv0ia/wucH4+n0T/DfzfwtfgQW0fP3vIbCFvQJh9oYxP+1wD/nTLuhqRshN7a/vHB2g7smvD7Ft2G/1jgzgKZ/w84Ox5fBlyc8Hsn8O94/AESje6CNB4H3p443ybK0ev6RflzsYxXAg8CxxVed0LDrxMYn4j7beCyeHwOFRj+eG3aiI2c6PYJYHY8PhF4ukx6PfKskox/BE5PXJu0hv/DifPvAj8vTAN4C6Hhp0TYu+hp+IvWpUR9SGP430Bo8BQr7xOBBYnzMbGMX5nyerQRRzOiWw9DDnwsoe9+hWUInAlcWk4H/9Xnl+bdzaeBi4BdJT1DGMb5cIp4TmPxLjO7OekgaQyhN3EooaUPMF5S1sw64/mSSjKRtB+h97AHoXcwkjCSMBC2JRizSYQH3FxJXVkSjE+el8xsXeJ8MaEHlybui2bWkThfD4yLcVvoeS0WJ46nAvtJWpVwayEMoeZ5rki6EIzckxRnKvAHSbmEWyewNcHwFLLMzLYrkVaeycBKM1uTcFtMmPfRH7Yi9GqT12MxoczyVFSH6IeMkg4Dzia8esgQynpehflC73KaXEK+ZyxawEihjqXqUiVMARYXpFNUVjNbH+v1OEh1PV4ws42J88kFOiSPpwKTC+p3FrizEmWcwaPsZCwzW2hmBxEebrua2ZvNbFHNJXOGAl8gDAXvZ2abEXoyEAxiHiuIU3heyG8Iw+lTzGwC4T26+o5SGkmvJxiRuwjD5xuA3c1sYvxNsDChLc/mksYmzrcnDIGmiVuKFwgjCVMK0s2zBLg9ke5EC186nJoi7SWEodNSfocVpDvKzIoZ/bQsA7aQND7htj3dDYly5VvICsIoxNQS6aVJs9C/IhkljSS8f/4+sLWZTQRuYAD1rgzPAtsq0YKkZ90oR9prvATYvtLJdymvR6EMzxKG+PMk9VlCGBlL1sPxZvbOSuRyBo80s/pPl7QZoUV6vqT7JR1Se9GcIcB4gjFcJWkLQg+hHMspbajyaa40s42S9gU+2B/BJG0m6QjCu/UrzGyemeWAXxDq6StiuG0lvaMg+tcljZB0AHAEcG0FcXsRRz+uA86RNCbOlD8hEeR6YBdJx0tqjb/XS3p1ClWvB7aR9DlJIyWNj6MmEBpN35Q0Nco7SdLRKdLsS5clwD+Bb0saJWkv4GQg/3nccmBa2i844rW5Jso5Psr6/xLppaFHnv2QMT+y9ALQEXu7tXyG/Ysw8nKapJZYJvtWEL/cPZTnXoJB/o6ksfFavClFvP5cj2uAMyVtLmlb4LQCOdZI+oqk0ZKykvaIjXJnCJLm5v2omb1MqBhbAscThmqd5ud/CRN7VhDeo9+YIs6PgGMkvSSp2DfcnwLOlbSGMBnomgpl+nOMu4TwXv+HhElzeb5CmOV9t6SXgZsJoxZ5niPMTF5GmET3STP7d8q4fXEaYRj1OcI72kvzHnFI+hDguJjvc3RPnOqTGPdg4MgY7z/AgdH7R4TRk7/Ha3I34X3rQPkA4b3/MuAPhLkI+ddA+dcyL0q6P2V6nyHMn1hIGJn5DXBJBfIUyzO1jPEafpZQ114iNDZnVZB/RZhZG2FC38mEORUfJjTgNqVM4pfAbnGtij/2kU8noV7sRJjgupQwn6ScfP25HufG9J8i3Be/I+oT5TiCMAfoKcLz4mLC1xzOECQ/w7N0AOlhM9tL0o8IE3L+IOkBM3vt4IjoONVB0kzC6EC599yOU1Uk3UOYCHhp2cANgKRTCZND31pvWZzKSdPjnyvp74SZxn+L79VyZeI4juMMWyS9VdIr41D/CYRPV9OMmA1JJG0j6U2SMpKmE+b//KHecjn9I82kkJMJQzgL48zQLek5tOo4jtPwSNoeeKyE925m9nQFyU2ne12HhcAxZvZsnWUaCCMIn6DuQHh9cRXhs1+nASk71A9hkhNhVm5XQ8HM7qihXI7jOI7j1ICyPX5J5xEmjDxGmKkK4VMPN/yO4ziO02Ckmdw3H9jLzNLOSHUcx3EcZ4iS5h3/QsLKWxUbfkmHEj45yhKWJP1Ogf+JhA1h8gtvXGBmF/eV5sSJE22nnXaqVJQhybp16xg7dmz5gEMc12Po0Sy6NIse0Dy6NIse0Hi6zJ07d4WZTRpoOmkM/3rgQUm3kDD+ZvbZviJJyhJ2HDuY8P3nfZJmmVnhRJWrzey0XgmUYOutt2bOnDlpgw9pZs+ezcyZM+stxoBxPYYezaJLs+gBzaNLs+gBjaeLpMXlQ5UnjeGfRf8Wu9iXsEnEQgBJVwFHU3qGquM4juM4Naas4TezyyWNIGzmADDfzNpTpL0tPTdyWErxVcXeK+kthK06Px+X43Qcx3Ecpwakmdw3E7icsCWlCJsznFDucz5JxwCHmtnH4vnxhM1eTkuE2RJYa2abJH0CONbM3lYkrVOAUwAmTZr0umuuqXSV16HJ2rVrGTeu0g25hh6ux9CjWXRpFj2geXRpFj2g8XQ58MAD55pZf3fK7CLNUP8PgEPMbD6ApF2A3wKvKxPvGXru4LQdBVuFmtmLidOLCftb98LMLiJsDcz06dOtkd7J9EWjvV8qhesx9GgWXZpFD6i/LvlOXr6vZ4XuXed5/57h8/zrrjvZ740H1FDSwePufzSPLpWQxvC35o0+gJk9Iak1Rbz7gJ0l7UAw+MdRsBObpG0Sq1kdBTyeRuiN7Z1IkJHiD3rugOk4ThIzwyw83M0s/u0jfMW771aOUuyKa0Bbx8BWCE+rS4q1zAYmh4VnV2F+hvUwxkUNcYqwhQa74E/V6DTj5Y1p3vYOfZpJl0pIY/jnSLqY7i0vPwSUnVZvZh2STgP+Rvic7xIze1TSucAcM5sFfFbSUYS9zFcCJ5ZNF1i9oXdBiWD8JcjGv4qNgnwDobuxEP9mvLHQTCR7NKV6M33GB9o7+2dkCo1GobEpZ1T6il9osLvCW7chKDToHTnj+TUbY5jGpTNnvLS+rd5iVIVOs6LPLscZbNIY/lOBTxO2cQS4k5RrNJvZDcANBW5nJY7PBM5MJWm5vIgPeYPOCh51hSMHg0lnzljVgA+1wp5aZ85Yvb69MFDfaRTx71fPpoq9ms6csXJd45VHKWrdg3UcpzFJM6t/k6QLgFsIu/LNj/tNNwVmoSVeSWOhankDmwY4jDkUMGBjR2fZcI7jOE79SbNW/+HAz4EnCf24HSR9wsz+WmvhHMdxHMepLmln9R9oZgsAJO0I/AVww+84juM4DUYmRZg1eaMfWQisqZE8juM4juPUkLSz+m8AriG8zn0fYd399wCY2XU1lM9xHMdxnCqSxvCPApYDb43nLwCjgSMJDQE3/I7jOI7TIKSZ1X/SYAjiOI7jOE7tKfuOX9J3JW0mqVXSLZJekPThwRDOcRzHcZzqkmZy3yFm9jJwBGGjnp2AL9VSKMdxHMdxakMaw59/HXA4cK2Zra6hPI7jOI7j1JA0k/uul/RvYANwqqRJwMbaiuU4juM4Ti0o2+M3szOANwIzzKwdWA8cXWvBHMdxHMepPmkm940BPgX8LDpNBmbUUijHcRzHcWpDmqH+S4G5hF4/wDPAtcD1tRLKcRzHGTzMjI6c0dFpdORy8a/R3pmL7uFvZ854clUntnRVvUWuCs2kSyWkMfw7mtmxkj4AYGbrpWKbqg4O7Z2wbNUGxozIMnpElhHZDHUUx3EcZ0B05HJsas+xqSPHpo5ONraHv0m3cv4bO3Jsau+M5znaOnJdRrszb8yjYe8y5gkD35mrcHfSe+fW5mLUg2bSJSVpDH+bpNHELc/jJj2baipVHyxbl+PdP/1n13lWYnRsBIxpjX/j+ejWLGNGtJT3i+ejR2TJDmIjYk2b8VKD7f8ugRDxHxKsbzfWbupABWHylzJ5Lohxu88lkTMjl+t+CHXmjJyFv3255c/zv44ibp05S7Xp8pJnO1j26HP9ui5mkDPrOjYs/gWinxF6Vt1hwnmP44L08u65XNg+Ohf1y0X/5DXIWQjbmTNWvLCJCc891jN8zkIaifTy8hTTp6h7yQuQ8kKp6GE47+EXTtas3sj4Jx8slUT39bHua5lL/oUebkbPsHm/fNnlCsJCz2uRPy706wrSh39HexvZu+7oSitvpCs2upGMYGRLlpEtGUa2Znocj8hmGDeyhZasaMlkaMmo+zireN7t3trl3u2fzYjWbKZXGkufnM8Ou7y6XzIPNRY98TjTGkiXd51XnXTSGP6zgRuBKZKuBN4EnFid7Ctn0mjxX4e/mg1tnaxv7wx/2zrY0HUc/q5Y28aGeLy+vYMNbZ308/6qLbPvrLcE1eG22+stQXWY92i9JSiLgIxEJhP+ZjPqPkdkMiLXkWPkmpU9/ZWPJ7KJ+CXzKeGlXia77/B5ehjQgpZCqYbGunbIrW8vGs8syC91/81fGwlaMhkyCg3LTKKx2RVW4XopGSYRNt+4zevWpXfPP90N3OhSeB3ypy+teJ4tJr2i63xEocFuyTCyNRyPau126z7OxvDhuDWruox2zlu9gD1fteWg51sLxq7MNo0uldCn4ZeUATYH3gPsT6jDp5vZikGQrShjWsWRr5lccTwzY1NHLjQG2rsbCPlGQf48V+oJVAOWPf0Uk7ffYdDyqwbFeqfLnl7EK6dM7eFPkV5v8ryw55sRZGMvI2+oWgrO88ctJdyS512/aOgyKZ6PTzzyILvssXe/roukrhGQwtGOvHHtNfJB0mD1HEVJpheMdjDUWaV72M+b8y/2nPGGfukylAh6vL7eYlSFeXNWseeMXesthuP0bfjNLCfpy2Z2DfCXQZKpJkhiVGuWUa1ZNq+3MJF5LGXPGVPqLcaAmZd5hj1nTK23GAPm5bEZpm45tt5iOI7j1JQ0K/fdLOmLkqZI2iL/q7lkjuM4juNUnTSG/1jg08AdhM/65gJz0iQu6VBJ8yUtkHRGEf+Rkq6O/vdImlaB7I7jOI7jVEiabXn7fAkt6WAzu6mIexa4EDgYWArcJ2mWmT2WCHYy8JKZ7STpOOA8QkPDcRzHcZwakKbHX45SHxjsCywws4Vm1gZcRe+lfo8GLo/HvwPeXs81AhzHcRyn2amG4S9lqLcFliTOl0a3omHMrANYDQy/byscx3EcZ5BI8x1/OWr+/ZukU4BTACZNmsS8Of+qdZaDwoZ1a5tCF9dj6NEsujSLHtA8ujSLHtBculRCNQx/KZ4Bkt+qbRfdioVZKqkFmAC8WJiQmV0EXASwy/Tp1gzfJ0OzfWvtegwlmkWXZtEDmkeXZtEDmkuXSqjGUP+iEu73ATtL2kHSCOA4YFZBmFnACfH4GOBWK7WGqOM4juM4AyZVj1/SG4FpyfBm9qv49z3F4phZh6TTgL8BWeASM3tU0rnAHDObBfwS+LWkBcBKQuPAcRzHcZwaUdbwS/o1sCPwINAZnQ34Vbm4ZnYDcEOB21mJ443A+9KL6ziO4zjOQEjT458B7OZD8I7jOI7T+KR5x/8I8MpaC+I4juM4Tu1J0+PfCnhM0r3ApryjmR1VM6kcx3Ecx6kJaQz/ObUWwnEcx6kOiv+J7u2gu9yha1tn9fDrGaivOBmJ8aNq+SX44NFMulRCmrX6bx8MQdIiYFRrNpxY/k/33u4J5+hmBec941AkjuM4zmAQjK+Quo8zeaMtutwzXWHi3+RxMt4grHieEYwZ0RzGspl0qYQ0s/r3B34CvBoYQfg0b52ZbVZj2UoyYXRrvbKuKo9nxNabjaq3GBVRbI5nS0a8YvzIMvEqzyvtM6xaD7t6lUfaebOFwQobuEn3bEZsMXZEjzhW0LxthOm6Wans/V5Y/CpYRby3f2F89elfSd59UXif+LYkTr1I09S5gPB9/bWEGf4fAXappVDO0KXUw6rcQ8yfcaVJawD6DtbbeLVmq7E+V32REiN8TYAbe2cooHK9DUlzzGyGpIfNbK/o9oCZvXZQJOwtzxpgfj3yrgFbASvqLUQVcD2GHs2iS7PoAc2jS7PoAY2ny1QzmzTQRNL0+NfHJXcflPRd4Fmqs9Rvf5lvZjPqmH/VyDeq6i3HQHE9hh7Nokuz6AHNo0uz6AHNpUslpDHgx8dwpwHrCJvqvLeWQjmO4ziOUxvSzOpfLGk0sI2ZfX0QZHIcx3Ecp0aU7fFLOpKwTv+N8XxvSYW77A0mF9Ux72rTLLq4HkOPZtGlWfSA5tGlWfSA5tIlNWkm980F3gbMzk/okzTPzPYcBPkcx3Ecx6kiad7xt5vZ6gK3BvgC2HEcx3GcQtIY/kclfRDIStpZ0k+Af9ZYrqJIOlTSfEkLJJ1RDxkGiqQpkm6T9JikRyWdXm+ZBoKkrKQHJF1fb1kGgqSJkn4n6d+SHpf0hnrL1B8kfT7Wq0ck/VZSw6wQJekSSc9LeiThtoWkmyT9J/7dvJ4ypqGEHt+LdethSX+QNLGOIqammC4Jvy9IMklb1UO2Siilh6TPxHJ5NH61NixIY/g/A+xO2KDnN8BqYNCNlaQscCFwGLAb8AFJuw22HFWgA/iCme0G7A98ukH1yHM68Hi9hagCPwJuNLNdgdfQgDpJ2hb4LDDDzPYgrLJ5XH2lqojLgEML3M4AbjGznYFb4vlQ5zJ663ETsEdcC+UJ4MzBFqqfXEZvXZA0BTgEeHqwBeonl1Ggh6QDgaOB15jZ7sD36yBXXUhj+HeLvxZgFOFC3VdLoUqwL7DAzBaaWRtwVZSloTCzZ83s/ni8hmBgtq2vVP1D0nbA4cDF9ZZlIEiaALwF+CWAmbWZ2aq6CtV/WoDRklqAMcCyOsuTGjO7A1hZ4Hw0cHk8vhx412DK1B+K6WFmfzezjnh6N7DdoAvWD0qUCcD5wJdpkNe+JfQ4FfiOmW2KYZ4fdMHqRBrDfyVwCfAe4Ij4O7KWQpVgW2BJ4nwpDWow80iaBrwWuKfOovSX/yXc/Lk6yzFQdgBeAC6Nry0uljS23kJVipk9Q+i1PE1YaGu1mf29vlINmK3N7Nl4/BywdT2FqRIfBf5abyH6i6SjgWfM7KF6yzJAdgEOkHSPpNslvb7eAg0WaQz/C2b2ZzN7yswW5381l6zJkTQO+D3wOTN7ud7yVIqkI4DnzWxuvWWpAi3APsDP4pcr62iMIeUexPffRxMaMpOBsZI+XF+pqoeFT5AaoodZCklfI7zuu7LesvQHSWOArwJn1VuWKtACbEF45fol4BoNk80U0hj+s2MP6AOS3pP/1Vyy3jxDWDUwz3bRreGQ1Eow+lea2XX1lqefvAk4StIiwmuXt0m6or4i9ZulwFIzy4+8/I7QEGg0DgKeMrMXzKwduA54Y51lGijLJW0DEP827HCspBMJI6YfsrRbMg49diQ0LB+K9/52wP2SXllXqfrHUuA6C9xLGLkc8hMVq0Eaw38SsDdhYsSR8XdEDWUqxX3AzpJ2iHsHHAfUcyGhfhFblL8EHjezH9Zbnv5iZmea2XZmNo1QFreaWUP2Ls3sOWCJpOnR6e3AY3UUqb88DewvaUysZ2+nAScpFjALOCEenwD8qY6y9BtJhxJeix1lZuvrLU9/MbN5ZvYKM5sW7/2lwD7xHmo0/ggcCCBpF8K28420YU+/SbNJz+vNbHr5YLXFzDoknQb8jTBb+RIze7TOYvWHNxH2P5gn6cHo9lUzu6F+IjmEr1eujI3KhYQGb0NhZvdI+h1wP2E4+QEaaGUySb8FZgJbSVoKnA18hzAEezKwGHh//SRMRwk9zgRGAjfF0eS7zeyTdRMyJcV0MbNf1leqyilRJpcAl8RP/NqAExp4JKYi0qzcdynwPTNrxB6Q4ziO4zgJ0hj+xwnvdZ4ifMsvwjybvWovnuM4juM41SSN4Z9azN1n9juO4zhO41HW8DuO4ziO0zykmdXvOI7jOE6T4IbfcRzHcYYRbvgdx3EcZxjhht9x6kDcBvhTZcJMi1til0trWrFtU1PKcUO5LWIlzZY0o4j73pLe2c981/YnnuM4A8cNv+PUh4lAn4YfmAaUNfwDwczeOYCdCPcG+mX4B0LcedBxnH7iht9x6sN3gB0lPSjpe/H3iKR5ko5NhDkghvl87NnfKen++Eu1Dr+kEyVdJ+lGSf+R9N2E3yJJW8Xj/5Y0X9Jdkn4r6YuJZN4n6V5JT0g6IK5weC5wbJTvWIogaZykS6NeD0t6b8Lvm5IeknS3pK2j25Fxt7QHJN2ccD9H0q8l/QP4taRJkm6S9GjcS2RxQo8PR1kflPR/krIpy8RxhgVu+B2nPpwBPGlmexP2Z98beA1ho53vxQ1pzgDuNLO9zex8wgY1B5vZPsCxwI8ryG/vGGdPgrFObniFwpak740yHAYUDu23mNm+wOcIy7a2EXZouzrKd3WJfP+bsD3wnnHRr1uj+1jCsrWvAe4APh7d7wL2j7skXkVY3z7PbsBBZvYBwpKrt5rZ7oRNlbaPerw66vmmeG07gQ+VvzyOM3zwITPHqT9vBn5rZp2E3ehuB14PFG7X3ApcIGlvgkHbpYI8bjGz1QCSHgOmAksS/m8C/mRmG4GNkv5cED+/i+RcwiuItBxE2MQJADN7KR62Adcn0jw4Hm8HXB0bPiMIK4bmmWVmG+Lxm4F3xzRvlJRP9+3A64D74pr4o2ngHf0cpxa44XecxuHzwHJCrzwDbKwg7qbEcSeV3/v5+P2JW4z2xIYoyTR/AvzQzGZJmgmck4izLkW6Ai43szOrIKPjNCU+1O849WENMD4e30kYfs9KmgS8Bbi3IAzABOBZM8sRdnis5rvrfwBHSholaRzptt4ulK8YNwGfzp9I2rxM+AnAM/H4hD7C/YO4U5+kQ4B8urcAx0h6RfTbotSy444zXHHD7zh1wMxeBP4RP8N7A/Aw8BDhHfiX4/7mDwOdcQLc54GfAidIegjYlXQ94LTy3AfMinn+FZgHrC4T7TZgt74m9wHfADaPExcfIu5/3gfnANdKmkvfe6N/HTgkXr/3Ac8Ba+Iuov8F/F3Sw4SGxzZl8nScYYWv1e84DhBm4JvZWkljCBPuTjGz++stVzEkjQQ6zaxD0huAn8XJfI7jlMHf8TuOk+ciSbsBowjvyYek0Y9sD1wjKUOYKPjxMuEdx4l4j99xmgRJ7wDOK3B+yszePQh5nwScXuD8DzP7dLHwjuPUDzf8juM4jjOM8Ml9juM4jjOMcMPvOI7jOMMIN/yO4ziOM4xww+84juM4wwg3/I7jOI4zjHDD7ziO4zjDCDf8juM4jjOMcMPvOI7jOMMIN/zOoCFpraRXpQg3TZJJavglpSWdKOmuesuRhmpfd0nT4wY+ayR9thpp1hJJMyUtTRHu0bhlcH/yqEndTntvOQ644XcSSFokaUN8iCyXdFncorU/ac2W9LGkm5mNM7OFVZRzjaRVkv4p6ZNx3XanD6Jxy8UyXiNpflxut9J0zpF0RZlgXwZuM7PxZvbj/klccZ79Dp8WM9vdzGanlGGRpIOqLUMhVby3Gqah6vSfsg9KSbtIuiVuf4mkvST9V+1Fc+rEkWY2DtgHmEHY4jQ1CgyGAT7SzMYDU4HvAF8BfjkI+TYDy2IZb0a4br+Im/NUm6nAo/2J2AyjPY4zZDGzPn/A7cC+wAMJt0fKxfNf4/2ARcBBifPvAdcDm8e/LwAvxePtEuFmA98E/gFsAK4EOoGNwFrgghjOgJ3i8eHAA8DLwBLgnER602LYljRyRrd9gRywRzwfCXwfeBpYDvwcGB39ZgJLga8S9nxfBHwokVaauF8AngeeBU5KxN2SsK/9y8C9wP8AdyX8dyXsEb8SmA+8P+F3GXAh8BdgDXAPsGPCf/dE3OXAV6N7BjgDeBJ4EbgG2KLEtZsJLC1wewE4pvC6A5OjLiuBBcDHo/uhhB3x2mP5PlQkn1sL6sAuwATgVzG/xYRGZSaGP5FQf86POnyjIL2ieVYqI3AS8Hi8vguBT/R1bcrVP+CceL1/FdN8FJgR/X5NqJMbogxfLrzGfeQxG/gG8M8Y98+EunUloW7dB0xLhE/eWyXrUbH8Y14fA14dy6sz5rkqxf2wFeF5sCqWwZ35MvXf0P2VDwD3xb8PJNwerLfg/qtBZej5QJsSH2L/Ex847wXGAOOBa4E/JuLNjg+F3QlbPbfmHyYF6ScfTjOBPQlGa6/4QHlX9Ovz4UgRwx/dnwZOjcfnEwzCFlHmPwPfTuTdAfwwPtTeCqwDplcQ99yo5zuB9cDm0f8qgiEYC+wBPEM0/NFtCcH4tACvJTQ8dov+lxGM3r7R/0rgqug3ntDI+AJh29zxwH7R73TgbmC7qM//Ab8tce1mEo1bvPbvJhjH6YXXHbgD+GnMb2+CwX5b9DsHuKJMfepRBwjG8U9R9mnAE8DJ0e/EeF0/E3UfXSS9XnlWKiOhwbkjoFju64F9Cq9NBffJOQRj+U4gC3wbuLtUXS28xmWu3YIo6wTgsXi9DorX51fApSXurcsoXY965Z8sp1gOdxXI0tf98G1CQ6A1/g4gbv7mv6H7SzMku0LSjrGyIOkYwgPIaU7+KGkVcBdhtOdbZvaimf3ezNab2RpC7/6tBfEuM7NHzazDzNrLZWJms81snpnlzOxh4LdF0qyUZcAWkgScAnzezFZGmb8FHFcQ/r/NbJOZ3U7oHb0/Zdx24FwzazezGwi9o+mSsoQG0llmts7MHgEuT8Q7AlhkZpfG6/QA8HvgfYkwfzCze82sg/DA3jsR9zkz+4GZbTSzNWZ2T/T7JPA1M1tqZpsIxuiYPobLJ8cyXgGcDRxvZvOTASRNAd4EfCXm9yBwMfCREmn2Sbw2xwFnRtkXAT8Ajk8EW2ZmP4nXZkOKNCuW0cz+YmZPWuB24O8EYzUQ7jKzG8ysk9DLf80A08tzaZR1NfBX4EkzuznWjWsJDcdSlKpHFZHifmgHtgGmxvvhTjPzLV+HOGneo30auAjYVdIzwFPAh2sqlVNP3mVmNycdJI0htPoPJQz7A4yXlI0POwg92dRI2o/wbn4PYAShp3rtQAQHtiUMN04ijE7MDc+tkCWhR5bnJTNblzhfTBg2ThP3xfhAzbMeGBfjttDzWixOHE8F9otGN08LwVjkea5IuhBGYJ6kOFOBP0jKJdw6ga0JIw6FLDOz7UqklWcykH/Q51lMmPfRH7Yi9AiT12MxoczyVFSH6IeMkg4jNHZ2IYx4jAHmVZhvIYVlNkpSS0Ed6Q/LE8cbipz3NfG2VD2qlHL3w/cIDc2/R/+LzOw7/czLGSTK9vjNbKGZHUSoALua2Ztja90ZPnyBMBS8n5ltBrwluisRprCVX67V/xvC8OEUM5tAGC5U31FKI+n1BCNyF6EnuwHY3cwmxt8ECxPa8mwuaWzifHvCiEGauKV4gTBcPaUg3TxLgNsT6U60MBv71BRpLwFKfa61BDisIN1RZlbM6KclP3oyPuG2Pd0NiUp7dSsIvcOpJdJLk2ahf0UyShpJGGH5PrC1mU0EbmAA9S4FQ633m2/sjkm4vTJxXChvn/dDHL35gpm9CjgK+H+S3l4r4Z3qkGZW/+mSNiO0Gs+XdL+kQ2ovmjOEGE+4+VdJ2oLQYyrHckobqnyaK81so6R9gQ/2RzBJm0k6gvBu/Yr86wPgF4T6+ooYbltJ7yiI/nVJIyQdQBhKv7aCuL2Iox/XAedIGhNnyp+QCHI9sIuk4yW1xt/rJb06harXA9tI+pykkZLGx1ETCI2mb0qaGuWdJOnoFGn2pcsSwsSyb0saJWkv4GQg/3nccmBa2i844rW5Jso5Psr6/xLppaFHnv2QMT+y9ALQEXv/tX6WlbsPBhUze4HQMPqwpKykjxLmEeRZDmwnaUQM3+f9IOkISTvFVwKrCSNNyZEnZwiS5qb9qJm9TLhBtiS8k/OhnOHF/wKjCa3/u4EbU8T5EeE980uSin3D/SngXElrgLMIRqES/hzjLgG+Rpiol/we/SuEyVF3S3oZuJkwapHnOcIXCssI70A/aWb/Thm3L04jDKs+R5hkdWneIw5JH0J4P7oshjmPYIz6JMY9GDgyxvsPcGD0/hFh9OTv8ZrcDexXLJ0K+QBhMtgy4A/A2YnXQPnXMi9Kuj9lep8h9DgXEkZmfgNcUoE8xfJMLWO8hp8l1LWXCI3NWRXk3x++DfxXXG/iizXOKy0fB75EmAC4O6HxlOdWwqTe5yStiG593Q87x/O1wL+An5rZbTXXwBkQKjcPQ9LDZraXpB8Bs83sD5IeMLO+JpY4zpBFYdW1K1K853Ycx2k60vT450r6O+Fzlb/F92k+lOM4juM4DUiaWf0nEz4FWWhm6yVtSc8hVcdxnKZB0vaE7+aLsZuZPV2lfNaW8DrMzO6sRh6OU4yyQ/0QJnMQZuN2NRTM7I4ayuU4juM4Tg0o2+OXdB5wLKEFnP9m2wgrZjmO4ziO00Ckmdw3H9grrgjmOI7jOE4Dk+Yd/0LCiltDwvBPnDjRdtppp3qLUTPWrVvH2LFjywdsUFy/xsb1a2xcv8Zm7ty5K8xs0kDTSWP41wMPSrqFhPE3s88ONPP+sPXWWzNnzpx6ZD0ozJ49m5kzZ9ZbjJrh+jU2rl9j4/o1NpIWlw9VnjSGfxa1X+TCcRzHcZxBoKzhN7PL4/KNu0Sn+ZZi9zXHcRzHcYYeaWb1zyRsLbqIsJnFFEkn+Od8juM4jtN4pBnq/wFwSH6/bkm7EPZOf10tBXMcx3Ecp/qkMfyteaMPYGZPSGpNk7ikQwkbiGSBiwv3aZZ0ImE/5/w2mheY2cVp0nYcx3Hqg5lhFhZ0MbP4F4zgDpArEYZEuGLxB7KRcUfOeP7ljQPUrvlJY/jnSLqY7q0uPwSUnVYvKQtcSNhRbClwn6RZZla4FObVZnZaBTI7juM4FZDLWZc9be/MdRll6G2gcwnjnLNuw5yLgQZglweFoS7fUCCN4T8V+DRhO0uAO4Gfpoi3L7DAzBYCSLoKOJrSa2A7juM0Lbmc0daZo60zR3tHruYGqpih7sgZK9e11ThnZ6iTZlb/JkkXALcQduWbb2Zpas62hL3S8yyl+B7h75X0FuAJ4PNmtqRIGMdxnIai0NB35Lwv6gwN0izZezjwc+BJwqz+HYBPmNlfy8Q7BjjUzD4Wz48H9ksO68ed/tbGxsUngGPN7G1F0joFOAVg0qRJr7vmmmsqULGxWLt2LePGjau3GDXD9WtsXL++sYL310ONDevWMnps85Zfs+t38NvfNtfMZgw0nbSz+g80swUAknYE/gL0afgJE/amJM63o3sSHwBm9mLi9GLgu8USMrOLgIsAdpk+3V7z+jeSzYrWTIaWrGjJCEkpVBn6NPvKU65fY+P6ddOIPfp5c/7FnjPeUG8xakaz61ct0hj+NXmjH1kIrEkR7z5gZ0k7EAz+ccAHkwEkbWNmz8bTo4DHU6RLW2cOOmFD12aBkM2EhkA2NgRasxmymeZoDDiOU38a0dA7TjHSzuq/AbiGMHr1PsIM/fcAmNl1xSKZWYek04C/ET7nu8TMHpV0LjDHzGYBn5V0FNABrARO7K8inTmjM9cZUooIaMl2jwq0ZDK0ZptndKBR6cxZ1+zh5Oc/ABkJKZSdJARkmrwBl3zdVvjmrZqmpdhV7OtzrMJh61BmxuoN7ak+ybJkvgLRu2zzt6JCgKL++XgkzruPC3QsuLeL6Vx4+5d6Hrihd5qVNIZ/FLAceGs8fwEYDRxJuLeLGn4AM7sBuKHA7azE8ZnAmZWJnB4jfLrS3tnTPSPRmlVoFGRioyCbqZUYDU/eMJnFT39IfAJU8NlP/lOg3uHCeUfOWLG28o0eC41HpsAwIMiop8HIqNtA9DKoeQPVdVygK4k4KcLm/TpyxgtrNkX3RKbFDxuOnMHGwhuqDBb/6/mN9tC8CsnvwIemhI4zcNLM6j9pMAQZTHJmbOowNnXkutxEeF1Q79GAzgF+blM4WdN6+BWE7cMaDbWHXqHx6BxyEnaTKzNh1hnaeOk5zU6atfq/C3wD2ADcCOxF+Ozuij4jNhj53mi9b/v8KIXjOI7j1II049uHmNnLwBGEjXp2Ar5US6Ecx3Ecx6kNaQx/flTgcOBaM1tdQ3kcx3Ecx6khaSb3XS/p34Sh/lMlTQJ8FwTHcRzHaUDK9vjN7AzgjcAMM2sH1hPW3Hccx3Ecp8Eoa/gljQE+BfwsOk0GBrxkoOM4juM4g0+ad/yXAm2EXj+EVfi+UTOJHMdxHMepGWne8e9oZsdK+gCAma1XvT92dxzHcQYVs7D2yfq2TjZ1dLKpPaxquKkjR1v8bero7HGe99/U3hlWQezoDl8YL+/fNoDPmds2bmTEnH9WUevmJI3hb5M0mviBe9ykp/Kl1xzHcRygeyVL6F6iuNp05owNbZ2sb+9g/aZONrR38u+Vnaz6zwusb+uMv+C3vr2T9Zs62NDeWdyvrYMNbZ0MZNXikS0ZRrRkuv6OyGYY2ZLtchs7soURLRlas5miSy2nYdXKNiZusVn/hRzi3FWldNIY/rMJC/dMkXQl8CYGsKa+4zhOs5Mz48W1bSxbtYFlqzewbNXGcLxqA8+u3sjzL2+is8QKjz2Woo4OeUNYuHdB3i0E63bvzPVcmbQHcx7u5TSqNcOYES2MGZFlzIgso1uzTBwzgskTsowZGc7HjmhhdPQf1ZrtYcSTBnxEttvA590Ha4+UsDvfHjXPp178okrp9Gn4JWWAzYH3APsT6t/pZraiSvlXzLp24x8LVrDZqFbGj2ph/KgWNhvdSquvtd9QmBkb23OhV9EW1n4fMyLL2JEtjGzJ1H3pZMfpCzPj5Q0d0agnDPvqDTy7aiPPrt7Ya8h6y7EjmDxxNHttN4FXThjFiPjMKtz/IbmdQVhLtHufiB5/kxsqdYUPDpIYOyLLmISxHjMiy3NPzWePPfcKxj3v35r1nUyHGX0afjPLSfqymV0D/GWQZOqTFRuM/3fNQ73cR7VmGD+yZ2MgHLey2agWxo3s7TY+Nh7c0PSNmdGZM9a3heHCdfkhwYJhwHVtnWFoMRrz9YnzvN/qdRtonz2bDW2lV9vPiB69j67jkeG48IE2tsC/MF5f5dvXrnLldqsLjj3TW99urN1YsEVkAaVqWqkqqIIYJcMV7jqXiNejh5gIkzO63stuau9+R7uxPbrF97P540WL2rlv41PxvDPG6Y5XGD4jGNUaymBk/Dsqxd9RraG3WOrvyNZM1yZMtWJ9W0ePnvqy1Ru7euzLVm3oarDm2WxUC9tMHM2rJo3lzTtvxeSJo9lmwqiuv6NaszWVNw3zVi/g1ds071C4k440Q/03S/oicDWwLu9oZitrJlUfbDsuw0UnzGDNxnbWbOzg5Q3h75pNHcFtQwcvb2znudUb+c/yDtZsamfdpr53E2vNKjQCRrbQkq1vA2Djhg2MeuDuiuP13Dq1e1e8Yn+7jukrTGK3vQrJDxV2GeLWLFuNG8Ho1iybXt7EtpMn9zDMo0eEB2LyveK6ROMh35BYtaq9+71jW2fqSUCZODzaq4dUK267vZap158nFpIRwQC3ZBiZN8aJ4/z7Wgw2xgbCqvVtbGrPsbGjk42xkbGxPUdnP18ct2bVq1EEBZtPJd1LZGOFgW6+FaCXXKNaM0yeMJrJE0ezz/YTexj2yRNGM25Umsep49SfNDX12Pj30wk3A15VfXHK05KBPbedUFGcjlyOdRs7eTnfWNjYztr4d83Gjh5upd67DRYvv7SRzTYf06+4Galra9pif/Nb2eb3vE/+LebW7Rf+jk70pEePyDI2MVw4JvHur6+eWHgHt0s/r05POjpzPUYZ1iUnJCUaDPnRhe6tfQO99oQv3Oo3ET65/W9hmKS6y5YsYvKUaUBxQzMgo1TgkEyr986L5eNA0GFka5xoVcSAj4zvavO98QXz5rLPvvvTUsWdLDs6c2xMjBRsLPibbyxsau/p15/Z3+VGVZ5/dimv2GY7AEaPyDI5b9gnjmbzMa0+Mug0BWm25d2hL39JB5vZTdUTqfq0ZDJMGJNhwpjWeotSlmAY96q3GA1BSzbDhNEZJoweOuU6L/MMe87Yvt5i1Ixlrar6fJqWbIZx2QzjRta/xzxvzvPsOWPHeovhODWlGnfweaU8JB0qab6kBZLOKOI/UtLV0f8eSdOqII/jOI7jOCWohuEvOvYlKQtcCBwG7AZ8QNJuBcFOBl4ys52A8+mjEeE4juM4zsCphuEv9VJ8X2CBmS00szbgKnpv7nM0cHk8/h3wdl8V0HEcx3FqRy0/ft8WWJI4XxrdioYxsw5gNbBlDWVyHMdxnGFNNWbTLKpCGn0i6RTgFIBJkyYxb86/ap1l3diwbq3r18C4fo2N69fYNLt+1SKV4Zf0RmBaMryZ/Sr+fU+JaM8AUxLn20W3YmGWSmoBJgAvFiZkZhcBFwHsMn267TnjDWnEbkjCrH7Xr1Fx/Rob16+xaXb9qkVZwy/p18COwINAfiUcA35VJup9wM6SdiAY+OOADxaEmQWcAPwLOAa41azOH9I7juM4ThOTpsc/A9itUoNsZh2STgP+BmSBS8zsUUnnAnPMbBbwS+DXkhYAKwmNA8dxHMdxakQaw/8I8Erg2UoTN7MbgBsK3M5KHG8E3ldpuo7jOI7j9I80hn8r4DFJ9wKb8o5mdlTNpHIcx3EcpyakMfzn1FoIpznpXhtfcW378BuRzfRc+z6u3GBxY6CuDYOSbnXTwnGcaqGu/3rudVG4f8ZA0h/hW7SXJc1a/U211VjSGOU3sOnadGUIrB2kuI1pNdPr079s/MTWrnRvTtO9sU1Pw57f3KfUtcxmxOZjR6SWP0kuZz12IOzaIjce5xKNBMv1doOem9l0uQ7Gjn3DgOS9BQUNuoItj52hQbnnYa/7uuDeD9ETbnTf+93GfPCerQN5vgwn0szq3x/4CfBqYARhot46M6vLps6Crv3Vu3qR+V3oEhUwU8x/CBj2cmSlIbXpzFAik+l6lNQ8r/xc1sJtfJNzXIs1JrIZMTFuBlVyx72uNIvvrmc9wg6OqSzcmTB5qyR3IsxmxJZjRxTd2TAt+VGdfCOua2QnuW1ysmFXEI6CsEk5e5wn60mhX6+wgYxgbJHNgkppV0ztYn3WSh49pXdqLF0XisXJPwPz+WckWjJiq3EjgzHPDP3noVMb0gz1X0CYbX8tYYb/R4Dq7KvaTyaO8RadU1u6ei29no19PyxDw7R6IzZDDRF20xtQGko2LIaW8clIQ2KXwFqSdYM/7FG5HoWkOWY2Q9LDZrZXdHvAzF47KBL2lmcNML8eeQ8SWwEr6i1EDXH9GhvXr7Fx/Rqb6WY2fqCJpGnarpc0AnhQ0ncJn/XVc/bEfDObUcf8a0q+oVVvOWqF69fYuH6NjevX2EiaU4100hjw42O404B1hCV231uNzB3HcRzHGVzSzOpfLGk0sI2ZfX0QZHIcx3Ecp0aU7fFLOpKwTv+N8XxvSbNqLFdfXFTHvAcD16+xcf0aG9evsXH9UpBmct9c4G3A7PyEPknzzGzPagjgOI7jOM7gkeYdf7uZrS5w83U4HMdxHKcBSWP4H5X0QSAraWdJPwH+WWO5kHSopPmSFkg6o4j/SElXR/97JE2rtUzVQtIUSbdJekzSo5JOLxJmpqTVkh6Mv7OKpTVUkbRI0rwoe6+ZqAr8OJbfw5L2qYec/UHS9ES5PCjpZUmfKwjTUOUn6RJJz0t6JOG2haSbJP0n/t28RNwTYpj/SDph8KROTwn9vifp37H+/UHSxBJx+6zLQ4ES+p0j6ZlEHXxnibh9PmuHAiX0uzqh2yJJD5aI2wjlV9Qm1OweDKtolf4BY4BvAvfF3zeAkeXiDeRHWB3wSeBVhNUCHyJsDZwM8yng5/H4OODqWspUZf22AfaJx+OBJ4roNxO4vt6yDkDHRcBWffi/E/grYQWX/YF76i1zP/XMAs8BUxu5/IC3APsAjyTcvgucEY/PAM4rEm8LYGH8u3k83rze+qTU7xCgJR6fV0y/6NdnXR4KvxL6nQN8sUy8ss/aofArpl+B/w+Asxq4/IrahFrdg2l6/LvFXwswCjia0ACoJfsCC8xsoZm1AVfFfJMcDVwej38HvF1qgDV5ATN71szuj8drgMeBbesr1aBzNPArC9wNTJS0Tb2F6gdvB540s8X1FmQgmNkdwMoC5+Q9djnwriJR3wHcZGYrzewl4Cbg0FrJ2V+K6Wdmfzezjnh6N7DdoAtWJUqUXxrSPGvrTl/6xef++4HfDqpQVaQPm1CTezCN4b8SuAR4D3BE/B2ZIt5A2BZYkjhfSm/D2BUm3ryrgS1rLFfVia8oXgvcU8T7DZIekvRXSbsPrmQDxoC/S5or6ZQi/mnKuBE4jtIPnEYuP4CtzezZePwcsHWRMM1Sjh8ljEAVo1xdHsqcFl9lXFJimLgZyu8AYLmZ/aeEf0OVX4FNqMk9mGblvhfM7M8pwjkVImkc8Hvgc2b2coH3/YTh47Xx3dwfgZ0HWcSB8GYze0bSK4CbJP07ttqbBoUVLY8Czizi3ejl1wMzM0lNOalX0teADkInpxiNWpd/BvwPwfD9D2E4/KN1lag2fIC+e/sNU36FNiE5iF3NezBNj/9sSRdL+oCk9+R/1ci8D54hrBCYZ7voVjSMpBZgAvBijeWqGpJaCQV8pZldV+hvZi+b2dp4fAPQKmmrQRaz35jZM/Hv88AfCEOKSdKU8VDnMOB+M1te6NHo5RdZnn/9Ev8+XyRMQ5ejpBMJo5gfsvjCtJAUdXlIYmbLzazTzHLALygud6OXXwthNPrqUmEapfxK2ISa3INpDP9JwN6EdwZHxt8RKeINhPuAnSXtEHtVxwGFiwbNAvKzF48Bbi114w414jupXwKPm9kPS4R5ZX7OgqR9CWXVEA0bSWMljc8fEyZRPVIQbBbwEQX2B1YnhrQahZI9jUYuvwTJe+wE4E9FwvwNOETS5nEo+ZDoNuSRdCjwZeAoM1tfIkyaujwkKZgz826Ky53mWTuUOQj4t5ktLebZKOXXh02ozT2YYrbh/DrNcnwnYWbjk8DXotu5hJsUwkTDa4EFwL3Aq+ohZz91ezNh+O1hwqqID0Z9Pwl8MoY5DXiUMMv2buCN9Za7Av1eFeV+KOqQL7+kfgIujOU7D5hRb7kr1HEswZBPSLg1bPkRGjDPAu2Ed4QnE+bM3AL8B7gZ2CKGnQFcnIj70XgfLgBOqrcuFei3gPBuNH8P5r8SmgzcEI+L1uWh9iuh36/jvfUwwYBsU6hfPO/1rB1qv2L6RffL8vdcImwjll8pm1CTezDNyn2XAt8zs8f6DOg4juM4zpAnjeF/HNgReArYROipmZntVXvxHMdxHMepJmkM/9Ri7tbg3y07juM4znCkrOF3HMdxHKd5SDOr33Ecx3GcJsENv+M4juMMI9zwO47jOM4wwg2/49QRSRMlfapMmGkKW2OXS2tactvSIv4zJP24EnnKpZkWSedKOqifccteI8dx0uOG33Hqy0TCFtN9MQ0oa/jLYWZzzOyzVZCnP3mfZWY39zP6RGogk+MMV9zwO059+Q6wo6QHJX0v/h6RNE/SsYkwB8Qwn4+98Dsl3R9/b0yTkaSZkq6Px+fEHdtmS1ooKd8g6CFPijRPlPRHSTdJWiTpNEn/T9IDku6WtEUMd5mkY+LxIklfj7LPk7RrQqYvJtJ+RGGnsl4ySfqSpPsUdp77enQbK+kvCjsiPpK4fo7jJEizO5/jOLXjDGAPM9tb0nsJy/6+BtgKuE/SHTHMF83sCABJY4CDzWyjpJ0Jy5nO6EfeuwIHAuOB+ZJ+lpQn5jUtRTp7ELYRHUVYMvQrZvZaSecDHwH+t0icFWa2TxzC/yLwsT7SL5TpEMJOh/sSFhSbJektwCRgmZkdHsNNSCG74ww7vMfvOEOHNwO/tbCj2nLgduD1RcK1Ar+QNI+wX8Vu/czvL2a2ycxWEHb9KrbXdxpuM7M1ZvYCsBrIb+M9j/Caohj53cfm9hGmFIfE3wOE7Y93JTQE5gEHSzpP0gFmtrrCdB1nWOA9fsdpPD4PLCeMDGSAjf1MZ1PiuJP+Pw+S6eQS57k+0syHSebbQc/OyKgScQV828z+r5eHtA9hc5NvSLrFzM4tL77jDC+8x+849WUNYagd4E7gWElZSZOAtxB2nkyGAZgAPGthn/XjgWyN5BlsFgH7QJcB36GETH8DPippXAy7raRXSJoMrDezK4Dv5dNyHKcn3uN3nDpiZi9K+kf8ZO6vhG05HyJs0fllM3tO0otAp6SHCNuQ/hT4vaSPADcC62ooz4XVSjsFvwc+IulR4B7CVrG9ZDKzL0l6NfCvsI05a4EPAzsB35OUI2zfeuogyu44DYOv1e84juM4wwgf6nccx3GcYYQP9TtOkyHpHcB5Bc5Pmdm7h1KajuPUBx/qdxzHcZxhhA/1O47jOM4wwg2/4ziO4wwj3PA7juM4zjDCDb/jOI7jDCPc8DuO4zjOMMINv+M4juMMI9zwO47jOM4wwg2/4ziO4wwj3PA7QxJJayW9KkW4aZJMUsOvQinpREl31VuONFT7ukuaLulBSWskfbYaadYSSTMlLU0R7lFJM/uZR03rtqTZkj4Wjxum7jkDxw2/0y8kLZK0IRro5ZIuy2+T2o+0uh5AecxsnJktrKKcayStkvRPSZ+U5HW/DNG45WIZr5E0X9JJ/UjnHElXlAn2ZeA2MxtvZj/un8QV59nv8Gkxs93NbHZKGRZJOqjaMjhOIWUffpJ2kXRL3BITSXtJ+q/ai+Y0AEea2TjCvuczgIrqhQKDYYCPNLPxwFTgO8BXgF8OQr7NwLJYxpsRrtsvJO1Wg3ymAo/2J2IzjPY4zmCS5qH7C+BMwv7WmNnDwHG1FMppLMzsGcLe7XtI2lzS9ZJekPRSPN4uHzb27r8p6R/AeuDXwAHABbFneUEMZ5J2iseHS3pA0suSlkg6p59yrjazWcCxwAmS9ojpj5T0fUlPx9GLn0saHf1mSloq6auSVsRe2YcS+qSJ+wVJz0t6NtljlrSlpFlRr3uBHZPyStpV0k2SVsbe9vsTfpdJulDSX2Jv/B5JOyb8d0/EXS7pq9E9I+kMSU9KelHSNZK2SHHtzMz+CLwE9DL8kiZHXVZKWiDp49H9UOCrwLGxfB8qEvdW4EC668AukiZI+lWsR4sl/Ve+kagwLP0PSedLehE4pyC9onlWKqOkkyQ9Hq/vQkmfKHediujW1YuPowrXRL3WKLwGmBH9fg1sD/w5yvDlCvLYQtKlkpbFe+6P0b3Pe7GP9BSv7fOxbs7L3ytOc5DG8I8xs3sL3DpqIYzTmEiaArwTeIBQpy4l9OC2BzYAFxREOR44BRgPnAjcCZwWh/dPK5LFOuAjwETgcOBUSe/qr7yxPi8lNDggjALsAuwN7ARsC5yViPJKYKvofgJwkaTpFcSdEN1PBi6UtHn0uxDYCGwDfDT+AJA0FrgJ+A3wCkJj+6fq2ds+Dvg6sDmwAPhmjDseuBm4EZgc5bolxvkM8C7grdHvpShHn8QGw7sJZTCvSJCrCNd0MnAM8C1JbzOzG4FvAVfH8n1NYUQzexs968ATwE/idXtVlPUjQPI1w37AQmDrvN6J9ErlWamMzwNHEEY7TgLOl7RPuWtVhqOiHBOBWcR7w8yOB54mjqKZ2XcrSPPXwBhgd0JdOT+6p7kXi3EI8BZCvZ4AvB94sQJ5nKGOmfX5I/TkdgTuj+fHAH8tF89/zf0DFgFrgVXAYuCnwOgi4fYGXkqczwbOLQgzG/hYgZsBO5XI+3+B8+PxtBi2pQ85DyrifjfwNUCEhsWOCb83ELacBZhJaOiOTfhfA/x3yrgbkrIRjMn+QJYwirZrwu9bwF3x+FjgzgKZ/w84Ox5fBlyc8Hsn8O94/AHggRLX43Hg7YnzbaIcva5flD8Xy3gl8CBwXOF1B6YAncD4RNxvA5fF43OAK8rUp646EK9NG7Bbwv8TwOx4fCLwdJn0euRZJRn/CJyeuDZLU94nByXyuDnhtxuwoVRdpUzdTpRfDtg8hSx70/tezF/zExN1723AE4R6mimXrv8a75fm3dingYuAXSU9AzwFfDhFPKf5eZeZ3Zx0kDSG0OM4lNATBRgvKWtmnfF8SSWZSNqP0LPeAxgBjASuHYjghB74SmASobc0V1JXlgTjk+clM1uXOF9M6DWmifuimSVHyNYD42LcFnpei8WJ46nAfpJWJdxaCL27PM8VSReCkXuS4kwF/iApl3DrJPScnykSfpmZlRsengysNLM1CbfFhHkf/WEroJWe12MxoczyVFSH6IeMkg4Dzib0fDOEsi422lEJhWU2SlJLQR2phCkEvV4q9Eh5L/bCzG5VeOV2ITBV0nXAF83s5X7K6Awxyg71m9lCMzuI8KDa1czebGaLai6Z06h8AZgO7GdmmxGGDCEYxDxWEKfwvJDfEIZFp5jZBODnBelVhKTXE4zIXcAKQq98dzObGH8TLExoy7N5HHrPsz2wLGXcUrxAGEmYUpBuniXA7Yl0J1oYAj41RdpLCEPkpfwOK0h3lIV5Gv1lGbBFfMWQZ3u6GxLlyreQFYRRiKkl0kuTZqF/RTJKGgn8Hvg+sLWZTQRuYAD1LgWVXicI5bmFpIlF/NLci8UFMfuxmb2OMCqxC/ClfsjmDFHSzOo/XdJmhNbp+ZLul3RI7UVzGpTxBGO4Kk4aOztFnOWUNlT5NFea2UZJ+wIf7I9gkjaTdAThHesVZjbPzHKECaznS3pFDLetpHcURP+6pBGSDiC89722gri9iD2u64BzJI2J7+5PSAS5HthF0vGSWuPv9ZJenULV64FtJH1OYfLh+DhqAqHR9E1JU6O8kyQdnSLNvnRZAvz/9s48To6q3N/Pt2cm+w4Bw5ZAgGBYRAiLe1BERBAvooAb4IIbinq5il5/iqhXcfdeRa8iCC4IqHgRUEE04saSQCBswRAICYEEkpA9k8z0+/vjnJ6p6emeqe6pnu6eeZ9POlN1tnrPqarznq3O+w/gS5JGSTqEsJ6h8HncKmCGUn7BEcvmmijn+CjrxxLppaHHNauQsTCy9AzQEXv/ta73+nsPemFmTxGmYy+Ji/naJBUUfDXvIvE5O0pSG2EqaxthOsEZIqR5Ed8Zh3iOA3YiLMz6ck2lcpqZbwGjCb222wkLzPrj28CpceVxqW+4PwBcJGkjYeHcNRXK9NsYdzlhXv8b9Fwo9gnC4rjbJW0gLIyblfB/mrAIbiXwM+B9ZvZwyrh9cS5heP5pwpz95QWPOCR9HGEB38oY5mKCMuqTGPfVwEkx3r8Iq+YhlPX1wM2xTG4nLJQbKGcQ5qRXAtcR1iIUpoEK0zJrJN2dMr0PEZTOUsLIzM+ByyqQp9Q1U8sYy/DDhGdtHaGxeX0F16+GLwGfVthv4vwK4r2dMELyMGENyUei+7eo/F2EsJjxh4R8LyMs7PtqBfI4DY7M+h5dknSfmR0i6duExTXXSbrHzF44OCI6Tv1Q2HXtpynmuR3HcZqCND3+BZJuJqwa/kOcI/NhH8dxHMdpQtKs6n8X4TOQpWa2RdJO9BwmdRzHGZZI2gt4sIz3bDN7IqPrbCrj9Voz+2sW13CGD/0O9UNYsERYYdvVUDCz22ool+M4juM4NaDfHr+kiwmbiTxI+N4Xwmcnrvgdx3Ecp8lIs7hvMXCImbUPjkiO4ziO49SKNHP8Swm7aDWE4p80aZLtu+++9RajZmzevJmxY8f2H7BJ8fw1N56/5sbz19wsWLDgWTObOtB00ij+LcBCSbeSUP5m9uGBXrwadt11V+bPn1+PSw8K8+bNY+7cufUWo2Z4/pobz19z4/lrbiQt6z9U/6RR/NdT+40rHMdxHMcZBPpV/GZ2haQRhP2aARab2Y7aiuU4juM4Ti1Is6p/LnAFwWSkgD0lnemf8zmO4zhO85Fm576vA8eZ2SvM7OXAawimHvtF0vGSFktaIumCEv5nSXpG0sL4e3dl4juO4ziOUwlp5vjbzGxx4cTMHolWm/pEUgvBnvOrgRXAXZKuN7PiXa6uNrNzKxE6a/J5Y+uOTto78uSLPm9M2q9M2FzvZdcy4YWKfeNpS06MbM3R1pLKSJnjOI7jZE4axT9f0qV0m698K5BmWf2RwBIzWwog6RfAyZTf3nJQMTPaO/Js3d7J9s60pgeqMZfdk83tkJMY1ZZjZGsLI1q9EeA4juMMHmkU//uBDxJMVAL8FbgkRbzdCWZQC6ygtPnPN0b70Y8AH412s2tGe0cn23bkad/RmYEar468GVu2d7Jleyc5iZFtOUZ5I8BxHMcZBNLu1T8CeD7BKt9iM9ueIs6pwPFm9u54/nbgqOSwfjT4s8nM2iW9FzjNzF5ZIq1zgHMApk6devg111Rqjj0o23y9NH0FbN28iXHjx/eaShgqbNq0iXHjxtVbjJrh+WtuPH/NzVDP3zHHHLPAzOYMNJ00q/pfB3wfeJQwW723pPea2e/6ifoksGfifI/o1oWZrUmcXgp8pVRCZvYD4AcAs2bNsjQbNOTzxraOTrZu76SjGTR+ZNH8fzL7sKORYGRrCyNbc4xszfVYX9DMDPUNNjx/zY3nr7kZ6vnLijRD/V8HjjGzJQCSZgI3Av0p/ruA/STtTVD4pwNvSQaQNM3MnoqnrwceqkD2XhTm7bft6GR7R75uQ/lZYAbbdnSybUdnaAS0tDCybWg1AhzHcZzBJ43i31hQ+pGlwMb+IplZh6RzgT8ALcBlZvaApIuA+WZ2PfBhSa8HOoC1wFmVZgBge0c+rsrvJMXMRdNhBts6OtnW0YmIIwHeCHCcYYWZYRaWGJtZ/AuGddV7hfMkya+MCh2KYsp9ldTTvTnoSL1Ye/iSdlX/TcA1hGfuTYRP804BMLNfl4toZjcBNxW5fSZx/Engk1XITUdnnm2xd9/ZREP5A8Xo2QgY0ZrrmhLI5dK9mqXWdZRqMJUq1WRc63JLxkn4l0rTYOv2zpLh+6PXZ5J9hS0TVOpOJxx3f6apgps3plJTUEbQrZC6jytMq8oxur6uU+7ZLBXPgLzBpvaOku9IVbL15WchQA/FTW+lHv9lQqcZ67cO3Y1XO/LGms39LkEb9qRR/KOAVcAr4vkzwGjgJMLzWFbx14q1m7ezw1t1GNDekae9I5RFKXXVaE2iTjM2bGuOikfxv/4aCt3hRWfeWL9lR4mESqRfzj2lfGnvbb86LNFLtISSKSigbnejI2+s3rCt4Z6rrMibsbm9o95iOE5NSbNX/9mDIUhaDFzpl2GoVsb1wuJ/XerPeviUjbOto/dQ6lDCnzPHaW76/XBc0lckTZDUJunWuMXu2wZDOMdxHMdxsiXNjjHHmdkG4ESCoZ59gf+opVCO4ziO49SGNIq/MB3wOuBaM1tfQ3kcx3Ecx6khaRb33SDpYWAr8H5JU4FttRXLcRzHcZxa0G+P38wuAF4MzDGzHcAWgrEdx3Ecx3GajDSL+8YAHwC+F512Awa8V7DjOI7jOINPmjn+y4HthF4/hO13v1AziRzHcRzHqRlp5vhnmtlpks4AMLMtGmJbm23ctoOHntrI4lUb2dGRpyWn7p/C31w8b82JXMFN0JrLRX96hC/8CmFbc2LMiFZ2nTDSd4ZzHMdx6kYaxb9d0mjivh3RSE97TaWqIds78vxr9UYeXLmBB1Zu4MGVG1i2dsugXX/syBZmTh3HfruMY+bUcey7yzhm7jKOcSPT3ArHcRzHGRhptM1ngd8De0r6GfASqjSmM9jkzVi2ZktU8ut58KkN/GvVpi4zvTuNHcGBu0/ghIOnMXu3CRzwvPGMGdlCZ97ozBv5PHTmjY58nk7rPu/MG51m3eEsbGUa4vT2L4RZv3UHS1Zv4tFnNvOHB1axqb3bSvG0iaPYd5dxTOjYzqoxq9h3l3HsMWU0rbk0szGO4zhhm+Wt0TqpFEYgcznIKYw+duYNM/NRx2FOn4pfUg6YDJwCHE3YRvw8M3t2EGSrmGc2tvPAyvVdPfmHnt7A5vawfeqYES08f9oE3nLUXsyeNoHZu01gl/Glh91bB0HXmhmrNrSzZPUmljyzKfxdvYllazq48bH7ARjRkmPvqWPZd5cwQrDv1DA6MGXsiNoL6DjOoJE3Y+v2Tja1d7C5vYPN2zvD376O2zvZvL33cb82y/74JwRh+rKoYZDLEdyk0v4KU5qN2nDYtmUroxbeUW8xGp4+Fb+Z5SV93MyuAW4cJJlSsWlbBw89tYEHnwpK/oGnNvDMxjAD0ZIT++0yjuMPfB6zd5vA7GkTmL7TWFpSWq8bDCTxvImjeN7EUbx0v5273O++4x+Mm3EwS1Zv4l+xMXD7o2u48b6nusJMGTuCfWNDYN9dwm/GzmMY2doyYLmSlsGgp3WwwshFPk8cAQnnhdGQvHWPboS/Pd3yefjXuk62L1sXRkas271iKriVIjwTbS05WnOitSVxnMvR2hLdCse5HG0taugKrl7kzdi2o5OOTmN7Z54d8be9I09H3tjeUXAzdnTmyRdZ7yPxXJWy6legnLGggl8hjeSoWhidK33c7ZbvMWrX0dnTf926dsY8urBr9K4v+RLZ6WGVsHQ463lusHVHVOLbO9jS3pnKBsLothbGjmxh7IhWxo5sZezIFqaMGcPYUa2MHdES3VoZ2ZILZU/P93bliieYOm2PHu9e3ore2aJ3s9PCKEHSv1HtNWxgKxMmja63GA2P+jM/KenLwLPA1cDmgruZra2taKWZstf+dsiH/pfH13TPy+85ZTQHTpsYlPxuE9h/13GZKMF6sGj+Pzl4zot6ua/dvJ1Hi0YHHnt2c5dlvhaJkW1hqKKUjW7odksanymuwJyeFBoKhcZAsqGQbCDkJCTYunkT48aN72o05KKZ3+TfQtgc8W/sXZULm7yfxfeu1HmXEiqy3V5owCXve96MHR1BSW/vzPdS6AUFvqMzz46OoBCajcLi2uIFu4Vfa0twa83l2L5tc+L+dbcvy1lkLPYj4d9lRrrnny7/oMSDoh4XlXhSoSePx41sZfSIlgFP/ZWrX4YKQz1/z5s4eoGZDfhz+jRz/KfFvx9MuBmwz0AvXg3bOow9p4zhNbE3//xpE5g4uq0eogwqU8aOYMreUzhi7yldbp15Y8W6LV0Nga07wrSGgi3ZbvvyUcEU6HILgXtUbsmKrbiy6zH8F4f8Sg0JdrmXCLNsyUPsO2t2d7joXknHulLdU+jNdOSDEuvIG52d3ceFvx1dfxNu+aD8OjpDT3FHZ0+3jpguhdGNrdDakuvqIe2IPd58H3/Dr7xfX/ez7HnRfUzG7ZGWxIiW0IAZN7KVEa1hJGREa47WllyXX1tLjraWHOtWPcnue+7VI1zBrxBuREuua1SlMMqWVIbFz2KXe5FbQfbgX6RQ43FBofdQ7EVKvpJRm6A4jkgd3nGakTRmeffuy1/Sq83sluxE6ps9xuf42pteMFiXa2hacmL6TmOZvtNYXvX8XestTirGrWvh4BlT+g/YpATFcVi9xagZi+av5uA5M+othuM4AyCLZWwXl/OQdLykxZKWSLqghP9ISVdH/zskzchAHsdxHMdxypCF4i85jiapBfgu8FpgNnCGpNlFwd4FrDOzfYFv0kcjwnEcx3GcgZOF4i8343oksMTMlprZduAX9DbuczJwRTz+JfCqobYroOM4juM0ErX8Yn13YHnifEV0KxnGzDqA9cBONZTJcRzHcYY1WewT+3gGafSJpHOAcwCmTp3Kovn/rPUl68bWzZs8f02M56+58fw1N0M9f1mRSvFLejEwIxnezK6Mf08pE+1JYM/E+R7RrVSYFZJagYnAmuKEzOwHwA8A9p81y4byd5pD/TtUz19z4/lrbjx/DqRQ/JJ+AswEFgKd0dmAK/uJehewn6S9CQr+dOAtRWGuB84E/gmcCvzJ+ttRyHEcx3GcqknT458DzK5UIZtZh6RzgT8ALcBlZvaApIuA+WZ2PfAj4CeSlgBrCY0Dx3Ecx3FqRBrFfz/wPOCp/gIWY2Y3ATcVuX0mcbwNeFOl6TqO4ziOUx1pFP/OwIOS7gTaC45m9vqaSeU4juNURNjWuNv+A/Q0LlQ4KmyjXDyG28v0Tt+nThOTRvFfWGshHMdxnG66bGMkjDZ1uyUMPRWF6Y/WnNh53MhByEF9eCgndp0wqt5iNDxp9ur/y2AIUkuKW8IitohFbzdKmNBMpFVsfrOr1VxkfrNU/L5M3jqOMzBUdFAw+1POyl7BrytsrA9Gj2jpmV41sqRQwrlEzzyp0HMNZD7cGZqkWdV/NPA/wPOBEYSFepvNbEKNZSstDzCqraWXwi68Z7liBd8kL5FFi2yFFnmykVDKlncPs6x0NypqTXFpJiu43n7FcYO1tAmj2iqyxlcJfaVbanlq0q1Uoy24F9x6D5sWh5VgVJFJ6OI703uItVimntdJU1RpN7wsFaqU1btiZVk4zsX7l4zXHb68oq1Grj7Dl7DglwUtifw5zlAlzVD/dwir7a8lrPB/B7B/LYXqj6FohleJxkuYg2uOBkulJHtUQ5EWiYljht7zWSA3xO+f4wwHUm3Za2ZLgBYz6zSzy4HjayuW4ziO4zi1IE2Pf4ukEcBCSV8hfNZXyz3+++SRRx7ZJGlxva4/COwMPFtvIWqI56+58fw1N56/5mZWFomov315JE0HVhHm9z9K2Fb3kjgKMOhImm9mc+px7cHA89fceP6aG89fc+P5S0eaVf3LJI0GppnZ5wZ6QcdxHMdx6ke/Q/aSTiLs0//7eH6opOtrLJfjOI7jODUgzVz9hcCRwHMAZrYQ2LtmEvXPD+p47cHA89fceP6aG89fc+P5S0GaOf7bzexoSfeY2Quj231mdkgWAjiO4ziOM3ikWdX/gKS3AC2S9gM+DPyjtmI5juM4jlML0gz1fwg4kGCg5+fAeuC8WgoFIOl4SYslLZF0QQn/kZKujv53SJpRa5myQtKekv4s6UFJD0jqVZ6S5kpaL2lh/H2mVFqNiqTHJS2Kss8v4S9J/x3v332SDquHnNUgaVbiviyUtEHSR4rCNNX9k3SZpNWS7k+4TZF0i6R/xb+Ty8Q9M4b5l6QzB0/q9JTJ31clPRyfv+skTSoTt89nuREok78LJT2ZeAZPKBO3z7q2ESiTv6sTeXtc0sIycZvh/pXUCTV7B8NWseV/hN36rgPuARbF3339xRvIj7At8KPAPoTPCO8FZheF+QDw/Xh8OnB1LWXKOH/TgMPi8XjgkRL5mwvcUG9ZB5DHx4Gd+/A/AfgdYYvCo4E76i1zlflsAZ4Gpjfz/QNeDhwG3J9w+wpwQTy+ALi4RLwpwNL4d3I8nlzv/KTM33FAazy+uFT+ol+fz3Ij/Mrk70Lg/H7i9VvXNsKvVP6K/L8OfKaJ719JnVCrdzBNj/9nwGXAKcCJ8XdSingD4UhgiZktNbPtwC+Ak4vCnAxcEY9/CbxKqtUO8NliZk+Z2d3xeCPwELB7faUadE4GrrTA7cAkSdPqLVQVvAp41MyW1VuQgWBmtwFri5yT79gVwBtKRH0NcIuZrTWzdcAtNODOnqXyZ2Y3m1lHPL0d2GPQBcuIMvcvDWnq2rrTV/5ivf9m4KpBFSpD+tAJNXkH0yj+Z8zst2b2mJktK/zSZadqdgeWJ85X0FsxdoWJL+96YKcay5U5cYrihcAdJbxfJOleSb+TdODgSjZgDLhZ0gJJ55TwT3OPm4HTKV/hNPP9A9jVzJ6Kx08Du5YIM1Tu4zsJI1Cl6O9ZbmTOjVMZl5UZJh4K9+9lwCoz+1cZ/6a6f0U6oSbvYJrFfZ+VdClwK2GeHwAz+3WKuE4fSBoH/Ar4iJltKPK+mzB8vCnOzf0G2G+QRRwILzWzJyXtAtwi6eHYah8yKGxl/XrgkyW8m/3+9cDMTNKQtCAt6T+BDsLoZima9Vn+HvB5guL7PGE4/J11lag2nEHfvf2muX/FOiE5iJ3lO5imx382cChh6OCk+Dsxi4v3wZPAnonzPaJbyTCSWglbCa+psVyZIamNcIN/VqoRZWYbzGxTPL4JaJO08yCLWTVm9mT8u5qwRuTIoiBp7nGj81rgbjNbVezR7Pcvsqow/RL/ri4Rpqnvo6SzCPXZWy1OmBaT4lluSMxslQXDanngh5SWu9nvXythGvrqcmGa5f6V0Qk1eQfTKP4jzGyOmZ1pZmfHX61bjXcB+0naO/aqTgeKdwu8HiisXjwV+FO5F7fRiHNSPwIeMrNvlAnzvMKaBUlHEu5VUzRsJI2VNL5wTFhEdX9RsOuBdyhwNLA+MaTVLJTtaTTz/UuQfMfOBP6vRJg/AMdJmhyHko+Lbg2PpOOBjwOvN7MtZcKkeZYbkqI1M/9GabnT1LWNzLHAw2a2opRns9y/PnRCbd7BFKsNL6cOqzwJq74fIaw4/c/odhHhJQUYBVwLLAHuBPYZbBkHkLeXEobf7iNsh7ww5vd9wPtimHOBBwirbG8HXlxvuSvI3z5R7ntjHgr3L5k/Ad+N93cRMKfecleYx7EERT4x4da094/QgHkK2EGYI3wXYc3MrcC/gD8CU2LYOcClibjvjO/hEuDseuelgvwtIcyNFt7BwldCuwE3xeOSz3Kj/crk7yfx3bqPoECmFecvnveqaxvtVyp/0f3HhXcuEbYZ7185nVCTdzDNzn0PATOBxwhz/CJMN/jOfY7jOI7TZKQ1y9sLa/LPlxzHcRxnONKv4nccx3EcZ+iQZnGf4ziO4zhDBFf8juM4jjOMcMXvOI7jOMMIV/yO4ziOM4xwxe84DY6kSZI+0E+YGZLekiKtGUnTpiX850j670rk6S/NSpH0Y0mnxuN5kuZklbbjOK74HacZmEQwQ90XM4B+FX9/mNl8M/twBvI4jtOguOJ3nMbny8BMSQslfTX+7pe0SNJpiTAvi2E+Gnvhf5V0d/y9OM2FJM2VdEM8vjBadZsnaamkQoOghzwp0myR9LUo832SPhTdPyPpruj+g8IWx32k8eNEvj+aJj+O4/QmjXU+x3HqywXAQWZ2qKQ3ErYGfgGwM3CXpNtimPPN7EQASWOAV5vZNkn7EbY8rWbI/ADgGGA8sFjS95LyxGvN6CeNcwgjEoeaWYekKdH9O2Z2UUzjJwRjOb8tk8ahwO5mdlAMP6mKvDiOg/f4HafZeClwlQWra6uAvwBHlAjXBvxQ0iKCTYvZVV7vRjNrN7NnCZbBStkD749jgf81sw4AM1sb3Y+RdEeU8ZXAgX2ksRTYR9L/ROM6xWasHcdJiSt+xxmafBRYRRgZmAOMqDKd9sRxJxmNEkoaBVwCnGpmBxPMxo4qF97M1hHyMo8w4nFpFnI4znDEFb/jND4bCUPtAH8FTotz3lOBlxOsUybDAEwEnrJgi/3tQEuN5EnDLcB7o+104lB/Qck/K2kcwbR2WSTtDOTM7FfAp4HDKpbacRzA5/gdp+ExszWS/h4/mfsdwXTnvQQznh83s6clrQE6Jd1LMFV6CfArSe8Afg9srqE83+0nyqXA/sB9knYAPzSz70j6IcE2+tMEu/B9sTtwuaRCZ+WT1efAcYY3bqTHcRzHcYYRPtTvOI7jOMMIH+p3nGGIpNcAFxc5P2Zm/9ZIaTqOkz0+1O84juM4wwgf6nccx3GcYYQrfsdxHMcZRrjidxzHcZxhhCt+x3EcxxlGuOJ3HMdxnGGEK37HcRzHGUa44nccx3GcYYQrfsdxHMcZRrjid+qGpE2S9kkRboYkK1h3a2YknSXpb/WWIw1Zl7ukWZIWStoo6cNZpFlLJM2VtCJFuAckza3yGgMq47QyOk6SfhW/pP0l3RotcSHpEEmfrr1oTr2R9LikrVFBr5L042hCtZq05kl6d9LNzMaZ2dIM5dwo6TlJ/5D0voQlN6cMUXHk4z3eKGmxpLOrSOdCST/tJ9jHgT+b2Xgz++/qJK74mlWHT4uZHWhm81LK8LikY7OWwXEqIU3F+EOCCcwdAGZ2H3B6LYVyGoqTzGwcwf75HIIt9NQoMBgK+CQzGw9MB74MfAL40SBcdyiwMt7jCYRy+6Gk2TW4znTggWoiDoXRnkbHy3j4kKZCHmNmdxa5ddRCGKdxMbMnCbbXD5I0WdINkp6RtC4e71EIG3v3X5T0d2AL8BPgZcB3Ys/yOzGcSdo3Hr9O0j2SNkhaLunCKuVcb2bXA6cBZ0o6KKY/UtLXJD0RRy++L2l09JsraYWkT0l6NvbK3prIT5q4/y5ptaSnkj1mSTtJuj7m605gZlJeSQdIukXS2tjbfnPC78eSvivpxtgbv0PSzIT/gYm4qyR9KrrnJF0g6VFJayRdI2lKirIzM/sNsA7opfgl7RbzslbSEknvie7HA58CTov3994Scf8EHEP3M7C/pImSrozP0TJJny40EhWmRP4u6ZuS1gAXFqVX8pqVyijpbEkPxfJdKum9/ZVTibx19eLjqMI1MV8bFaYB5kS/nwB7Ab+NMny8gmtMkXS5pJXxnftNkX+556/se6XuaYZ3SXoC+JOkFklfj+/BY5LOVWIqIt6zH8XrPCnpC5JaKi0zp86YWZ8/QmU/E7g7np8K/K6/eP5r/h/wOHBsPN6T0Fv7PLAT8EZgDDAeuBb4TSLePOAJ4ECCBci26PbuovQN2DcezwUOJjRGDwFWAW+IfjNi2Nb+5CxyfwJ4fzz+JnA9MCXK/FvgS4lrdwDfAEYCrwA2A7MqiHtRzOcJhMbO5Oj/C+AaYCxwEPAk8LfoNxZYDpwdy+mFwLPA7Oj/Y2ANcGT0/xnwi+g3HngK+HdgVDw/KvqdB9wO7BHz87/AVWXKbi6wIh7ngH8jjO7NKi534Dbgkni9Q4FngFdGvwuBn/bzPPV4BoArgf+Lss8AHgHeFf3OiuX6oZj30SXS63XNSmUEXkeo3xTv+xbgsOKyqeA9uRDYFp+DFuBLwO3lntXiMu7jGjcCVwOTCc/ZK1I+f3Pp/726kvAsjgbeBzwYn53JwB+LnoHrCM/TWGAX4E7gvfWuq/xX2a//ALBPvPlbiJUWMKPegvtvEB6OUEltAp4DlsUKtVQFfCiwLnE+D7ioKMw8+lD8JdL8FvDNeNxn5VhcmSbcbwf+M1bqm4GZCb8XEUzGJivPsQn/a4D/lzLu1qRswGrgaELFvwM4IOH3X3Qr/tOAvxbJ/L/AZ+Pxj4FLE34nAA/H4zOAe8qUx0PAqxLn06Icvcovyp+P93gtsBA4vbjcCQ2/TmB8Iu6XgB/H4wupQPHHstlObOREt/cC8+LxWcAT/aTX45oZyfgb4LxE2VSj+P+Y8JsNbC33rJJC8cf7lycq8xL3r+TzV8F7tU/C/08kFDlwbOIZ2BVoJ1EHxOfwz/2Vkf8a69fvnI6FxVfHShoL5MxsY39xnCHFG8zsj0kHSWMIveDjCb0CgPGSWsysM54vr+Qiko4izM0fBIwg9FSvHYjgwO4EZTaVMDqxQFLXJQnKp8A6M9ucOF8G7JYy7hozS05/bQHGxbit9CyLZYnj6cBRkp5LuLUSpkYKPF0iXQhK7lFKMx24TlI+4dZJqLifLBF+pZntUcI9yW7A2qL3fxlh3Uc17EzooSbLYxnhnhWo6BmiChklvRb4LLA/oVc8BlhU4XWLKb5noyS1Fj0jlbAnIV/ryviXe/7SvlfJct6t6Dx5PJ1wz55KvAs5Kr9PTp1Js6r/PEkTCA/TNyXdLem42ovmNDD/ThgKPsrMJgAvj+5KhLGiOMXnxfycMJy+p5lNBL5flF5FSDqCoET+Rhg+3wocaGaT4m+ihQVtBSbHxm2BvYCVKeOW4xnCSMKeRekWWA78JZHuJAtfOrw/RdrLCaNx5fxeW5TuKAvrNKplJTBF0viE2150NyT6u7/FPEsYhZheJr00aRb7VySjpJHAr4CvAbua2STgJgbw3KWg0nKCcD+nSJpURdw071VSpqcIw/wFks/uckKPf+fEczXBzA6sQi6njqRZ3PdOM9sAHEeY2307oQXpDF/GE5Thc3HR2GdTxFlFeUVVSHOtmW2TdCTwlmoEkzRB0omEufWfmtkiM8sTvk75pqRdYrjdJb2mKPrnJI2Q9DLgRODaCuL2Io5+/Bq4UNIYhZXyZyaC3ADsL+ntktri7whJz0+R1RuAaZI+orD4cHzs3UGo3L8oaXqUd6qkk1Ok2VdelgP/AL4kaZSkQ4B3AYXP41YBM5TyC45YNtdEOcdHWT+WSC8NPa5ZhYyFHvAzQEfs/de6U9Pfe9ALM3uKsNbqEoWFtW2SXt5fvEil79U1wHnxGZ9E+MojKcfNwNfje5aTNFPSKyrJj1N/0rykhdbhCcCVZvYAtW0RO43PtwgLgZ4lzKP/PkWcbwOnxhXJpb7h/gBwkaSNwGcIFVAl/DbGXU6Y1/8GYdFcgU8AS4DbJW0grFuZlfB/mrCafSVhEd37zOzhlHH74lzCsOvThDn7ywsecUj6OMLnsStjmIsJyqhPYtxXAyfFeP8irJqHUNbXAzfHMrkdOKpUOhVyBmFeeCVhkddnE9NAheHjNZLuTpnehwjrJ5YSRmZ+DlxWgTylrplaxliGHyY8a+sISvH6Cq5fDV8CPq2w38T5FcR7O2GE5GHCHP5HUsar9L36IUG53wfcQxgB6SBMFQG8g9BgepBQZr8krEFwmgiZ9T3yJOlywpDp3sALCHOb88zs8NqL5zi1R2HXtZ+mmOd2nGFFHAX5vplN7zew0zSk2bDhXYRV20vNbIuknejZk3Icx3GGAAr7UxxD6PXvSpjGu66uQjmZk2ZVf17SKmC2fGcnx3GGGZL2Igxtl2K2mT2R0XU2lfF6rZn9NYtrpBED+Bxhz4CthP0DPjNI13YGiTRD/RcTvjd+kO55HjOz19dYNsdxHMdxMiaN4l8MHGJm7YMjkuM4juM4tSLNqv6lhE0bKkbS8Qr7jy+RdEEJ/7MU9uleGH/vLpWO4ziO4zjZkGbOfguwUNKthM0bADCzPu1pR8MN3yV8crQCuEvS9WZWPFd2tZmdm1bgSZMm2b777ps2uNMHmzdvZuzYsf0HdPrFyzI7vCyzw8syOxqhLBcsWPCsmU0daDppFP/1VPdt65HAkrjlL5J+AZxM+UUyqdh1112ZP3/+QJJwIvPmzWPu3Ln1FmNI4GWZHV6W2eFlmR2NUJaSlvUfqn/SrOq/QtIIwl7WAIvNbEeKtHen5x7OKyi9icgb4y5UjwAfjbtvOY7jOI5TA/pV/HFzkysIVqUE7CnpTDO7LYPr/5ZgLrRdwQ72FcArS8hwDnAOwNSpU5k3b14Gl3Y2bdrkZZkRXpbZ4WWZHV6W2TGUyjLNqv4FwFvMbHE835+grPvcuU/Si4ALzew18fyTAGb2pTLhWwh7Sk/sK91Zs2bZ4sWL+5TZSUcjDF0NFbwss8PLMju8LLOjEcpS0gIzq9YiZhdp5vjbCkofwMwekZRmlf9dwH6S9iZYxzqdIgMRkqZFww8AryfYEXccx2kqCh2oZD/Kiv26zgd4rQoM/BnQ3tHZb7iq5LDuvwWZwnHIc4/8xjBdcRJhkvGx6swXDgYdeWPVhm31FiMT0ij++ZIupdvC1VuBflfXmVmHpHOBPxD297/MzB6QdBEw38yuBz4s6fUEIxBrgbP6TRdYvXEbKrITpMSperirjHsy/PC0OdSZN9ZvSbNcozSlKqBSlVq5F7m/0ab0cqSn0judfH76ojNvrN28vax/JXlNE7K/5PpVDlUU/UDvVq+SVPFpcOjIG89sDB8QFRd/8bud1TMEfT2nBf/eWr1RlVSBzrzx3ADecWdokkbxvx/4IMGKFcBfgUvSJG5mNxGsOyXdPpM4/iTwyVSS9kijRMVW9g1s9FezfhiwrUa9gaFDuufHgB2d+dqK0uT0Ksler3C3Q97SaFZ/tx2nGtKs6m+X9B3gViBPWNVfvmvjOI7jOE7DkmZV/+uA7wOPEkba9pb0XjP7Xa2FcxzHcRwnW9IM9X8dOMbMlgBImkmw2OSK33Ecx3GajDR79W8sKP3IUmBjjeRxHMdxHKeGpF3VfxNwDWE1zZsI++6fAmBmv66hfI7jOI7jZEgaxT8KWAW8Ip4/A4wGTiI0BFzxO47jOE6TkGZV/9mDIYjjOI7jOLWn3zl+SV+RNEFSm6RbJT0j6W2DIZzjOI7jONmSZnHfcWa2ATiRYKhnX+A/aimU4ziO4zi1IY3iL0wHvA641szW11Aex3Ecx3FqSJrFfTdIehjYCrxf0lRgaFgqcBzHcZxhRr89fjO7AHgxMMfMdgBbgJNrLZjjOI7jONmTZnHfGOADwPei027AgO0BO47jOI4z+KSZ478c2E7o9QM8CXyhZhI5juM4jlMz0szxzzSz0ySdAWBmW5TWSLnjOI4zZOnMG+0dnbTvyNPekQ/HHfl43sm2jjztO6JbPN7emS8Zfls83tHRmOatN23cxrjFd9dbjExIo/i3SxpNNH4djfS011SqPli71fjqHxaTE+QkcjnRIiHR/Ten4CeRy9F9nIhTMn5ueLVnlj/VwcoHnk4d3qzbTrpZsJ+eNyAeF/v3DNt/3FoigdR9rwvPg8r8zfUI13dYIR57ppMNS54N+ev6rztvXdmzbrvzBXdLZD4Z1swSx4m0yhwXl7eZ9TymfNkb9LoXSdmK0yEZJhmnxP0slGPXMSL+6ypnSSj6r35yB3dvf7yXe1caiXjJckuI1VV+xW708O++R8VuEMqzo9PozBsdeaMjnw/HneG8M7pVG6aUzMmTcnKVymM5OnbsoPVvt/UZplLMYEc+KOuOfPUv7oiWHCPbcoxszTGytSX8bcvR1pKjEWvizjzs6GzMRkmlqL8HR9KrgU8Ds4GbgZcAZ5nZvJpLV4LRu+1n+733O5iF1mY+Vm6FF6mz1hrEcYY5BUWsQvWsnm4FhSzRo0GQTzQauo6bhBaJ1hbRkhOtucLfXA+31lyOlpakfxm3llzsnHSnr4SqKzeemnRODrr2dO8ZZ83qVey0y67VZ7wMrS0FhZ1jZFsLowrKu4QiH9nawogYdlQMM6I119WQaxYWzf8nB895UV1leN7E0QvMbMBr7Prs8UvKAZOBU4CjCc/YeWb27EAvXC17js9xy0df0WeYvIUGQT5f+rgzHyqd4oZDfpg1Gh65fyH7H3Ro6vDJ3lehgi97XBw+RdxaUlA8eQu9pFJ/C89C8m9xnFJhzODRhxex7/MP7lZ69OyRJhVlKXclzgtlHdJJWd59lX0/4SkOV7gwvdPM/r4kRiLi8aIFtzP7hUdF/zINhnjcoywTDZFut+789QqXCFBKeebUrbCbdXZz0fx1HDzngHqL4TQYfSp+M8tL+riZXQPcOEgyDZjC8GyqpYvDmA1jc0zfaWy9xRgaPN3CQbtPrLcUTUehgZJsbbTlxKi2ljpK5ThDmzSq8Y+Szpe0p6QphV/NJXMcx3EcJ3PSLO47Lf79YMLNgH2yF8dxHMdxnFqSZue+vUv8upR+XPxXEknHS1osaYmkC0r4j5R0dfS/Q9KMqnPiOI7jOE6/ZDELfnEpR0ktwHeB1xK+CDhD0uyiYO8C1pnZvsA3y6XlOI7jOE42ZKH4yy13PRJYYmZLzWw78At67/F/MnBFPP4l8CrfHMhxHMdxakcWir/cN3C7A8sT5yuiW8kwZtYBrAd2ykAmx3Ecx3FKkGZxX92RdA5wDsDUqVNZNP+fdZZoaLB18yYvy4zwsswOL8vs8LLMjqFUllko/sfLuD8J7Jk43yO6lQqzQlIrMBFYU5yQmf0A+AHA/rNmWb13TxoqNMJOVEMFL8vs8LLMDi/L7BhKZZlK8Ut6MTAjGd7Mrox/TykT7S5gP0l7ExT86cBbisJcD5wJ/BM4FfiT9beHsOM4juM4VdOv4pf0E2AmsBDojM4GXNlXPDPrkHQu8AegBbjMzB6QdBEw38yuB34E/ETSEmAtoXHgOI7jOE6NSNPjnwPMrqYnbmY3ATcVuX0mcbwNeFOl6TqO4ziOUx1pVvXfDzyv1oI4juM4jlN70vT4dwYelHQn0F5wNLPX10wqx3Ecx3FqQhrFf2GthXAcx3EcZ3DoV/Gb2V8GQxDHcZzhwoC3J60ggVrthSqEFMygK15HCFQ47ja7XPAryJI87xWuQTdvfSgndp0wqt5iZEKaVf1HA/8DPB8YQVihv9nMJtRYttLyAJPGtPVwS7vssDicld10cHiQkxg/qrZ7OGngVVxmFO538jlIPgHJ9as93Xs7Fj87Aka2VrYRZlVlUyZKf3Vlf1fqr7JNI2lW9XVfz2Vf73ot9EXhHhWn3aXAivzV5a+i857ug0VrTuwyfmgoKyc70tT63yF8ZnctYYX/O4D9aylUf4xsbann5YcMOcGYEU2xeWPD05ITk8aMqLcYQwJ/Lh2ntqTqopjZEqDFzDrN7HLg+NqK5TiO4zhOLUjTrN4iaQSwUNJXgKfIxrhPVTzyyCObJC2u1/WHGDsDz9ZbiCGCl2V2eFlmh5dldjRCWU7PIhH1ty+PpOnAKsL8/kcJ++lfEkcBBh1J881sTj2uPdTwsswOL8vs8LLMDi/L7BhKZZlmVf8ySaOBaWb2uUGQyXEcx3GcGtHvkL2kkwj79P8+nh8q6foay+U4juM4Tg1IM1d/IXAk8ByAmS0E9q6ZRP3zgzpee6jhZZkdXpbZ4WWZHV6W2TFkyjLNHP/tZna0pHvM7IXR7T4zO2RQJHQcx3EcJzPSrOp/QNJbgBZJ+wEfBv5RW7Ecx3Ecx6kFaYb6PwQcSDDQ83NgPXBeLYUqh6TjJS2WtETSBfWQYSgg6TJJqyXdX29Zmh1Je0r6s6QHJT0gqS7vxlBA0ihJd0q6N5alLyYeAJJaJN0j6YZ6y9LsSHpc0iJJCyXNr7c8AyXNUP8c4D+BGXSPENhgD/VLagEeAV4NrADuAs4wswcHU46hgKSXA5uAK83soHrL08xImkb44uVuSeOBBcAb/LmsHIX9bMea2SZJbcDfgPPM7PY6i9aUSPoYYbfVCWZ2Yr3laWYkPQ7MMbN6f8efCWmG+n8GnA/cD+RrK06fHAksMbOlAJJ+AZwMeAVbIWZ2m6QZ9ZZjKGBmTxE2tcLMNkp6CNgdfy4rxkIvZFM8bYu/4W1Qo0ok7QG8Dvgi8LE6i+M0GGmG+p8xs9+a2WNmtqzwq7lkvdkdWJ44XxHdHKchiI2pFwJ31FmUpiUOTy8EVgO3mJmXZXV8C/g49e2sDSUMuFnSAknn1FuYgZKmx/9ZSZcCtxLm+QEws1/XTCrHaTIkjQN+BXzEzDbUW55mxcw6gUMlTQKuk3SQmflalAqQdCKw2swWSJpbZ3GGCi81sycl7QLcIulhM7ut3kJVSxrFfzZwAGHYrdB6NGCwFf+TwJ6J8z2im+PUlTgf/SvgZ94gzgYze07SnwkGwVzxV8ZLgNdLOgEYBUyQ9FMze1ud5WpazOzJ+He1pOsIU89DWvEfYWazai5J/9wF7Cdpb4LCPx14S31FcoY7cUHaj4CHzOwb9ZanmZE0FdgRlf5owkLei+ssVtNhZp8EPgkQe/znu9KvHkljgVxcwzMWOA64qM5iDYg0c/z/kDS75pL0g5l1AOcCfwAeAq4xswfqK1VzIukq4J/ALEkrJL2r3jI1MS8B3g68Mn7qszD2tJzKmQb8WdJ9hIb+LWbmn6I59WZX4G+S7gXuBG40s9/XWaYBkeZzvoeAmcBjhDl+UYfP+RzHcRzHGThpzfL2ok4r+x3HcRzHGQD9Kn7HcRzHcYYOaeb4HcdxHMcZIrjidxzHcZxhhCt+x3EcxxlGuOJ3HMdxnGGEK37HaRAkTZL0gX7CzJDU78ZVMVzZHe8kzZH035XI01+afaTzuKSdK43nOE5tcMXvOI3DJKBPxU8wjz3gHSvNbL6ZfTgDeWqKpDS7izqOUwGu+B2ncfgyMDPu/vfV+Ltf0iJJpyXCvCyG+Wjshf9V0t3x9+I0F5I0V9IN8fhCSZdJmidpqaRCg6CHPCnSbJH0tSjzfZI+lPD+UJRvkaQDYvgjJf1T0j2S/iFpVnQ/S9L1kv4E3CppjKRrJD0o6TpJd0iaE8MeF9O4W9K10ViS4zh94K1px2kcLgAOMrNDJb0ReB/wAmBn4C5Jt8Uw55vZiQCSxgCvNrNtkvYDrgLmVHHtA4BjgPHAYknfS8oTrzWjnzTOIYxIHGpmHZKmJPyeNbPD4tTB+cC7gYeBl8WwxwL/Bbwxhj8MOMTM1ko6H1hnZrMlHQQsjPLsDHwaONbMNkv6BMH2fFPvo+44tcYVv+M0Ji8FropmaldJ+gtwBFBs8rcN+I6kQ4FOYP8qr3ejmbUD7ZJWE/Ynr5Rjge9HuxqY2dqEX8Fq4QLglHg8EbgiNliMkJcCtyTivxT4dkzz/riXP8DRwGzg78FWEiMINigcx+kDV/yO09x8FFhFGBnIAduqTKc9cdxJ9nVDIf1k2p8H/mxm/xZHE+Ylwm9OkaYIDYQzshLScYYDPsfvOI3DRsJQO8BfgdPivPlU4OUEy2DJMBB6zU+ZWZ5gJbClRvKk4RbgvYUFeUVD/aWYSDCxDXBWH+H+Drw5pjkbODi63w68RNK+0W+spGpHPBxn2OCK33EaBDNbQxi2vh94EXAfcC/wJ+DjZvZ0dOuUdK+kjwKXAGdGk6EHkK6nXLE8aRb3AZcCTwD3RXn6+/rgK8CXJN1D3yMMlwBTJT0IfAF4AFhvZs8QGgxXxeH/fxLKwHGcPnAjPY7jNDSSWoC2uIBxJvBHYJaZba+zaI7TlPgcv+M4jc4Y4M+S2gjz+h9wpe841eM9fscZwkh6DXBxkfNjZvZvjZSm4ziDhyt+x3EcxxlG+OI+x3EcxxlGuOJ3HMdxnGGEK37HcRzHGUa44nccx3GcYYQrfsdxHMcZRrjidxzHcZxhhCt+x3EcxxlGuOJ3HMdxnGGEK/4hgKRNkvZJEW6GJCtYT2tmJJ0l6W/1liMNWZe7pFmSFkraKOnDWaQ5WEi6UNJP6y2HM3DS1juDiaR5kt4dj5umjhhsXPEPApIel7Q1viirJP1Y0rgq0+p6sAuY2TgzW5qhnBslPSfpH5LeJ8mfk36QNFdSPt7jjZIWSzq7inTSKMaPE+zYjzez/65OYqdSYuNt33rL0ShkVe84g09mFbqk/SXdGk2KIukQSZ/OKv0hwElmNg44DJgDVFQ2CgyGAj7JzMYD04EvA58AfjQI1x0KrIz3eAKh3H4Y7cdnzXSCadqKGQqjPQWGUl4qYTDyPVzLdriQpSL5IfBJYAeAmd0HnJ5h+kMCM3sS+B1wkKTJkm6Q9IykdfF4j0LY2Lv/oqS/A1uAnwAvA74Te5bfieG6eiKSXifpHkkbJC2XdGGVcq43s+uB0wj23g+K6Y+U9DVJT8TRi+9LGh395kpaIelTkp6NIwhvTeQnTdx/l7Ra0lPJHrOknSRdH/N1JzAzKa+kAyTdImlt7G2/OeH3Y0nflXRj7I3fEc27FvwPTMRdJelT0T0n6QJJj0paI+kaSVNSlJ2Z2W+AdUAvxS9pt5iXtZKWSHpPdD8e+BRwWry/95aI+yfgGLqfgf0lTZR0ZXyOlkn6dKGRqDDc+XdJ35S0BriwRJoXxrxdGcvnAUlzEv49erqxPL8Qjwv37eOJ+/YGSSdIeiTm8VNFlxwl6ep4rbslvaCobH4V8/KYElMZUc5fSvqppA3AWeXugaSW+Bw+Gq+zQNKeKjHtop7Dw/tK+ouk9fEZvjq63xaD3xvL/bTo/p54D9fGe7pbUbl9QNK/ogyflzRTYSRtQyzzEYnwJypM4RRG2w5J+D0u6ROS7gM2qw/FHMM9qe6Rp1dF97LPc6Jc3iXpCeBPkn4n6dyitO+VdEoif4V6Z7Skr8fnb72kv6n73T465ue5GH9uOdkT15ki6XJJKxXqxt9E98nqo87sIz0pvAOrY9kvUqzThiVmlskPuCv+vSfhtjCr9Jv5BzwOHBuP9yT01j4P7AS8kWB2dDxwLfCbRLx5wBPAgQQTym3R7d1F6RuwbzyeCxxMaNQdAqwC3hD9ZsSwrf3JWeT+BPD+ePxN4HpgSpT5t8CXEtfuAL4BjAReAWwm2E5PG/eimM8TCI2dydH/F8A1wFjgIOBJ4G/RbyywHDg7ltMLgWeB2dH/x8Aa4Mjo/zPgF9FvPPAU8O/AqHh+VPQ7D7gd2CPm53+Bq8qU3VxgRTzOAf9GaATPKi534Dbgkni9Q4FngFdGvwuBn/bzPPV4BoArgf+Lss8AHgHeFf3OiuX6oZj30SXSuxDYFsu8BfgScHup5ytRnl8oum+fifftPTE/P4/yHAhsBfZOXGsHcGoMfz7wWDzOAQtiWiOAfYClwGuK4r4hhu2Vl4SM/wEsiuUv4AWE963HvSguT+Aq4D9j+qOAl/ZRDq8kPGeHxefjf4DbisL/H2EE6ECgHbg15msi8CBwZgz7QmA1cFS8B2cS3seRiXdzIaH+6Cvfswjvwm6Jd35mf89zolyuJLxPo4F3AH9PpD0beC4hU7Le+W4sx92j/C+O19id8O6dEMv01fF8aj/P+I3A1cDk+Gy8IrqnqTML9/IsuuuI1xCerUnxeXg+MK0e+qARftklFHqxM4G74/mpwO/qncFG+MWXdlN8aZYRKv1SFfChwLrE+TzgoqIwXQ92wq1HhVTk9y3gm/G48HJXqvhvJ1SGIijymQm/FxFMskK3Ehib8L8G+H8p426lZ4W8Gjg6ViQ7gAMSfv+VeKlPA/5aJPP/Ap+Nxz8GLk34nQA8HI/PINFYLUrjIeBVifNpUY5e5Rflz8d7vJZQSZ9eXO6EirsTGJ+I+yXgx/H4QipQ/LFsthMbOdHtvcC8eHwW8EQ/6V0I/DFxPhvYWu75orfi3wq0xPPxMfxRifAL6G58XkjPRkWO0PB6GUHpPVEk2yeByxNxb+srL4l4i4GTS7h33Ysy5Xkl8ANgjxJxi8vhR8BXEufj4vMxIxH+JUXl8InE+deBb8Xj7wGfL5GHVyTezXemyPe+hPfmWKAt7fOcKJd9Ev7jCe/s9Hj+ReCy4vKI93Ar8IIS8nwC+EmR2x+IDZ4yeZhGeJcmp8jvofSuM0sp/lcSGsRHA7k0z9BQ/mU5j/NBwgtzgKQnCa34t2WYfrPzBjP7Y9JB0hhCL/h4QssWYLykFjPrjOfLK7mIpKMIc/MHEXpNIwmt4oGwO0GZTSW0tBdI6rokQfkUWGdmmxPny4DdUsZdY2YdifMthMp0KqFySpbFssTxdOAoSc8l3FoJUyMFni6RLgRF/CilmQ5cJymfcOsEdiWMOBSz0sz6G3bcDVhrZhsTbssI6z6qYWdCjyhZHssI96xAmmeouHxGSWotuh/lWJN4XrfGv6sS/lvpLu8e8phZXtIKQrkYsFvRfWwB/loqbj/0dV/74uOE0bg7Ja0Dvm5ml5UJuxtwd+HEzDYpTKfsTlDU0Lscis+fF4+nE6bUPpTwHxGvUaDfvJvZEkkfITSSDpT0B+BjZraSvp/nXtcws42SbiRM2V5MaCS/p8RldyaMjpQq7+nAmySdlHBrA/7cRzb2JLwj64o9UtaZvTCzPylMjX4XmC7p18D5ZrahDzmGLJnN8ZvZUjM7llBJH2BmLzWzx7NKf4jy74ShuaPMbALw8uiuRBgrilN8XszPCcPpe5rZROD7RelVhKQjCBXZ3wjDmluBA81sUvxNtLCgrcBkSWMT53sBK1PGLcczhJGEPYvSLbAc+Esi3UkWVhy/P0XaywlDr+X8XluU7igL6zSqZSUwRdL4hNtedDck+ru/xTxL6LVNL5NeNWkWs4XQaCvwvHIBU9J1HxXWIuxBKJflhBGgZHmPN7MTEnHT5mU5RetAIoVGacn8mNnTZvYeM9uNMHJyicqv5C8o00JexhKGoqt5PpYDXyzK+xgzuyoRJlXezeznZvbSKJsRlHbhGv09z8XXuAo4Q9KLCMq9lMJ+ljBVVKq8lxN6/MlrjjWzL/eRheWEd2RSCb80dWZJzOy/zexwwojW/oTpoGFJlqv6z5M0gVBJfFNh0c5xWaU/RBlPUIbPxUU2n00RZxXlFVUhzbVmtk3SkcBbqhFM0gRJJxLm1n9qZovMLE9YxPlNSbvEcLtLek1R9M9JGiHpZcCJwLUVxO1FbMn/GrhQ0hiFlfJnJoLcAOwv6e2S2uLvCEnPT5HVG4Bpkj6isPhwfBw1gdBo+qKk6VHeqZJOTpFmX3lZDvwD+JKkUXEB17uAwid8q4AZSvkFRyyba6Kc46OsH0uklwULgbcoLJg7nrB2YyAcLukUhQVqHyHMfd8O3AlsVFicNjpe76DY+KyUS4HPS9ovLuw6RNJOZvYMQTG/Lab/ThIKS9KbEovF1hEUYaGHXPzuXQWcLelQSSMJ0093VNnh+SHwPklHRXnHKizUHd9vzAQKezy8MsqzjVC/FOSv5nm+idCAuAi4Or7HPYhulwHfUFic2SLpRVGGnwInSXpNdB+lsCC07MiYmT1FmDq+RGExX5ukgoKvps4k1gdHSWojNP62Jcpl2JHlqv53xmGT4wit3rcThpyd8nyLsIjmWULF9/sUcb4NnKqworXUN9wfAC6StJGwSOqaCmX6bYy7nDCv/w3CorkCnwCWALcrrKz+I6EFXuBpQoW5krCI7n1m9nDKuH1xLmG4+GnCHPPlBY84bH4cYUhyZQxzMWGao09i3FcDJ8V4/yKsmodQ1tcDN8cyuZ0wDz1QziDMqa4EriOsRShMAxWmZdZIurtE3FJ8iFCZLSWMzPycUBFnxXmE8nkOeCvwmwGm93+EdRnrCPXEKWa2IzZiTiTM2z5GeC8uJSyEq5RvEJ79m4ENhPn40dHvPYTe3hrCort/JOIdAdwhaRPh3p9n3d+qXwhcobA6/c3xnv0/4FeEdQozqfJLJjObH+X6DqFcltDHVwt9MJJQ7z5LeJ53IayTgCqeZzNrJzS6jyU8V+U4n7CY8i7CtODFhLn05cDJhK9VniHUK/9B/7rn7YSRrIcJaxY+Et2/ReV1JoQFlj8klO0ywr3/asq4Qw6ZDXQUMCYk3Wdmh0j6NmFh0XWS7jGzF2ZyAafhUfhM56cp5rkdx3GcOpFlj3+BpJsJK6b/EIeohu1QiuM4juM0Ilkq/ncBFwBHmNkWworUircsdRzHSYPCBjObSvyKNwwaUkjaq0y+N0naq/8UGoM+8vCyess21MlsqB/CYi3CQpCuzwTN7LbyMRzHcRzHGUwy+45f0sWEBTsPEr4NhbAitk/FL+kywoKe1WY2fLdQdBzHcZxBIMvFfYuBQ+Iq0ErivZywq92Vrvgdx3Ecp7ZkuXPfUsKOTBUpfjO7TdKMtOEnTZpk++7b/JYxN2/ezNixY/sP2OAMhXwMhTyA56PR8Hw0DkMhDwALFix41symDjSdLBX/FmChpFtJKH8z+3D5KJWz6667Mn/+/CyTrAvz5s1j7ty59RZjwAyFfAyFPIDno9HwfDQOQyEPAJKW9R8qRToZDvWfWcrdzK5IEXcGcEO5oX5J5wDnAEydOvXwa66pdE+axmPTpk2MG5dmt9rGZijkYyjkATwfjYbno3EYCnkAOOaYYxaYWbV2PbrIelX/CMIeyACLzWxHyngz6EPxJ5k1a5YtXry4eiEbhKHSAh0K+RgKeQDPR6Ph+WgchkIeACRlovizXNU/F7iCYJVKwJ6SzvTP+RzHcRyncchyjv/rwHFmthhA0v4EIxaH9xVJ0lUEm947K5jn/KyZ/ShDuRzHcWpGX6OmpfzUbZbacepCloq/raD0AczskWgJqU/M7IwMZXCcYUk+b5jBth29TZIXdI8lLK4m9ZH1CGtl3Hs7VpJeybSK0igcduSN1Ru29cpHMdlNUtaGjryxemNFHznVhf6aIWnvRyPTKHlolGc2S8U/X9KldJsDfSvQ/MvvHadBMTO27cjT3tHJ9o48nWas35pqWU3D0ygV5HAgTVkPhfsxFPKQFVkq/vcDHwQKn+/9Fbgkw/QdZ9hjZrR35Nm2Iyh7r8wcx6mUzBS/mbVL+g5wK8Eq32Iz255V+o4zXCko+/bYu3dl7zjOQMhyVf/rgO8DjxKmjfaW9F4z+11W13Cc4YIre8dxakXWq/qPMbMlAJJmAjcCrvgdJyXtHZ1d8/YZbrHhOI7TRZaKf2NB6UeWAhszTN9xhiTbO/Js6+hk2w5X9o7j1J6sV/XfBFxDWED5JuAuSacAmNmvM7yW4zQ1BWXfviNP3rW94ziDSJaKfxSwCnhFPH8GGA2cRGgIuOJ3hjU7OsNq/G2u7B3HqSNZruo/O6u0HGeo0NGZZ1v8/K4z78recZz6k8sqIUlfkTRBUpukWyU9I+ltWaXvOM1CR2eeTe0dPLupnTWbt7O5vcOVvuM4DUNmip+wT/8G4ESCoZ59gf/IMH3HaVg688bm9g7WuLJ3HKfByXKOv5DW64BrzWy9G6NwhjKdeev6/G5HZ77e4tSdvBnb494DhYWL2zo6434EnWyLfws7D7YXhW3vCGGefaadyU8+ULFtAXq49x++R8xy4cvIUPo6PQNsfG4b45cuRInd8IurxMJ5IUyXdyKcusKq6Lw4LZWI0zP9oj890igX5rk17Uxe9SDNzNpn2pn8dP95SN1UTxmw+JkoG26Q+whZKv4bJD0MbAXeL2kqUH+rCI6TIfm8xU/vmkPZd+QLmwAllG1ir4D2Hd3u3f5JxVxGYReFKbhVg4BRbS2MbM0xsi1HfkeekdvW9w5XSknR08hMub5GKaXYV5plDnsr0j7Cbt0O7ZsSm5cWGUvqNp5U2r9UmOKGTq80SqTfO2xp/3JhdmzP07Zhbe/ATcSO7XlGbEqXhx73tq9wGfdrB7OfnOXivgskfQVYb2adkrYAJ2eVvuPUi3w+sT9+Ayl7M+PxNVtYsGwddy9bx0PLt8Kdf+/Ri+6ocrqhNSdGtuUY2drCqPh3ZGuOUW0tjBvZys7juhX1qNaWsmGLw5QK29aiHop50fx/cvCcF2VVTHUj5OPIeosxYIbC/RgKeQB43iezSSfLLXvHAB8A9gLOAXYDZgE3ZHUNxxksGtEYjpmxfO1WFjyxrkvZr9kcepS7jB/J7mNz7LrLJEa15hjZVqR8eyjibqVbTlG35rJc/uM4TiOR5VD/5cAC4MXx/EngWlzxO01Coyl7M2Plc9tYsCwo+gVPrOOZaN9953EjmDNjMoftNZnDp09mj8mjuX/B7Rw858A6S+04TqOTpeKfaWanSToDwMy2qMFW96VZCNTDvdJ0Kkx7e5VzotVSi7thUNVcd5aLWdIuoCkb32D9lh0NYQznqfVbuxT93cue4+kNYZnM5DFtHD59ctdvryljaLDXy3GcJiFLxb9d0mii/otGetozTB9i4qs3buvpUCZcI9OZN9ZtaX6rxZ15Y+3m5s5Hp4UFe/Vg1YbuHv3dT6xj5XPh2Z44uo3D9prE247ei8OnT2bvnce6onccJxOyVPyfBX4P7CnpZ8BLgLMyTL8L3+3UaVae3dTePXS/bB0r1m0FYMKoVl6412ROPyIo+n2mjiXnit5xnBqQieKXlAMmA6cARxO+ajnPzJ7NIn3HaVbWbt7O3QlFv2ztFgDGjWzlhXtN4tTD9+CwvSaz367jXNE7jjMoZKL4zSwv6eNmdg1wYxZpOk4z8tyW7dz9xHNdiv6xZzcDMGZEC4fuOYnXH7obh0+fzP67jqcl54recZzBJ8uh/j9KOh+4GthccDSz5t75wXH6YMPWHdzzxHNdn9gtWb0JgFFtOV6wxyRee9DzOHz6ZA6YNt4/kXMcpyHIUvGfFv9+MOFmwD4ZXsNx6sqmbR0sXN7do39k1UYMGNma45A9JvK+V+zD4dMnM3vaBFpbXNE7jtN4ZLlz3959+Ut6tZndktX1HGcw2Nzewb0ruhX94qc3kjcY0ZLjoN0n8O6X7c3h0ydz4G4TGdHqit5xnMYnyx5/f1wMuOJ3Gpqt2zu7FP3dT6zjoZUb6TSjNScO2n0iZ78kKPqDdp/AyNaWeovrOI5TMYOp+BtyJZNZ2P4lbwYGeYvH0c0sfD6Yj+EsunWf9x8+b4l4hL/LN+YZuWpjWetc5SxvVWp1qyvd/qyCpfQvvonr2401m9oTRkRKGwFJ6540WFLKvYd1taR7LNekX1r3B57t5O9/eZQFy9bx4MoNdOSNlpw4cLcJvP1F0zl8+mQO2WMio9pc0VeKFJ6hnMIznIvnykFO4enKSSFc9GvJiSljR/Sfdu3FD9ep8muL1pzYedzIsv7lNgJLy0BiV3LplpyYPKb/+9HIDIU8ZMlgKv5Mvr5/cmOe13/nb+SNqKgtoXi7K/SkEi7nVndz6f+8s84CZMRf/lZvCQZMi5ZxwLTxvOWovboU/ZgRg/l6NB4iKD0pKOek0k4q7MJniF1hEn+rvW7bEFkf0feXGw3ZF+qFoOmnsYZCHrKk7jWbpOOBbwMtwKVm9uW+wo9qFUfMmNJV4RQqp8L71d17SFRU6t2r6Bm/Z2VVqNQQ5IoqtkL45HWKey09wosi/xD+iUcXs9fMWUB6k5sF/+L2Sn/mNsv5lzMHWokp0JVPLGX3vfbpad5U3YYtC+UdTijp3jNuGXd6jnoUX6/YXYmL9ee+YsnDnDD3aMaNrPvrkBnFSrv4mS4878XPaldY/9TQcYYsg1nTPV7sIKkF+C7wamAFcJek683swXKJ7DRa/L8TZ9dMyMFi0aZHOfiAXeotxoBZZMs5+PA96i3GgFi0rqXplL4ErbkcLTnR1hKGx1tzYuq4kV0NTMdxnFJkWttJejEwI5mumV0Z/55SIsqRwBIzWxrj/wI4GSir+B1nOFFQ8K0tQbG35ERbLle2R+49dcdx+iMzxS/pJ8BMYCFQsHhiwJV9RNsdWJ44XwEclZVMjtMsSNCWy9ESFXxrLkdrTq7IHcfJHA10ZWlXQtJDwGyrIEFJpwLHm9m74/nbgaPM7NyicOcA5wBMnTr18J//4upMZK4nWzdvYvTYcfUWY8AMhXwMdh661pXE9QZZqfZNmzYxblxz3wvwfDQaQyEfQyEPAMccc8wCM5sz0HSyHOq/H3ge8FQFcZ4E9kyc7xHdemBmPwB+ALD/rFl28JwXDUDMxmDR/H/i+WgMapGHnGLPvUVdc/G17sHPmzePuXPn1iz9wcLz0VgMhXwMhTxkSZaKf2fgQUl3Au0FRzN7fR9x7gL2k7Q3QeGfDrwlQ5kcp6bklFxc173YzhfXOY7TqGSp+C+sNIKZdUg6F/gD4XO+y8zsgQxlcpxMKPTYg2Lv7sG7gnccp9nIcq/+v1QZ7ybgpqzkcJyBUFDorS25LkXvCt5xnKFElqv6jwb+B3g+MILQg99sZhOyugaEhVCjyu2RXqZuLldn97mnVh8Vfd/xysXp6dEiMWFUW9l0bIAbHQ5kzWYlUXMSY/v4Br5SdVmNfi0u20rTb5HYaewIWlzBO44zDMhyqP87hDn6a4E5wDuA/TNMv4uJY8orzGZBgtEjmn/v95xous1vipFwE7qO4wwbsvycb76ZzZF0n5kdEt3uMbMXZnKB7utsBBZnmWad2Bl4tt5CZMBQyMdQyAN4PhoNz0fjMBTyADDLzMYPNJEsu2pbJI0AFkr6CuGzvlp0oxZn8R1jvSk0lOotx0AZCvkYCnkAz0ej4floHIZCHiDkI4t0slTMb4/pnQtsJnyf/8YM03ccx3EcZ4Bkuap/maTRwDQz+1xW6TqO4ziOkx2Z9fglnUTYp//38fxQSddnlX6CH9QgzXrg+WgchkIewPPRaHg+GoehkAfIKB9ZLu5bALwSmFdY0CdpkZkdnMkFHMdxHMcZMFnO8e8ws/VFbtm0KhzHcRzHyYQsFf8Dkt4CtEjaT9L/AP/IMH0kHS9psaQlki7IMu3BQtJlklZLur/eslSLpD0l/VnSg5IekHRevWWqBkmjJN0p6d6Yj6ZemyKpRdI9km6otyzVIulxSYskLcxqBfNgI2mSpF9KeljSQ5KazoqVpFnxHhR+GyR9pN5yVYOkj8b3+35JV0kaVW+ZqkHSeTEPDwz0XmQ51D8G+E/guOj0B+DzZtZePlZF6bcAjwCvBlYQDPycYWYPZpH+YCHp5cAm4EozO6je8lSDpGmERZx3SxoPLADe0IT3QsBYM9skqQ34G3Cemd1eZ9GqQtLHCJtnTTCzE+stTzVIehyYY2ZN+821pCuAv5rZpfET5zFm9lydxaqaWPc+STCZvqze8lSCpN0J7/VsM9sq6RrgJjP7cX0lqwxJBwG/AI4EthPW0r3PzJZUk16WPf7Z8dcKjAJOJijnrDgSWGJmS81sO6EQTs4w/UHBzG4D1tZbjoFgZk+Z2d3xeCPwELB7faWqHAtsiqdt8deU01OS9gBeB1xab1mGM5ImAi8HfgRgZtubWelHXgU82mxKP0ErMFpSKzAGWFlnearh+cAdZrbFzDqAvwCnVJtYlor/Z8BlBGFOjL+TMkx/d2B54nwFTahshhqSZgAvBO6osyhVEYfHFwKrgVvMrCnzAXwL+DiQr7McA8WAmyUtkHROvYWpgr2BZ4DL47TLpZLG1luoAXI6cFW9hagGM3sS+BrwBGFTufVmdnN9paqK+4GXSdopjq6fQNgrpyqyVPzPmNlvzewxM1tW+GWYvtNgSBoH/Ar4iJltqLc81WBmnWZ2KLAHcGQcUmsqJJ0IrDazBfWWJQNeamaHAa8FPhinxpqJVuAw4Hvx66bNQFOuRwKIUxWvJ9hgaTokTSaMDO8N7AaMlfS2+kpVOWb2EHAxcDNhmH8h0Fltelkq/s/G1u0Zkk4p/DJM/0l6tnD2iG5OHYhz4r8CfmZmv663PAMlDsf+GTi+zqJUw0uA18f58V8Ar5T00/qKVB2xh4aZrQauI0zxNRMrgBWJkaNfEhoCzcprgbvNbFW9BamSY4HHzOwZM9sB/Bp4cZ1lqgoz+5GZHW5mLwfWEda8VUWWiv9s4FBCxXlS/GW5wOguYD9Je8dW6OlALTYIcvohLor7EfCQmX2j3vJUi6SpkibF49GEhaMP11WoKjCzT5rZHmY2g/Be/MnMmq5XI2lsXCxKHB4/jjDE2TSY2dPAckmzotOrgKZa9FrEGTTpMH/kCeBoSWNivfUqwpqkpkPSLvHvXoQp9Z9Xm1aWRnqOMLNZ/QerDjPrkHQu4WuBFuAyM3ugVterFZKuAuYCO0taAXzWzH5UX6kq5iUE2wyL4vw4wKfM7Kb6iVQV04Ar4qrlHHCNmTXtp3BDgF2B60L9TCvwczP7fX1FqooPAT+LHZSlhE5R0xEbX68G3ltvWarFzO6Q9EvgbqADuIfm3cXvV5J2AnYAHxzIotEsP+e7HPhqs33S5TiO4zjDiSwV/0PATOAxoB0Q4YupQzK5gOM4juM4AyZLxT+9lLuv7Hccx3GcxiEzxe84juM4TuOT5ap+x3Ecx3EaHFf8juM4jjOMcMXvOI7jOMMIV/yOkxGS5kmaU285iolmYj9QbzlqiaSbCpsx1eHaXfc9mhXeuR5yOE5aXPE7TgMQLYfViknAoCr+WuQnbrRUEjM7YQhYwXOcQcEVvzPskDRD0kOSfijpAUk3Sxpd1HPbOe59j6SzJP1G0i2xR3eupI9F62u3S5qSSP7tkhZKul/SkTH+WEmXSbozxjk5ke71kv4E3NqHvJ+QtEjSvZK+HN3KyXpgvM5CSfdJ2g/4MjAzun1Vga9GGRdJOi3GnSvpL5L+T9JSSV+W9NaY3iJJM2O4qZJ+Jemu+HtJdL9Q0k8k/R34SZm8lJIPSW9LuP9vQclL2iTp65LuBT4p6dpEWnMl3RCPu3rakt4R075X0k/6krmMjOMkXR7zfJ+kN0b370maH5+Zz5WLn7jnN0YZ7i+UseM0BGbmP/8Nqx8wg7B956Hx/BrgbcA8YE502xl4PB6fBSwBxgNTgfXA+6LfNwnWCYnxfxiPXw7cH4//C3hbPJ5EMK4xNqa7ApjSh6yvBf4BjInnUxLXKiXr/wBvjccjgNExv/cn0nwjcAth6+tdCfuZTyNsJf1cPB5JMIL1uRjnPOBb8fjnBCt6AHsRbDYAXAgsAEb3kZ9S8j0f+C3QFt0vAd4Rjw14czxujbKOjeffS5Tr47EcDozlu3NReZWUuYyMFxfyGs8nF6XVEsv/kBL3oiDHGwvPQnSfWO/n3n/+K/xqObzoOI3MY2a2MB4vICjHvvizmW0ENkpaT1BUAIuA5O6UVwGY2W2SJsR55+MI1vPOj2FGEZQPwC1mtraP6x4LXG5mW2K6fYUF+Cfwn5L2AH5tZv9S2Ps+yUuBq8ysE1gl6S/AEcAG4C4zewpA0qMEM6CFfB6TkGl2It0JCiaaAa43s60Vyvcq4HDgrpjmaGB1DN9JsAKJBXsdvwdOUth//XXAx4vSfyVwrZk9G+MUyqukzGa2qYSMxxKMHRHTWBcP3yzpHEIDZBowG7ivTD4XAV+XdDFwg5n9tY8ycZxBxRW/M1xpTxx3EpRNB93TX6P6CJ9PnOfp+R4V74hlhO2r32hmi5Meko4i2GuvhpKymtnPJd1BUIo3SXovwVBMWtLkMwccbWbbkhGjUu0zP2XkE3CFmX2yRJRtsYFS4BfAucBaYH5sjKWhpMxpkbQ3cD7BGNk6ST+m9zPShZk9Iukw4ATgC5JuNbOLqrm242SNz/E7TjePE3qeAKdWmUZhvvylwHozW0+wKPkhRc0o6YUVpHcLcLakMTFuYT1BSVkl7QMsNbP/Bv6PMBqxkTBNUeCvwGmSWiRNJUxL3FmBTDcTLNAVrnlo2ohl5LsVOFXdZkenqMwW4MBfCPbt30NoBBTzJ+BNClbMkuVVicy3AB9MhJ0MTCA0atZL2pUwBdNXPncDtpjZT4GvRpkdpyFwxe843XwNeL+kewjztNWwLcb/PvCu6PZ5oA24T9ID8TwVFszSXg/MVzCBXJguKCfrm4H7Y9iDgCvNbA3w97jI7KvAdYQh6nsJivLjFuzIp+XDwJy48O1B4H0VxC0l34PAp4GbJd1HULzTSkWOvf8bCIq3lwllC6a6vwj8JS4I/EYVMn8BmBzL617gGDO7l2DS9WHCeoG/95PPg4E7Yz4/G9N0nIbA9+p3HMdxnGGE9/gdx3EcZxjhi/scpwGQdDC9v31vN7Oj6iHPQJH0GsJncUkeM7N/q4c8pZB0NuEzxSR/N7MPlgrvOEMFH+p3HMdxnGGED/U7juM4zjDCFb/jOI7jDCNc8TuO4zjOMMIVv+M4juMMI1zxO47jOM4w4v8DeVizTc6xC0YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 504x720 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model.partial_plot(df, cols=['total_night_minutes', 'total_night_calls', 'total_night_charge', 'total_intl_minutes', 'total_intl_calls', 'total_intl_charge', 'number_customer_service_calls'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shutdown H2O Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O session _sid_840b closed.\n"
     ]
    }
   ],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Appendix - Generalized Linear Model (GLM)  \n",
    "\n",
    "The generalized linear model (GLM) is a flexible generalization of ordinary linear regression that allows for response variables that have error distribution models other than a normal distribution. The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a link function and by allowing the magnitude of the variance of each measurement to be a function of its predicted value.\n",
    "\n",
    "Generalized Linear Models (GLM) estimate regression models for various probability distributions. In addition to the Gaussian (i.e. normal) distribution, these include Poisson, binomial, and gamma distributions. This can be used either for prediction or classification.\n",
    "\n",
    "Overfitting is prevented using L1, L2 and elastic-net regularization.\n",
    "\n",
    "While not easily parallelable, maximum likelihood estimates of coefficients is very efficient.\n",
    "\n",
    "GLMs are highly interpretable as the coefficients (i.e. the slopes) as they directly related the degree the dependent variable changes in response to a change in each independent variable.\n",
    "\n",
    "For these data and the regression case, we can think of this as linear regression. to \n",
    "In linear regression, the use of the least-squares estimator is justified by the Gauss--Markov theorem, which does not assume that the distribution is normal. From the perspective of generalized linear models, however, it is useful to suppose that the distribution function is the normal distribution with constant variance and the link function is the identity, which is\n",
    "the canonical link if the variance is known.\n",
    "\n",
    "In our case, we will assume that the the distribution of errors is normal and that the link function is the identity, which means the will will be performing simple linear regression.   Linear regression predicts the response variable $y$ assuming it has a linear relationship with predictor variable(s) $x$ or $x_1, x_2, ,,, x_n$.\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x + \\varepsilon .$$\n",
    "\n",
    "*Simple* regression use only one predictor variable $x$. *Mulitple* regression uses a set of predictor variables $x_1, x_2, ,,, x_n$.\n",
    "\n",
    "The *response variable* $y$ is also called the regressand, forecast, dependent or explained variable. The *predictor variable* $x$ is also called the regressor, independent or explanatory variable.\n",
    "\n",
    "The parameters $\\beta_0$ and $\\beta_1$ determine the intercept and the slope of the line respectively. The intercept $\\beta_0$ represents the predicted value of $y$ when $x=0$. The slope $\\beta_1$ represents the predicted increase in $Y$ resulting from a one unit increase in $x$.\n",
    "\n",
    "Note that the regression equation is just our famliar equation for a line with an error term.\n",
    "\n",
    "The equation for a line:  \n",
    "$$ Y = bX + a $$\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x $$\n",
    "\n",
    "The equation for a line with an error term:  \n",
    "\n",
    "$$ Y = bX + a + \\varepsilon $$\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x + \\varepsilon .$$\n",
    "\n",
    "- $b$ = $\\beta_1$ = slope\n",
    "- $a$ = $\\beta_0$ = $Y$ intercept\n",
    "- $\\varepsilon$ = error term\n",
    "\n",
    "\n",
    "We can think of each observation $y_i$ consisting of the systematic or explained part of the model, $\\beta_0+\\beta_1x_i$, and the random *error*, $\\varepsilon_i$.\n",
    "\n",
    "_Zero Slope_\n",
    "\n",
    "Note that when  $\\beta_1 = 0$ then response does not change as the predictor changes.\n",
    "\n",
    "For multiple regression $x$ is a $X$ to produce a system of equations:  \n",
    "\n",
    "$$ Y = \\beta_0 + \\beta_1 X  + \\varepsilon $$\n",
    "\n",
    "_The error $\\varepsilon_i$_\n",
    "\n",
    "The error term is a catch-all for anything that may affect $y_i$ other than $x_i$. We assume that these errors:\n",
    "\n",
    "* have mean zero; otherwise the forecasts will be systematically biased.\n",
    "* statistical independence of the errors (in particular, no correlation between consecutive errors in the case of time series data).\n",
    "* homoscedasticity (constant variance) of the errors.\n",
    "* normality of the error distribution.\n",
    "\n",
    "If any of these assumptions is violated then the robustness of the model to be taken with a grain of salt.\n",
    "\n",
    "\n",
    "_Least squares estimation_\n",
    "\n",
    "In a linear model, the values of $\\beta_0$ and $\\beta_1$. These need to be estimated from the data. We call this *fitting a model*.\n",
    "\n",
    "The least squares method iis the most common way of estimating $\\beta_0$ and $\\beta_1$ by minimizing the sum of the squared errors. The values of $\\beta_0$ and $\\beta_1$ are chosen so that that minimize\n",
    "\n",
    "$$\\sum_{i=1}^N \\varepsilon_i^2 = \\sum_{i=1}^N (y_i - \\beta_0 - \\beta_1x_i)^2. $$\n",
    "\n",
    "\n",
    "Using mathematical calculus, it can be shown that the resulting **least squares estimators** are\n",
    "\n",
    "$$\\hat{\\beta}_1=\\frac{ \\sum_{i=1}^{N}(y_i-\\bar{y})(x_i-\\bar{x})}{\\sum_{i=1}^{N}(x_i-\\bar{x})^2} $$ \n",
    "\n",
    "and\n",
    "\n",
    "$$\\hat{\\beta}_0=\\bar{y}-\\hat{\\beta}_1\\bar{x}, $$\n",
    "\n",
    "where $\\bar{x}$ is the average of the $x$ observations and $\\bar{y}$ is the average of the $y$ observations. The estimated line is known as the *regression line*.\n",
    "\n",
    "To solve least squares with gradient descent or stochastic gradient descent (SGD) or losed Form (set derivatives equal to zero and solve for parameters).\n",
    "\n",
    "_Fitted values and residuals_\n",
    "\n",
    "The response values of $y$ obtained from the observed $x$ values are\n",
    "called *fitted values*: $\\hat{y}_i=\\hat{\\beta}_0+\\hat{\\beta}_1x_i$, for\n",
    "$i=1,\\dots,N$. Each $\\hat{y}_i$ is the point on the regression\n",
    "line corresponding to $x_i$.\n",
    "\n",
    "The difference between the observed $y$ values and the corresponding fitted values are the *residuals*:\n",
    "\n",
    "$$e_i = y_i - \\hat{y}_i = y_i -\\hat{\\beta}_0-\\hat{\\beta}_1x_i. $$\n",
    "\n",
    "The residuals have some useful properties including the following two:\n",
    "\n",
    "$$\\sum_{i=1}^{N}{e_i}=0 \\quad\\text{and}\\quad \\sum_{i=1}^{N}{x_ie_i}=0. $$\n",
    "\n",
    "Residuals are the errors that we cannot predict.Residuals are highly useful for studying whether a given regression model is an appropriate statistical technique for analyzing the relationship.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Appendix - _Decision-tree based methods (DRF, XRT, GBM, and XGBoost)_\n",
    "\n",
    "\n",
    "**What is a decision-tree?**\n",
    "\n",
    "What is a tree?  In mathematics, and more specifically in graph theory, a [tree](https://en.wikipedia.org/wiki/Tree_(graph_theory)) is a directed or an undirected graph in which any two vertices are connected by exactly one path. In other words, any acyclic connected graph is a tree.\n",
    "\n",
    "A tree is an undirected graph G that satisfies any of the following equivalent conditions:  \n",
    "* G is connected and has no cycles.   \n",
    "* G is acyclic, and a simple cycle is formed if any edge is added to G.  \n",
    "* G is connected, but is not connected if any single edge is removed from G.  \n",
    "\n",
    "A rooted tree is a tree in which one vertex/node has been designated the root. The edges of a rooted tree can be assigned a natural orientation, either away from or towards the root, in which case the structure becomes a directed rooted tree. \n",
    "\n",
    "A vertex/node that does not split is called Leaf or Terminal node.     \n",
    "\n",
    "A sub section of entire tree is called branch or sub-tree.  \n",
    "\n",
    "A vertex/node, which is divided into sub-nodes is called parent node of sub-nodes where as sub-nodes are the child of parent node.  \n",
    "\n",
    "A [decision tree](https://en.wikipedia.org/wiki/Decision_tree) is a [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning) algorithm that uses a tree-like graph or model of decisions and their outcomes.  The decision tree can be linearized into decision rules, where the outcome is the contents of the leaf node, and the conditions along the path form a conjunction in the if clause. In general, the rules have the form:\n",
    "\n",
    "$if \\quad condition1 \\quad and \\quad condition2 \\quad and \\quad condition3 \\quad then \\quad outcome$\n",
    "\n",
    "Each node in the tree is a decisions/tests. Each path from the tree root to a leaf corresponds to a conjunction of attribute decisions/tests. The tree itself corresponds to a disjunction of these conjunctions.\n",
    "\n",
    "**The 20 Questions of machine learning**  \n",
    "\n",
    "In the traditional [20 Questions](https://en.wikipedia.org/wiki/Twenty_Questions) game, one player is chosen to be the answerer. That person chooses a subject (object) but does not reveal this to the others. All other players are questioners. They each take turns asking a question which can be answered with a simple \"Yes\" or \"No.\" The questioners try to guess the answerers subject (object).\n",
    "\n",
    "The Two Rules \n",
    "\n",
    "  Rule 1: Questioners ask Yes-or-No questions     \n",
    "  Rule 2: Answerer responds with a Yes or a No    \n",
    "\n",
    "Traditionally,first question is something like the following: \n",
    "\n",
    "  * \"Is it animal?\"  \n",
    "  * \"Is it vegetable?\"  \n",
    "  * \"Is it mineral?\"  \n",
    "  \n",
    "Suppose the answer is \"Justin Bieber?\"\n",
    "\n",
    "Which would be a better first question?\n",
    "\n",
    "\"Is it Taylor Swift?\" or \"Is it animal?\"   \n",
    "\n",
    "**Estimating the information in a data split?**\n",
    "\n",
    "Like 20 questions we want to split data in such a way as to maximize the information generated from the split.\n",
    "\n",
    "To calculate entropy, we can calculate the information difference, $-p_1 \\log p_1 - p_2 \\log p_2$. Generalizing this to n events, we get:\n",
    "\n",
    "$$\n",
    "entropy(p_1, p_2, ... p_n) = -p_1 \\log p_1 - p_2 \\log p_2 ...  - p_n \\log p_n \n",
    "$$\n",
    "\n",
    "which is just the Shannon entropy\n",
    "\n",
    "$$\n",
    "H_1 (X) = - \\sum_{i=1}^n p_i \\log p_i. \n",
    "$$\n",
    "\n",
    "For example, if entropy = $-1.0 \\log (1.0) - 0.0 \\log (0.0) = 0$ then this provides no information. If entropy = $-0.5 \\log (0.5) - 0.5 \\log (0.5) = 1.0$ then this provides one “bit” of information.  Note that when $P(X)$ is 0.5 one is most uncertain and the Shannon entropy is highest (i.e. 1). When $P(X)$ is either 0.0 or 1.0 one is most certain and the Shannon entropy is lowest (i.e. 0)\n",
    "\n",
    "_Shannon entropy_  \n",
    "\n",
    "The notion of using entropy as a measure of change in system state and dynamics comes both from [statistical physics](https://en.wikipedia.org/wiki/Entropy) and from [information theory](https://en.wikipedia.org/wiki/Entropy_(information_theory)). In statistical physics, entropy is a measure of disorder and uncertainty in a random variable; the higher the entropy, the greater the disorder. In the statistical physics context, the term usually refers to [Gibbs entropy](https://en.wikipedia.org/wiki/Entropy_(statistical_thermodynamics)), which measures the macroscopic state of the system as defined by a distribution of atoms and molecules in a thermodynamic system. Gibbs entropy is a measure of the disorder in the arrangements of its particles. As the position of a particle becomes less predictable, the entropy increases. For a classical system (i.e., a collection of classical particles) with a discrete set of microstates, if $E_i$ is the energy of microstate $i$, and $p_i$ is the probability that it occurs during the system's fluctuations, then the entropy of the system is\n",
    "\n",
    "$$\n",
    "S = -k_\\text{B}\\,\\sum_i p_i \\ln \\,p_i\n",
    "$$\n",
    "\n",
    "The quantity $k_\\text{B}$ is a physical constant known as [Boltzmann's constant](https://en.wikipedia.org/wiki/Boltzmann_constant), which, like the entropy, has units of heat capacity. The logarithm is dimensionless.\n",
    "\n",
    "In information theory, entropy is also a measure of the uncertainty in a random variable. In this context, however, the term usually refers to the [Shannon entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)), which quantifies the expected value of the information contained in a message (or the expected value of the information of the probability distribution). The concept was introduced by [Claude E. Shannon](https://en.wikipedia.org/wiki/Claude_Shannon) in his 1948 paper \"A Mathematical Theory of Communication.\" Shannon entropy establishes the limits to possible data compression and channel capacity.  That is, the entropy gives a lower bound for the efficiency of an encoding scheme (in other words, a lower bound on the possible compression of a data stream). Typically this is expressed in the number of ‘bits’ or ‘nats’ that are required to encode a given message. Given the probability of each of n events, the information required to predict an event is the distribution’s entropy. \n",
    "\n",
    "Low entropy means the system is very ordered, that is, very predictable. High entropy means the system is mixed, that is, very unpredictable; a lot of information is needed for prediction. \n",
    "\n",
    "The Shannon entropy can explicitly be written as\n",
    "\n",
    "$$\n",
    "E(X) = \\sum_{i} {\\mathrm{P}(x_i)\\,\\mathrm{I}(x_i)} = -\\sum_{i} {\\mathrm{P}(x_i) \\log_b \\mathrm{P}(x_i)},\n",
    "$$\n",
    "\n",
    "where b is the base of the logarithm used. Common values of b are 2, Euler's number $e$, and 10, and the unit of entropy is shannon for b = 2, nat for b = e, and hartley for b = 10.When b = 2, the units of entropy are also commonly referred to as bits.\n",
    "\n",
    "The Shannon entropy is by far the most common information-theoretic measure there are others. Other information-theoretic measures include: plog,Rényi entropy, Hartley entropy, collision entropy, min-entropy, Kullback-Leibler divergence and the information dimension.\n",
    "\n",
    "The Shannon entropy is the Rényi entropy with an alpha of one (see appendix). The Shannon entropy is a simple estimate of the expected value of the information contained in a message. It assumes independence and identically distributed random variables, which is a simplification when applied to word counts. In this sense it is analogous to naïve Bayes, in that it is very commonly used and thought to work well in spite of violating some assumptions upon which it is based.\n",
    "\n",
    "The limiting value of $H_\\alpha as \\alpha \\rightarrow 1$ is the Shannon entropy:\n",
    "\n",
    "$$\n",
    "H_1(X) = - \\sum_{i=1}^n p_i \\log p_i. \n",
    "$$\n",
    "\n",
    "**Classification vs Regression Trees**  \n",
    "\n",
    "Types of decision tree is based on the type of target variable we have. It can be of two types:\n",
    "\n",
    "Classification Tree (Categorical Response Variable Decision Tree): Decision Tree which separates the dataset into classes belonging to the categorical target variable. Usually the response variable has two classes: Yes or No (1 or 0).  \n",
    "\n",
    "Regression trees (Continuous Response Variable Decision Tree): If a decision Tree has continuous target variable it is applicable for prediction type of problems as opposed to classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def shannon_entropy(p):   \n",
    "    return (-p *np.log2(p) - (1-p)*np.log2(1-p))\n",
    "\n",
    "base=0.0000000001\n",
    "x = np.arange(base, 1.0-base, 0.01)\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(x, shannon_entropy(x), 'go', x, shannon_entropy(x), 'k')\n",
    "plt.ylabel('Shannon entropy(X)')\n",
    "plt.xlabel('X')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainy is not the same as probability\n",
    "\n",
    "Notice that when $P(X)$ is 0.5 one is most uncertain and the Shannon entropy is highest (i.e. 1). When $P(X)$ is either 0.0 or 1.0 one is most certain and the Shannon entropy is lowest (i.e. 0)\n",
    "\n",
    "\n",
    "### Computing Information Gain\n",
    "\n",
    "$$\n",
    "Information Gain = entropy(parent) – [average entropy(children)]\n",
    "$$\n",
    "\n",
    "Note that since the entropy(parent) doesn't change the child node for which entropy is minimum is, equivalently, the child node for which information gain is maximum.  \n",
    "\n",
    "Intuitively, low entropy means certainty and high entropy means uncertainty. A high information gain is equivalent to going from uncertainty to certainty.\n",
    "\n",
    "\n",
    "### Let's Build a Decision Tree by Computing Information Gain\n",
    "\n",
    "Building a decision tree is a simple algorithm once one understands the concept of entropy and information gain.  \n",
    "\n",
    "1. Calculate the entropy of every attribute using the data set S, using the Shannon entropy.\n",
    "2. Split the set S into subsets using the attribute for which entropy is minimum (or, equivalently, information gain is maximum)  \n",
    "3. Make the decision tree (or sub-tree) root node that attribute.  \n",
    "4. Recur on subsets using remaining attributes. \n",
    "\n",
    "## Bootstrapping, bagging, boosting and aggregating predictions\n",
    "\n",
    "\n",
    "**Bootstrapping**\n",
    "\n",
    "In [bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) is any test or metric that relies on random sampling with replacement. Bootstrapping allows assigning\n",
    "measures of accuracy (defined in terms of bias, variance, confidence intervals, prediction error or some other such measure) to sample estimates. This technique allows estimation of the sampling distribution of almost any statistic using random sampling\n",
    "methods. It falls in the broader class of resampling methods.\n",
    "\n",
    "**Bagging**\n",
    "\n",
    "The training algorithm for random forests applies the general technique of [bootstrap aggregating](https://en.wikipedia.org/wiki/Bootstrap_aggregating), or bagging, to tree learners. Given a training set $X = x_1, ..., x_n$ with responses $Y = y_1, ..., y_n$, bagging repeatedly ($B$ times) selects a random sample with replacement of the training set and fits trees to these samples \n",
    "\n",
    " For $b = 1, ..., B$ \n",
    " - Sample, with replacement, $B$ training examples from $X, Y$; call these $X_b, Y_b$.\n",
    " - Train a decision or regression tree $f_b \\quad on \\quad X_b, Y_b$.\n",
    "\n",
    "After training, predictions for unseen samples ${mvar|x'}$ can be made by averaging the predictions from all the individual regression trees on ${mvar|x'}$ \n",
    "\n",
    " $$\\hat{f} = \\frac{1}{B} \\sum_{b=1}^Bf_b (x')$$\n",
    "\n",
    "or by taking the majority vote in the case of decision trees.\n",
    "\n",
    "This bootstrapping procedure leads to better model performance because it decreases the [Bias–variance dilemma](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff) of the model, without increasing the bias. This means that while the predictions of a single tree are highly sensitive to noise in its training set, the average of many trees is not, as long as the trees are not correlated. Simply training many trees on a single training set would give strongly correlated trees (or even the same tree many times, if the training algorithm is deterministic); bootstrap sampling is a way of de-correlating the trees by showing them different training sets.\n",
    "\n",
    "The number of samples/trees, $B$, is a free parameter. Typically, a few hundred to several thousand trees are used, depending on the size and nature of the training set. An optimal number of trees $B$ can be found using cross-validation, or by observing the _out-of-bag error_ the mean prediction error on each training sample $x_i$, using only the trees that did not have $x_i$ in their bootstrap sample. The training and test error tend to level off after some number of trees have been fit.\n",
    "\n",
    "\n",
    "**Boosting**\n",
    "\n",
    "[Boosting](https://en.wikipedia.org/wiki/Boosting_(machine_learning) is an ensemble meta-algorithm for primarily reducing bias, and also variance in supervised learning, and a family of machine learning algorithms that convert weaker learners to strong ones. While boosting is not algorithmically constrained, most boosting algorithms consist of iteratively learning weak classifiers with respect to a distribution and adding them to a final strong classifier. When they are added, they are typically weighted in some way that is usually related to the weak learners' accuracy.  After a weak learner is added, the data weights are readjusted, known as \"re-weighting\".  Misclassified input data gain a higher weight and examples that are classified correctly lose weight. Thus, future weak learners focus more on the examples that previous weak learners misclassified.\n",
    "\n",
    "There are many boosting algorithms. The many differnce between boosting based decision-tree ensemble methods like XGboost and GBMs is the boosting algorithm used. \n",
    "\n",
    "\n",
    "**aggregating predictions**\n",
    "\n",
    "\n",
    "For regression aggregating predictions can as simple as averaging the predictions from a set of models.  For classification, aggregating predictions can as simple as ataking the majority vote of the predictions from a set of models. \n",
    "\n",
    "Usually a surrogate model is used.  Since the output from the models is always predictions, that set of predictions can serve as the input to another algorithm, usually GLMs or tree-based algorithms, which then predict the same target as the base models.  The helps as it, in effect, weights the predictions for each model according to their accuracy rather than weighting them equally as simple averaging or majority vote would do.\n",
    "\n",
    "_Distributed Random Forest (DRF)_    \n",
    "\n",
    "A Distributed Random Forest (DRF) is a powerful low-bias classification and regression tool that can fit highly non-linear data. To prevent overfitting a DRF generates a forest of classification or regression trees, rather than a single classification or regression tree through a process called bagging. The variance of estimates can be adjusted by the number of trees used. \n",
    "\n",
    "[Random forests](https://en.wikipedia.org/wiki/Random_forest) or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set.\n",
    "\n",
    "The training algorithm for random forests applies the general technique of bootstrap aggregating, or bagging, to tree learners. Given a training set $X = x_1, ..., x_n$ with responses $Y = y_1, ..., y_n$, bagging repeatedly (B times) selects a random sample with replacement of the training set and fits trees to these samples:\n",
    "\n",
    "For $b = 1, ..., B$:   \n",
    "\n",
    "*  Sample, with replacement, B training examples from $X, Y$; call these $X_b, Y_b$.   \n",
    "*  Train a decision or regression tree $f_b on X_b, Y_b$.  \n",
    "*  After training, predictions for unseen samples $x'$ can be made by averaging the predictions from all the individual regression trees on $x'$:  \n",
    "\n",
    "$$\n",
    "\\hat{f} = \\frac{1}{B} \\sum_{b=1}^Bf_b (x')\n",
    "$$\n",
    "\n",
    "or by taking the majority vote in the case of decision trees.\n",
    "\n",
    "This bootstrapping procedure leads to better model performance because it decreases the variance of the model, without increasing the bias. This means that while the predictions of a single tree are highly sensitive to noise in its training set, the average of many trees is not, as long as the trees are not correlated. Simply training many trees on a single training set would give strongly correlated trees (or even the same tree many times, if the training algorithm is deterministic); bootstrap sampling is a way of de-correlating the trees by showing them different training sets.\n",
    "\n",
    "The number of samples/trees, $B$, is a free parameter. Typically, a few hundred to several thousand trees are used, depending on the size and nature of the training set. An optimal number of trees $B$ can be found using cross-validation, or by observing the out-of-bag error: the mean prediction error on each training sample $x_i$, using only the trees that did not have $x_i$ in their bootstrap sample. The training and test error tend to level off after some number of trees have been fit.\n",
    "\n",
    "\n",
    "_Extreme Random Forest (XRT)_\n",
    "\n",
    "Extreme random forests are nearly identical to standard random forests except that the splits, both attribute and cut-point, are chosen totally or partially at random. Bias/variance\n",
    "analysis has shown that XRTs work by decreasing variance while at the same time increasing bias. Once the randomization level is properly adjusted, the variance almost vanishes while bias only slightly increases with respect to standard trees. \n",
    "\n",
    "\n",
    "_Gradient Boosting Machine (GBM)_   \n",
    "\n",
    "Gradient Boosting Machine (for Regression and Classification) is a forward learning ensemble method. The guiding heuristic is that good predictive results can be obtained through increasingly refined approximations. Boosting can create more accurate models than bagging but doesn’t help to avoid overfitting as much as bagging does.\n",
    "\n",
    "Unlike a DRF which uses bagging to prevent overfitting a GBM uses boosting to sequentially refine a regression or classification tree. However as each tree is built in parallel it allows for multi-threading (asynchronous) training large data sets.\n",
    "\n",
    "As with all tree based methods it creates decision trees and is highly interpretable.\n",
    "\n",
    "\n",
    "_XGBoost_\n",
    "\n",
    "XGBoost is a supervised learning algorithm that implements a process called boosting to yield accurate models. Boosting refers to the ensemble learning technique of building many models sequentially, with each new model attempting to correct for the deficiencies in the previous model. \n",
    "\n",
    "Both XGBoost and GBM follows the principle of gradient boosting. However, XGBoost has a more regularized model formalization to control overfitting. Boosting does not prevent overfitting the way bagging does, but typically gives better accuracy. XGBoost corrects for the deficiencies of boosting by ensembling regularized trees.\n",
    "\n",
    "Like a GBM, each tree is built in parallel it allows for multi-threading (asynchronous) training large data sets.\n",
    "\n",
    "As with all tree based methods it creates decision trees and is highly interpretable.\n",
    "\n",
    "**Preventing overfitting**\n",
    "\n",
    "The idea of overfitting means that your prediction model is too biased towards your training data. To limit overfitting two things are usually done:\n",
    "\n",
    "  * Limit the tree size (see above)    \n",
    "  * Prune the decision trees (see below) \n",
    "  \n",
    "_Constraints on Tree Size_  \n",
    "\n",
    "When creating a decision tree, there is a trade-off between its simplicity and predictive power. A deep tree with many leaves is usually over-fitting the training data. In contrast, a shallow tree may not have high training accuracy. \n",
    "\n",
    "One wants a tree that is deep enough to be accurate on the training data while being shallow enough to be predictive on a wide range of data. As a rule of thumb, a depth of the square root of the total number of features should be in the ballpark but we should always check the tree through cross-validatiion and how sensible the rules generated are.\n",
    "\n",
    "**Pruning**  \n",
    "\n",
    "The [pruning](https://en.wikipedia.org/wiki/Pruning_(decision_trees)) (of a node) in a decision tree, reduces the size of decision trees by removing sections of the tree that provide little power to classify instances. Pruning reduces the complexity of the final classifier, and hence improves predictive accuracy by the reduction of overfitting.\n",
    "\n",
    "Pruning can occur in a top down or bottom up fashion. A top down pruning will traverse nodes and trim subtrees starting at the root, while a bottom up pruning will start at the leaf nodes. Below are several popular pruning algorithms.\n",
    "\n",
    "_Reduced error pruning_    \n",
    "\n",
    "One of the simplest forms of pruning is reduced error pruning. Starting at the leaves, each node is replaced with its most popular class. If the prediction accuracy is not affected then the change is kept. While somewhat naive, reduced error pruning has the advantage of simplicity and speed.\n",
    "\n",
    "_Cost complexity pruning_  \n",
    "\n",
    "Cost complexity pruning generates a series of trees $T_0 . . . T_m$ where $T_0$ is the initial tree and $T_m$ is the root alone. At step $i$ the tree is created by removing a subtree from tree $i-1$ and replacing it with a leaf node with value chosen as in the tree building algorithm. The subtree that is removed is chosen as follows. Define the error rate of tree $T$ over data set $S$ as $err(T,S)$. The subtree that minimizes \n",
    "\n",
    "$$\\frac{err(prune(T,t),S)-err(T,S)}{|leaves(T)|-|leaves(prune(T,t))|}$$\n",
    "\n",
    "is chosen for removal. The function prune(T,t) defines the tree gotten by pruning the subtrees t from the tree T. Once the series of trees has been created, the best tree is chosen by generalized accuracy as measured by a training set or cross-validation.\n",
    "\n",
    "\n",
    "**Decision Trees Pros and Cons**  \n",
    "\n",
    "_Advantages_  \n",
    "\n",
    "Easy to Understand: Decision tree output is very easy to interpret. One can often check the rules to see if they make sense.\n",
    "\n",
    "Significant Variables: Decision tree is one of the fastest way to identify most significant variables and relation between two or more variables. \n",
    "\n",
    "Non Parametric: Decision treea are usually created with non-parametric algorithms. Non-parametric models do not require the modeler to make any assumptions about the distribution of the population, and so are sometimes referred to as a distribution-free method. \n",
    "\n",
    "_Disadvantages_   \n",
    "\n",
    "Over fitting: Over fitting is easy with decision trees. Limiting the tree depth, cross-validation and pruning are essential to creating robust trees. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Appendix - Entropy and information gain\n",
    "\n",
    "#### Plog\n",
    "\n",
    "Plog (which we pronounce ‘plog, ’ for positive log) is simply the negative log of the frequency. As the value of plog increases, the frequency decreases. \n",
    "\n",
    "$$\n",
    "E(X) = -\\sum\\ln{p_i}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "freq  | (base 2)  \n",
    "----  | -------------  \n",
    "0.5   |  1  \n",
    "0.25  |  2  \n",
    "1/16  |  5  \n",
    "\n",
    "  \n",
    "\n",
    "Big plog means low frequency.\n",
    "\n",
    "#### Rényi entropies  \n",
    "\n",
    "The [Rényi entropies](https://en.wikipedia.org/wiki/R%C3%A9nyi_entropy) generalize the Shannon entropy, the Hartley entropy, the min-entropy, and the collision entropy. As such, these entropies as an ensemble are often called the Rényi entropies (or the Rényi entropy, even though this usually refers to a class of entropies). The difference between these entropies is in the respective value for each of an order parameter called alpha: the values of alpha are greater than or equal to zero but cannot equal one. The Renyi entropy ordering is related to the underlying probability distributions and allows more probable events to be weighted more heavily. As alpha approaches zero, the Rényi entropy increasingly weighs all possible events more equally, regardless of their probabilities. A higher alpha (a) weighs more probable events more heavily. The base used to calculate entropies is usually base 2 or Euler's number base $e$. If the base of the logarithm is 2, then the uncertainty is measured in bits. If it is the natural logarithm, then the unit is nats. \n",
    "\n",
    "#### Rényi entropies\t \n",
    "\n",
    "The Rényi entropy of order $\\alpha$, where $\\alpha \\geq 0$  and $\\alpha \\neq 1$ , is defined as\n",
    "\n",
    "$$\n",
    "H_\\alpha(X) = \\frac{1}{1-\\alpha}\\log\\Bigg(\\sum_{i=1}^n p_i^\\alpha\\Bigg)\n",
    "$$\n",
    "\n",
    "Here, X is a discrete random variable with possible outcomes 1,2,...,n and corresponding probabilities $p_i \\doteq \\Pr(X=i) for i=1,\\dots,n,$ and the logarithm is base 2. \n",
    "\n",
    "\n",
    "#### Hartley entropy\n",
    "\n",
    "The Hartley entropy is the Rényi entropy with an alpha of zero. \n",
    "\n",
    "the probabilities are nonzero, $H_0$ is the logarithm of the cardinality of X, sometimes called the Hartley entropy of X:  \n",
    "\n",
    "$$\n",
    "H_0 (X) = \\log n = \\log |X|\n",
    "$$\n",
    "\n",
    "#### Shannon entropy \n",
    "\n",
    "The Shannon entropy is the Rényi entropy with an alpha of one. The Shannon entropy is a simple estimate of the expected value of the information contained in a message. It assumes independence and identically distributed random variables, which is a simplification when applied to word counts. In this sense it is analogous to naïve Bayes, in that it is very commonly used and thought to work well in spite of violating some assumptions upon which it is based.\n",
    "\n",
    "The limiting value of $H_\\alpha as \\alpha \\rightarrow 1$ is the Shannon entropy:\n",
    "\n",
    "$$\n",
    "H_1 (X) = - \\sum_{i=1}^n p_i \\log p_i. \n",
    "$$\n",
    "\n",
    "#### collision entropy\n",
    "\n",
    "The collision entropy is the Rényi entropy with an alpha of two and is sometimes just called \"Rényi entropy,\" refers to the case $\\alpha = 2$,\n",
    "\n",
    "$$\n",
    "H_2 (X) = - \\log \\sum_{i=1}^n p_i^2 = - \\log P(X = Y)\n",
    "$$\n",
    "\n",
    "where $X$ and $Y$ are independent and identically distributed. \n",
    "\n",
    "#### min-entropy\n",
    "\n",
    "The min-entropy is the Rényi entropy as the limit of alpha approaches infinity. The name min-entropy stems from the fact that it is the smallest entropy measure in the Rényi family of entropies. In the limit as $\\alpha \\rightarrow \\infty$, the Rényi entropy $H_\\alpha converges to the min-entropy H_\\infty$:\n",
    "\n",
    "$$\n",
    "H_\\infty(X) \\doteq \\min_i (-\\log p_i) = -(\\max_i \\log p_i) = -\\log \\max_i p_i\\,.\n",
    "$$\n",
    "\n",
    "Equivalently, the min-entropy $H_\\infty(X)$ is the largest real number b such that all events occur with probability at most $2^{-b}$.\n",
    "\n",
    "\n",
    "#### Kullback-Leibler divergence\n",
    "\n",
    "[Kullback-Leibler divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) is a non-symmetric measure of the difference between two probability distributions. The Kullback-Leibler measure goes by several names: relative entropy, discrimination information, Kullback-Leibler (KL) number, directed divergence, informational divergence, and cross entropy. Kullback-Leibler divergence is a measure of the difference between the observed entropy and its excepted entropy. We calculate the KL divergence by weighting one distribution (like an observed frequency distribution) by the log of probabilities of some other distribution D2. For discrete probability distributions P and Q, the Kullback–Leibler divergence of Q from P is defined to be\n",
    "\n",
    "$$\n",
    "D_{\\mathrm{KL}}(P\\|Q) = \\sum_i P(i) \\, \\ln\\frac{P(i)}{Q(i)}\n",
    "$$\n",
    "\n",
    "In words, it is the expectation of the logarithmic difference between the probabilities P and Q, where the expectation is taken using the probabilities P.\n",
    "\n",
    "\n",
    "#### Mutual Information\n",
    "\n",
    "[Mutual information](https://en.wikipedia.org/wiki/Mutual_information) quantifies the mutual dependence of the two random variables. It is a measure of the “stickiness” between two items. It measures how much knowing one of these variables reduces uncertainty about the other. We can use mutual information to quantify the association between two tags. Mutual information is given by:\n",
    "\n",
    "the mutual information of two discrete random variables X and Y can be defined as:\n",
    "\n",
    "$$\n",
    " I(X;Y) = \\sum_{y \\in Y} \\sum_{x \\in X} \n",
    "                 p(x,y) \\log{ \\left(\\frac{p(x,y)}{p(x)\\,p(y)}\n",
    "                              \\right) }, \\,\\!\n",
    "$$                              \n",
    "                              \n",
    "where $p(x,y)$ is the joint probability distribution function of $X$ and $Y$, and $p(x)$ and $p(y)$ are the marginal probability distribution functions of $X$ and $Y$ respectively. In the case of continuous random variables, the summation is replaced by a definite double integral:\n",
    "\n",
    "$$\n",
    " I(X;Y) = \\int_Y \\int_X \n",
    "                 p(x,y) \\log{ \\left(\\frac{p(x,y)}{p(x)\\,p(y)}\n",
    "                              \\right) } \\; dx \\,dy,\n",
    "$$\n",
    " \n",
    "where $p(x,y)$ is now the joint probability density function of $X$ and $Y$, and $p(x$) and $p(y)$ are the marginal probability density functions of $X$ and $Y$ respectively.\n",
    "\n",
    "#### Gini Index\n",
    "\n",
    "The [Gini coefficient](https://en.wikipedia.org/wiki/Gini_coefficient) (sometimes expressed as a Gini ratio or a normalized Gini index) is a measure of homogeneity. A Gini coefficient (G) of zero expresses perfect equality, where all values are the same. A Gini coefficient of 1 (or 100%) expresses maximal inequality among values. G is a measure of inequality, defined as the mean of absolute differences between all pairs of individuals for some measure.\n",
    "\n",
    "\n",
    "#### Chi-Square\n",
    "\n",
    "A [chi-squared test](https://en.wikipedia.org/wiki/Chi-squared_test), also written as $\\chi^2$ test, is any statistical hypothesis test wherein the sampling distribution of the test statistic is a chi-squared distribution when the null hypothesis is true. It is used to test the statistical significance between the differences between sub-nodes and parent node. \n",
    "\n",
    "We measure it by sum of squares of standardized differences between observed and expected frequencies of sample population. Chi-squared tests are often constructed from a sum of squared errors, or through the sample variance. Test statistics that follow a chi-squared distribution arise from an assumption of independent normally distributed data. A chi-squared test can be used to attempt rejection of the null hypothesis that the data are independent.\n",
    "\n",
    "The higher the value of Chi-Square, the higher the statistical significance of differences between two populations.\n",
    "\n",
    "Chi-Square of each node is calculated using formula and the observed, $O$, and expected, $E$, frequencies of sample population.\n",
    "\n",
    "$$\n",
    "\\tilde{\\chi}^2=\\frac{1}{d}\\sum_{k=1}^{n} \\frac{(O_k - E_k)^2}{E_k}\\\n",
    "$$\n",
    "\n",
    "#### Reduction in Variance\n",
    "\n",
    "\n",
    "Reduction in variance is often used to calculate information gain when one has continuous variables rather than categorical variables.\n",
    "\n",
    "The variance reduction of a node $N$ is defined as the total reduction of the variance of the target variable $x$ due to the split at this node:\n",
    "\n",
    "$$\n",
    "I_{V}(N) = \\frac{1}{|S|^2}\\sum_{i\\in S} \\sum_{j\\in S} \\frac{1}{2}(x_i - x_j)^2 - \\left(\\frac{1}{|S_t|^2}\\sum_{i\\in S_t} \\sum_{j\\in S_t} \\frac{1}{2}(x_i - x_j)^2 + \\frac{1}{|S_f|^2}\\sum_{i\\in S_f} \\sum_{j\\in S_f} \\frac{1}{2}(x_i - x_j)^2\\right)\n",
    "$$\n",
    "\n",
    "where $S$, $S_t$, and $S_f$ are the set of presplit sample indices, set of sample indices for which the split test is true, and set of sample indices for which the split test is false, respectively. Each of the above summands are indeed [variance](https://en.wikipedia.org/wiki/Variance) estimates, though, written in a form without directly referring to the mean.\n",
    "\n",
    "#### ID3 algorithm\n",
    "\n",
    "This idea of iteratively finding the attribute with the most information gain to find a root in decision tree learning is called the  [ID3 (Iterative Dichotomiser 3)](https://en.wikipedia.org/wiki/ID3_algorithm) algorithm. The invented by [Ross Quinlan](https://en.wikipedia.org/wiki/Ross_Quinlan). It is a simple algorithm once one understands the concept of entropy and information gain.  \n",
    "\n",
    "1.  Calculate the entropy of every attribute using the data set S, using the Shannon entropy.\n",
    "2. Split the set S into subsets using the attribute for which entropy is minimum (or, equivalently, information gain is maximum)  \n",
    "3. Make the decision tree (or sub-tree) root node that attribute.  \n",
    "4. Recur on subsets using remaining attributes.  \n",
    "\n",
    "#### C4.5 algorithm\n",
    "\n",
    "[C4.5](https://en.wikipedia.org/wiki/C4.5_algorithm) is an extension of Quinlan's earlier ID3 algorithm. The splitting criterion is based on statistical confidence estimates. This technique has the advantage that it allows all of the available labeled data to be used for training. To generate this confidence one calculates the error rate over $n$ labled training instances. The observed error rate $e$ is analaogous to the observed fraction of heads in $n$  tosses of a biased coin (i.e. the probability of heads may not be 0.5). One wishes to estimate the true error rate, $p$ from the observed error rate $e$.   \n",
    "\n",
    "The confidence interval, is calculated as follows, if one chooses a level of confidence $z$ then \n",
    "\n",
    "$$\n",
    "p = e + z \\times \\sqrt{e \\times \\frac{1-e}{n}}\n",
    "$$  \n",
    "\n",
    "Paired values for z and confidence levels (z,confidence) are in the following lists: (0.67 z, 50% confidence), (1.0 z, 68% confidence) , (1.64 z, 90% confidence) and (1.96 z, 95% confidence).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2019 NEU AI Skunkworks\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
